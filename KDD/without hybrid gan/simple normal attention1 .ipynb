{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dtypes = {\n",
    "\"feature1\": np.float16,\n",
    "\"feature2\": np.float16,\n",
    "\"feature3\": np.float16,\n",
    "\"feature4\": np.float16,\n",
    "\"feature5\": np.float16,\n",
    "\"feature6\": np.float16,\n",
    "\"feature7\": np.float16,\n",
    "\"feature8\": np.float16,\n",
    "\"feature9\": np.float16,\n",
    "\"feature10\": np.float16,\n",
    "\"feature11\": np.float16,\n",
    "\"feature12\": np.float16,\n",
    "\"feature13\": np.float16,\n",
    "\"feature14\": np.float16,\n",
    "\"feature15\": np.float16,\n",
    "\"feature16\": np.float16,\n",
    "\"feature17\": np.float16,\n",
    "\"feature18\": np.float16,\n",
    "\"feature19\": np.float16,\n",
    "\"feature20\": np.float16,\n",
    "\"label\": np.object}    \n",
    "'''\n",
    "columns = [\"feature1\",\"feature2\",\"feature3\",\"feature4\",\"feature5\",\"feature6\",\"feature7\",\"feature8\",\"feature9\",\"feature10\",\"feature11\",\"feature12\",\"feature13\",\"feature14\",\"feature15\",\"feature16\",\"feature17\",\"feature18\",\"feature19\",\"feature20\",\"label\"]\n",
    "#df = pd.read_csv(\"/kaggle/input/kdd-cup-1999-data/kddcup.data_10_percent_corrected\", sep=\",\", names=columns, dtype=dtypes, index_col=None)\n",
    "df = pd.read_csv(r\"C:\\Users\\admin\\ablation study - 20 neurons\\afterdimensionalityreduction\",sep=\",\", names=columns, dtype=str, index_col=None)\n",
    "#df_read = pd.read_csv(savefile, dtype=str, index_col=0)\n",
    "#print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             feature1               feature2 feature3     feature4  \\\n",
       "0        0.049896017                    0.0      0.0  0.074576885   \n",
       "1         0.05703238                    0.0      0.0          0.0   \n",
       "2         0.05211395  0.0006721932400000001      0.0          0.0   \n",
       "3         0.04974308            0.003009851      0.0          0.0   \n",
       "4         0.04832898              0.0042979      0.0          0.0   \n",
       "...              ...                    ...      ...          ...   \n",
       "1048571  0.023582537            0.011685466      0.0          0.0   \n",
       "1048572  0.023108114             0.01054538      0.0          0.0   \n",
       "1048573  0.022631112            0.008008906      0.0          0.0   \n",
       "1048574  0.022127744            0.008818104      0.0          0.0   \n",
       "1048575   0.02162299   0.008149143000000001      0.0          0.0   \n",
       "\n",
       "             feature5              feature6 feature7              feature8  \\\n",
       "0                 0.0          0.0035594553      0.0           0.012225969   \n",
       "1         0.052905086           0.043763362      0.0                   0.0   \n",
       "2          0.01591806            0.02435071      0.0          0.0016837418   \n",
       "3        0.0029502455  0.017709356000000002      0.0          0.0066348887   \n",
       "4                 0.0           0.014554087      0.0           0.009138886   \n",
       "...               ...                   ...      ...                   ...   \n",
       "1048571           0.0           0.005893277      0.0           0.046702452   \n",
       "1048572           0.0          0.0058220904      0.0            0.04695243   \n",
       "1048573           0.0           0.005821051      0.0  0.047111400000000005   \n",
       "1048574           0.0           0.005707981      0.0           0.047399394   \n",
       "1048575           0.0  0.005666818499999999      0.0  0.047594800000000013   \n",
       "\n",
       "        feature9    feature10  ... feature12 feature13 feature14    feature15  \\\n",
       "0            0.0  0.019287573  ...       0.0       0.0       0.0          0.0   \n",
       "1            0.0  0.031135669  ...       0.0       0.0       0.0  0.006044184   \n",
       "2            0.0   0.02647767  ...       0.0       0.0       0.0          0.0   \n",
       "3            0.0  0.025008397  ...       0.0       0.0       0.0          0.0   \n",
       "4            0.0  0.024143761  ...       0.0       0.0       0.0          0.0   \n",
       "...          ...          ...  ...       ...       ...       ...          ...   \n",
       "1048571      0.0          0.0  ...       0.0       0.0       0.0  0.015696432   \n",
       "1048572      0.0          0.0  ...       0.0       0.0       0.0  0.015654337   \n",
       "1048573      0.0          0.0  ...       0.0       0.0       0.0  0.015895598   \n",
       "1048574      0.0          0.0  ...       0.0       0.0       0.0  0.015462209   \n",
       "1048575      0.0          0.0  ...       0.0       0.0       0.0  0.015328575   \n",
       "\n",
       "        feature16   feature17 feature18 feature19 feature20   label  \n",
       "0             0.0  0.06614828       0.0       0.0       0.0  Normal  \n",
       "1             0.0         0.0       0.0       0.0       0.0  Normal  \n",
       "2             0.0         0.0       0.0       0.0       0.0  Normal  \n",
       "3             0.0         0.0       0.0       0.0       0.0  Normal  \n",
       "4             0.0         0.0       0.0       0.0       0.0  Normal  \n",
       "...           ...         ...       ...       ...       ...     ...  \n",
       "1048571       0.0         0.0       0.0       0.0       0.0  Normal  \n",
       "1048572       0.0         0.0       0.0       0.0       0.0  Normal  \n",
       "1048573       0.0         0.0       0.0       0.0       0.0  Normal  \n",
       "1048574       0.0         0.0       0.0       0.0       0.0  Normal  \n",
       "1048575       0.0         0.0       0.0       0.0       0.0  Normal  \n",
       "\n",
       "[1048576 rows x 21 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal      595798\n",
       "Abnormal    452778\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     object\n",
       "feature2     object\n",
       "feature3     object\n",
       "feature4     object\n",
       "feature5     object\n",
       "feature6     object\n",
       "feature7     object\n",
       "feature8     object\n",
       "feature9     object\n",
       "feature10    object\n",
       "feature11    object\n",
       "feature12    object\n",
       "feature13    object\n",
       "feature14    object\n",
       "feature15    object\n",
       "feature16    object\n",
       "feature17    object\n",
       "feature18    object\n",
       "feature19    object\n",
       "feature20    object\n",
       "label        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df)   \n",
    " \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature1'] = df['feature1'].astype(float) \n",
    "df['feature2'] = df['feature2'].astype(float) \n",
    "df['feature3'] = df['feature3'].astype(float) \n",
    "df['feature4'] = df['feature4'].astype(float) \n",
    "df['feature5'] = df['feature5'].astype(float) \n",
    "df['feature6'] = df['feature6'].astype(float) \n",
    "df['feature7'] = df['feature7'].astype(float) \n",
    "df['feature8'] = df['feature8'].astype(float) \n",
    "df['feature9'] = df['feature9'].astype(float) \n",
    "df['feature10'] = df['feature10'].astype(float) \n",
    "df['feature11'] = df['feature11'].astype(float) \n",
    "df['feature12'] = df['feature12'].astype(float) \n",
    "df['feature13'] = df['feature13'].astype(float) \n",
    "df['feature14'] = df['feature14'].astype(float) \n",
    "df['feature15'] = df['feature15'].astype(float) \n",
    "df['feature16'] = df['feature16'].astype(float) \n",
    "df['feature17'] = df['feature17'].astype(float) \n",
    "df['feature18'] = df['feature18'].astype(float) \n",
    "df['feature19'] = df['feature19'].astype(float) \n",
    "df['feature20'] = df['feature20'].astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 for normal data and 1 for abnormalities\n",
    "df.label=df.label.apply(lambda x: 0 if x == 'Normal' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly sample 500 data point for training\n",
    "df_train=df[df.label==0].sample(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "371932  0.026557  0.004126       0.0       0.0  0.000000  0.005460       0.0   \n",
       "240736  0.033874  0.016817       0.0       0.0  0.000000  0.010579       0.0   \n",
       "400263  0.000000  0.059251       0.0       0.0  0.023905  0.000000       0.0   \n",
       "14244   0.038895  0.000418       0.0       0.0  0.000000  0.016198       0.0   \n",
       "728349  0.000000  0.013596       0.0       0.0  0.065201  0.000000       0.0   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "837916  0.027667  0.015779       0.0       0.0  0.000000  0.005940       0.0   \n",
       "893601  0.035821  0.017934       0.0       0.0  0.000000  0.006323       0.0   \n",
       "120197  0.030983  0.009596       0.0       0.0  0.000000  0.007617       0.0   \n",
       "397590  0.034716  0.019239       0.0       0.0  0.000000  0.004806       0.0   \n",
       "56482   0.032540  0.013902       0.0       0.0  0.000000  0.006175       0.0   \n",
       "\n",
       "        feature8  feature9  feature10  ...  feature12  feature13  feature14  \\\n",
       "371932  0.034826  0.000000   0.019423  ...        0.0        0.0        0.0   \n",
       "240736  0.022600  0.000000   0.030713  ...        0.0        0.0        0.0   \n",
       "400263  0.014005  0.099211   0.000000  ...        0.0        0.0        0.0   \n",
       "14244   0.017770  0.000000   0.031272  ...        0.0        0.0        0.0   \n",
       "728349  0.010659  0.108828   0.000000  ...        0.0        0.0        0.0   \n",
       "...          ...       ...        ...  ...        ...        ...        ...   \n",
       "837916  0.046429  0.000000   0.000000  ...        0.0        0.0        0.0   \n",
       "893601  0.043790  0.000000   0.000000  ...        0.0        0.0        0.0   \n",
       "120197  0.028658  0.000000   0.026184  ...        0.0        0.0        0.0   \n",
       "397590  0.043882  0.000000   0.000000  ...        0.0        0.0        0.0   \n",
       "56482   0.045375  0.000000   0.000000  ...        0.0        0.0        0.0   \n",
       "\n",
       "        feature15  feature16  feature17  feature18  feature19  feature20  \\\n",
       "371932   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "240736   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "400263   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "14244    0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "728349   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "837916   0.015850        0.0        0.0        0.0        0.0        0.0   \n",
       "893601   0.019818        0.0        0.0        0.0        0.0        0.0   \n",
       "120197   0.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "397590   0.019317        0.0        0.0        0.0        0.0        0.0   \n",
       "56482    0.018550        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "        label  \n",
       "371932      0  \n",
       "240736      0  \n",
       "400263      0  \n",
       "14244       0  \n",
       "728349      0  \n",
       "...       ...  \n",
       "837916      0  \n",
       "893601      0  \n",
       "120197      0  \n",
       "397590      0  \n",
       "56482       0  \n",
       "\n",
       "[40000 rows x 21 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0.033874\n",
       "feature2     0.016817\n",
       "feature3     0.000000\n",
       "feature4     0.000000\n",
       "feature5     0.000000\n",
       "feature6     0.010579\n",
       "feature7     0.000000\n",
       "feature8     0.022600\n",
       "feature9     0.000000\n",
       "feature10    0.030713\n",
       "feature11    0.000000\n",
       "feature12    0.000000\n",
       "feature13    0.000000\n",
       "feature14    0.000000\n",
       "feature15    0.000000\n",
       "feature16    0.000000\n",
       "feature17    0.000000\n",
       "feature18    0.000000\n",
       "feature19    0.000000\n",
       "feature20    0.000000\n",
       "label        0.000000\n",
       "Name: 240736, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#https://datacarpentry.org/python-ecology-lesson/03-index-slice-subset/index.html\n",
    "csv_1=csv_1[0:100]\n",
    "csv_2=csv_2[0:40000]\n",
    "merged = csv_1.merge(csv_2,on=\"Label\")\n",
    "\n",
    "merged.to_csv(\"attentiongan.csv\", index=False)\n",
    "#result = pd.concat([csv_1, csv_2], axis=1)\n",
    "out = csv_1.append(csv_2)\n",
    "print(out)\n",
    "out.to_csv(\"attentiongan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = mydataframe.drop(['acol','bcol'], axis=1).values \n",
    "#y = mydataframe['targetvalue'].values\n",
    "df_label=df_train.label\n",
    "X=df_train.drop(['label'], axis=1).values \n",
    "y=df_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.to_csv('normallabel1.csv',header=False, index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 371932    0\n",
       "240736    0\n",
       "400263    0\n",
       "14244     0\n",
       "728349    0\n",
       "         ..\n",
       "837916    0\n",
       "893601    0\n",
       "120197    0\n",
       "397590    0\n",
       "56482     0\n",
       "Name: label, Length: 40000, dtype: int64>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000 Training sequences (28000, 20)\n",
      "12000 Validation sequences (12000, 20)\n",
      "28000 Training sequences (28000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(X,y,train_size=0.70, random_state=2)\n",
    "print(len(x_train), \"Training sequences\",x_train.shape)\n",
    "print(len(x_val), \"Validation sequences\",x_val.shape)\n",
    "print(len(y_train), \"Training sequences\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Attention\n",
    "#https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation,RepeatVector,Permute \n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "maxlen=20\n",
    "vocab_size = x_train.shape[0]\n",
    "#vocab_size = 50000\n",
    "visible = layers.Input(shape=(maxlen,))\n",
    "\n",
    "embed=Embedding(vocab_size,20)(visible)\n",
    "\n",
    "activations= keras.layers.GRU(20, return_sequences=True)(embed)\n",
    "\n",
    "attention = TimeDistributed(Dense(1, activation='tanh'))(activations) \n",
    "attention = Flatten()(attention)\n",
    "attention = Activation('softmax', name='attention_vec')(attention)\n",
    "#attention = RepeatVector(1)(attention)\n",
    "#attention = Permute([2, 1])(attention) \n",
    "\n",
    "#sent_representation = keras.layers.multiply([activations, attention])\n",
    "#sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",
    "predictions=Dense(1, activation='sigmoid')(attention)\n",
    "\n",
    "model = keras.Model(inputs=visible, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 20, 20)            560000    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 20, 20)            2520      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 20, 1)             21        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "attention_vec (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 562,562\n",
      "Trainable params: 562,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "28000/28000 [==============================] - 8s 281us/sample - loss: 0.6600 - accuracy: 1.0000 - val_loss: 0.6451 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "28000/28000 [==============================] - 3s 103us/sample - loss: 0.6317 - accuracy: 1.0000 - val_loss: 0.6163 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "28000/28000 [==============================] - 3s 94us/sample - loss: 0.6011 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "28000/28000 [==============================] - 3s 97us/sample - loss: 0.5675 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "28000/28000 [==============================] - 3s 102us/sample - loss: 0.5403 - accuracy: 1.0000 - val_loss: 0.5277 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, batch_size=1024, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0h 1m 1s\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "\n",
    "diff = (end - start)\n",
    "\n",
    "datetime.timedelta(seconds=10, microseconds=885206)\n",
    "\n",
    "diff_seconds = int(diff.total_seconds())\n",
    "\n",
    "minute_seconds, seconds = divmod(diff_seconds, 60)\n",
    "hours, minutes = divmod(minute_seconds, 60)\n",
    "hms = f\"{hours}h {minutes}m {seconds}s\"\n",
    "\n",
    "'0h 0m 10s'\n",
    "print(hms) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_model = Model(inputs=model.input, outputs=model.layers[2].output)\n",
    "#output_before_att = new_model.predict(x_test_sample) #extract layer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=model.input,\n",
    "              outputs=[model.output, model.get_layer('attention_vec').output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.get_layer('attention_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[0.0112609 , 0.01010128, 0.00993895, ..., 0.07262563, 0.07262564,\n",
      "        0.07262564],\n",
      "       [0.0112609 , 0.01010128, 0.00993895, ..., 0.07262563, 0.07262564,\n",
      "        0.07262564],\n",
      "       [0.0112609 , 0.01010128, 0.00993895, ..., 0.07262563, 0.07262564,\n",
      "        0.07262564],\n",
      "       ...,\n",
      "       [0.0112609 , 0.01010128, 0.00993895, ..., 0.07262563, 0.07262564,\n",
      "        0.07262564],\n",
      "       [0.0112609 , 0.01010128, 0.00993895, ..., 0.07262563, 0.07262564,\n",
      "        0.07262564],\n",
      "       [0.0112609 , 0.01010128, 0.00993895, ..., 0.07262563, 0.07262564,\n",
      "        0.07262564]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "keras_function = K.function([model.input], [layer.output])\n",
    "outputs.append(keras_function([x_train, 0]))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.05111162, 0.04997791, 0.04977211, ..., 0.04977211, 0.04977211,\n",
      "        0.04977211],\n",
      "       [0.05142421, 0.0505545 , 0.04971144, ..., 0.04971144, 0.04971144,\n",
      "        0.04971144],\n",
      "       [0.04949602, 0.05251734, 0.04949602, ..., 0.04949602, 0.04949602,\n",
      "        0.04949602],\n",
      "       ...,\n",
      "       [0.0513057 , 0.05022004, 0.04974045, ..., 0.04974045, 0.04974045,\n",
      "        0.04974045],\n",
      "       [0.05144748, 0.05065737, 0.04969208, ..., 0.04969208, 0.04969208,\n",
      "        0.04969208],\n",
      "       [0.05134976, 0.05040156, 0.04970571, ..., 0.04970571, 0.04970571,\n",
      "        0.04970571]], dtype=float32)]\n",
      "(1, 40000, 20)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "hidden_layers = keras.backend.function(\n",
    "[layer.input],  # we will feed the function with the input of the first layer  \n",
    "[layer.output,] # we want to get the output of the first layer\n",
    ")\n",
    "h=hidden_layers([X])\n",
    "print(h)\n",
    "print(np.shape(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.concatenate(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('normalattentionvector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_1 = pd.read_csv('normalattentionvector.csv')\n",
    "csv_2 = pd.read_csv('normallabel1.csv')\n",
    "\n",
    "result = pd.concat([csv_1, csv_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"attentionnormalresult.csv\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
