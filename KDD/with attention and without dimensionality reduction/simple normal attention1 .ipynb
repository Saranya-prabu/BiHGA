{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edb8d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6538182f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]\n"
     ]
    }
   ],
   "source": [
    "def createList(r1, r2):\n",
    "  \n",
    "    # Testing if range r1 and r2 \n",
    "    # are equal\n",
    "    if (r1 == 118):\n",
    "        return \"Label\"\n",
    "  \n",
    "    else:\n",
    "  \n",
    "        # Create empty list\n",
    "        res = []\n",
    "  \n",
    "        # loop to append successors to \n",
    "        # list until r2 is reached.\n",
    "        while(r1 < r2+1 ):\n",
    "              \n",
    "            res.append(r1)\n",
    "            r1 += 1\n",
    "        return res\n",
    "      \n",
    "# Driver Code\n",
    "r1, r2 = 1, 118\n",
    "print(createList(r1, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c474759",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_1 = pd.read_csv(r'C:\\Users\\admin\\ablation study - Copy\\with attention and without dimensionality reduction\\lgcnormalresult.csv', header=None, names=createList(1, 118))\n",
    "\n",
    "csv_1.to_csv(\"lgcnormalresult.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1ef095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               1         2    3    4    5    6    7    8    9    10   ...  109  \\\n",
       "0.0  3.836304e-07  0.000287  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
       "0.0  4.124748e-07  0.000139  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
       "0.0  2.610418e-07  0.000341  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
       "0.0  4.658370e-07  0.000037  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
       "0.0  4.023793e-07  0.000968  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
       "..            ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "0.0  2.408507e-07  0.000437  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
       "0.0  4.917969e-07  0.000896  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
       "0.0  4.225704e-07  0.002216  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
       "0.0  4.629525e-07  0.000114  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0   \n",
       "0.0  0.000000e+00  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "     110  111  112  113  114  115  116  117  118  \n",
       "0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[40000 rows x 118 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ca598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c751b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lgcnormalresult.csv\",sep=\",\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea4a0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      float64\n",
      "2      float64\n",
      "3      float64\n",
      "4      float64\n",
      "5      float64\n",
      "        ...   \n",
      "114    float64\n",
      "115    float64\n",
      "116    float64\n",
      "117    float64\n",
      "118    float64\n",
      "Length: 118, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d18482f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                   1         2    3    4    5    6    7    8    9   10  ...  \\\n",
       "0      3.836304e-07  0.000287  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \n",
       "1      4.124748e-07  0.000139  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \n",
       "2      2.610418e-07  0.000341  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \n",
       "3      4.658370e-07  0.000037  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \n",
       "4      4.023793e-07  0.000968  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \n",
       "...             ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "39995  2.408507e-07  0.000437  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \n",
       "39996  4.917969e-07  0.000896  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \n",
       "39997  4.225704e-07  0.002216  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \n",
       "39998  4.629525e-07  0.000114  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \n",
       "39999  0.000000e+00  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "       109  110  111  112  113  114  115  116  117  118  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "39995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "39996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "39997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "39998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "39999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[40000 rows x 118 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cb85a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = mydataframe.drop(['acol','bcol'], axis=1).values \n",
    "#y = mydataframe['targetvalue'].values\n",
    "df_label=df['118'].values\n",
    "X=df.drop(['118'], axis=1).values \n",
    "y=df['118'].values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cdf9ac9",
   "metadata": {},
   "source": [
    "y.to_csv('normallabel1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9102d075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000 Training sequences (28000, 117)\n",
      "12000 Validation sequences (12000, 117)\n",
      "28000 Training sequences (28000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(X,y,train_size=0.70, random_state=2)\n",
    "print(len(x_train), \"Training sequences\",x_train.shape)\n",
    "print(len(x_val), \"Validation sequences\",x_val.shape)\n",
    "print(len(y_train), \"Training sequences\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b48862b",
   "metadata": {},
   "source": [
    "# attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0b8542",
   "metadata": {},
   "source": [
    "#https://stackoverflow.com/questions/53867351/how-to-visualize-attention-weights#:~:text=On%20loading%20saved%20model%20you,attention%20layer%20output%20on%20predict.&text=Now%20you%20can%20get%20the,and%20also%20the%20attention%20vector.&text=To%20summarize%20you%20need%20to,rgb%20or%20hex%20and%20visualise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34b09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation,RepeatVector,Permute \n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "maxlen=117\n",
    "vocab_size = x_train.shape[0]\n",
    "visible = layers.Input(shape=(maxlen,))\n",
    "\n",
    "embed=Embedding(vocab_size,117)(visible)\n",
    "\n",
    "activations= keras.layers.GRU(117, return_sequences=True)(embed)\n",
    "\n",
    "attention = TimeDistributed(Dense(1, activation='tanh'))(activations) \n",
    "attention = Flatten()(attention)\n",
    "attention = Activation('softmax', name='attention_vec')(attention)\n",
    "#attention = RepeatVector(1)(attention)\n",
    "#attention = Permute([2, 1])(attention) \n",
    "\n",
    "#sent_representation = keras.layers.multiply([activations, attention])\n",
    "#sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",
    "predictions=Dense(1, activation='sigmoid')(attention)\n",
    "\n",
    "model = keras.Model(inputs=visible, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b31bfb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 117)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 117, 117)          3276000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 117, 117)          82836     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 117, 1)            118       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 117)               0         \n",
      "_________________________________________________________________\n",
      "attention_vec (Activation)   (None, 117)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 118       \n",
      "=================================================================\n",
      "Total params: 3,359,072\n",
      "Trainable params: 3,359,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70e32d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5bf8c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "28000/28000 [==============================] - 104s 4ms/sample - loss: 0.6747 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "28000/28000 [==============================] - 105s 4ms/sample - loss: 0.6449 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "28000/28000 [==============================] - 107s 4ms/sample - loss: 0.6132 - accuracy: 1.0000 - val_loss: 0.5972 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "28000/28000 [==============================] - 104s 4ms/sample - loss: 0.5838 - accuracy: 1.0000 - val_loss: 0.5691 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "28000/28000 [==============================] - 99s 4ms/sample - loss: 0.5577 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, batch_size=1024, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edf67837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0h 8m 49s\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "\n",
    "diff = (end - start)\n",
    "\n",
    "datetime.timedelta(seconds=10, microseconds=885206)\n",
    "\n",
    "diff_seconds = int(diff.total_seconds())\n",
    "\n",
    "minute_seconds, seconds = divmod(diff_seconds, 60)\n",
    "hours, minutes = divmod(minute_seconds, 60)\n",
    "hms = f\"{hours}h {minutes}m {seconds}s\"\n",
    "\n",
    "'0h 0m 10s'\n",
    "print(hms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5e3ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=model.input,\n",
    "              outputs=[model.output, model.get_layer('attention_vec').output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcf0d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.get_layer('attention_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ff368ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[0.00660017, 0.01455546, 0.026004  , ..., 0.00380232, 0.00380038,\n",
      "        0.00380037],\n",
      "       [0.00591817, 0.01305142, 0.02331697, ..., 0.00340768, 0.00340768,\n",
      "        0.00340768],\n",
      "       [0.00660017, 0.01455546, 0.026004  , ..., 0.00380232, 0.00380038,\n",
      "        0.00380037],\n",
      "       ...,\n",
      "       [0.00660017, 0.01455546, 0.026004  , ..., 0.00380232, 0.00380038,\n",
      "        0.00380037],\n",
      "       [0.00660017, 0.01455546, 0.026004  , ..., 0.00380232, 0.00380038,\n",
      "        0.00380037],\n",
      "       [0.00743183, 0.01638953, 0.02928065, ..., 0.00429484, 0.00427927,\n",
      "        0.00427924]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K\n",
    "outputs = []\n",
    "keras_function = K.function([model.input], [layer.output])\n",
    "outputs.append(keras_function([x_train, 0]))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10ad2e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.00766108, 0.00766328, 0.00766108, ..., 0.00766108, 0.02082498,\n",
      "        0.00766108],\n",
      "       [0.00775497, 0.00775604, 0.00775497, ..., 0.00775497, 0.02108018,\n",
      "        0.00775497],\n",
      "       [0.00773701, 0.00773965, 0.00773701, ..., 0.00773701, 0.02103138,\n",
      "        0.00773701],\n",
      "       ...,\n",
      "       [0.00773651, 0.00775367, 0.0077365 , ..., 0.0077365 , 0.02102999,\n",
      "        0.0077365 ],\n",
      "       [0.00770576, 0.00770663, 0.00770576, ..., 0.00770576, 0.02094642,\n",
      "        0.00770576],\n",
      "       [0.00730165, 0.00730165, 0.00730165, ..., 0.00730165, 0.00730165,\n",
      "        0.00730165]], dtype=float32)]\n",
      "(1, 40000, 117)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "hidden_layers = keras.backend.function(\n",
    "[layer.input],  # we will feed the function with the input of the first layer  \n",
    "[layer.output,] # we want to get the output of the first layer\n",
    ")\n",
    "h=hidden_layers([X])\n",
    "print(h)\n",
    "print(np.shape(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5290e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.concatenate(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c79b65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('normalattentionvector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bde13f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_1 = pd.read_csv('normalattentionvector.csv', header=None)\n",
    "csv_2 = pd.read_csv('normallabel1.csv', header=None)\n",
    "\n",
    "result = pd.concat([csv_1, csv_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78a9ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"attentionnormalresult.csv\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347d43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
