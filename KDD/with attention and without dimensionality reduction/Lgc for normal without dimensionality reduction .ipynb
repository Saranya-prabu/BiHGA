{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading libraries \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(precision=3)\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "colnames = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "            \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\"num_access_files\",\n",
    "            \"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\n",
    "            \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\n",
    "            \"dst_host_count\",\"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "            \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\n",
    "            \"dst_host_srv_rerror_rate\",\"result\"]\n",
    "print(len(colnames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "train = pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\feature selection\\datasets\\kddcup 1999\\kddcup_data_corrected.csv\",header=None,names=colnames)\n",
    "#print(type(train))\n",
    "#test = pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\feature selection\\datasets\\kddcup 1999\\corrected.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_shells</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <th>is_host_login</th>\n",
       "      <th>is_guest_login</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>215</td>\n",
       "      <td>45076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>162</td>\n",
       "      <td>4528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>236</td>\n",
       "      <td>1228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>233</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        215      45076     0   \n",
       "1         0           tcp    http   SF        162       4528     0   \n",
       "2         0           tcp    http   SF        236       1228     0   \n",
       "3         0           tcp    http   SF        233       2032     0   \n",
       "4         0           tcp    http   SF        239        486     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  num_failed_logins  logged_in  num_compromised  \\\n",
       "0               0       0    0                  0          1                0   \n",
       "1               0       0    0                  0          1                0   \n",
       "2               0       0    0                  0          1                0   \n",
       "3               0       0    0                  0          1                0   \n",
       "4               0       0    0                  0          1                0   \n",
       "\n",
       "   root_shell  su_attempted  num_root  num_file_creations  num_shells  \\\n",
       "0           0             0         0                   0           0   \n",
       "1           0             0         0                   0           0   \n",
       "2           0             0         0                   0           0   \n",
       "3           0             0         0                   0           0   \n",
       "4           0             0         0                   0           0   \n",
       "\n",
       "   num_access_files  num_outbound_cmds  is_host_login  is_guest_login  count  \\\n",
       "0                 0                  0              0               0      1   \n",
       "1                 0                  0              0               0      2   \n",
       "2                 0                  0              0               0      1   \n",
       "3                 0                  0              0               0      2   \n",
       "4                 0                  0              0               0      3   \n",
       "\n",
       "   srv_count  serror_rate  srv_serror_rate  rerror_rate  srv_rerror_rate  \\\n",
       "0          1          0.0              0.0          0.0              0.0   \n",
       "1          2          0.0              0.0          0.0              0.0   \n",
       "2          1          0.0              0.0          0.0              0.0   \n",
       "3          2          0.0              0.0          0.0              0.0   \n",
       "4          3          0.0              0.0          0.0              0.0   \n",
       "\n",
       "   same_srv_rate  diff_srv_rate  srv_diff_host_rate  dst_host_count  \\\n",
       "0            1.0            0.0                 0.0               0   \n",
       "1            1.0            0.0                 0.0               1   \n",
       "2            1.0            0.0                 0.0               2   \n",
       "3            1.0            0.0                 0.0               3   \n",
       "4            1.0            0.0                 0.0               4   \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                   0                     0.0                     0.0   \n",
       "1                   1                     1.0                     0.0   \n",
       "2                   2                     1.0                     0.0   \n",
       "3                   3                     1.0                     0.0   \n",
       "4                   4                     1.0                     0.0   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.00                          0.0   \n",
       "1                         1.00                          0.0   \n",
       "2                         0.50                          0.0   \n",
       "3                         0.33                          0.0   \n",
       "4                         0.25                          0.0   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                   0.0   \n",
       "1                   0.0                       0.0                   0.0   \n",
       "2                   0.0                       0.0                   0.0   \n",
       "3                   0.0                       0.0                   0.0   \n",
       "4                   0.0                       0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate   result  \n",
       "0                       0.0  normal.  \n",
       "1                       0.0  normal.  \n",
       "2                       0.0  normal.  \n",
       "3                       0.0  normal.  \n",
       "4                       0.0  normal.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data has 1048576 rows and 42 columns\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "print ('The train data has {0} rows and {1} columns'.format(train.shape[0],train.shape[1]))\n",
    "print ('----------------------------')\n",
    "#print ('The test data has {0} rows and {1} columns'.format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal.             595798\n",
       "smurf.              227524\n",
       "neptune.            204815\n",
       "ipsweep.              7579\n",
       "satan.                5393\n",
       "portsweep.            2782\n",
       "nmap.                 2316\n",
       "back.                 2002\n",
       "teardrop.              199\n",
       "guess_passwd.           53\n",
       "pod.                    40\n",
       "warezmaster.            20\n",
       "land.                   17\n",
       "imap.                   12\n",
       "ftp_write.               8\n",
       "multihop.                6\n",
       "buffer_overflow.         5\n",
       "phf.                     3\n",
       "loadmodule.              2\n",
       "perl.                    2\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048576 entries, 0 to 1048575\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   duration                     1048576 non-null  int64  \n",
      " 1   protocol_type                1048576 non-null  object \n",
      " 2   service                      1048576 non-null  object \n",
      " 3   flag                         1048576 non-null  object \n",
      " 4   src_bytes                    1048576 non-null  int64  \n",
      " 5   dst_bytes                    1048576 non-null  int64  \n",
      " 6   land                         1048576 non-null  int64  \n",
      " 7   wrong_fragment               1048576 non-null  int64  \n",
      " 8   urgent                       1048576 non-null  int64  \n",
      " 9   hot                          1048576 non-null  int64  \n",
      " 10  num_failed_logins            1048576 non-null  int64  \n",
      " 11  logged_in                    1048576 non-null  int64  \n",
      " 12  num_compromised              1048576 non-null  int64  \n",
      " 13  root_shell                   1048576 non-null  int64  \n",
      " 14  su_attempted                 1048576 non-null  int64  \n",
      " 15  num_root                     1048576 non-null  int64  \n",
      " 16  num_file_creations           1048576 non-null  int64  \n",
      " 17  num_shells                   1048576 non-null  int64  \n",
      " 18  num_access_files             1048576 non-null  int64  \n",
      " 19  num_outbound_cmds            1048576 non-null  int64  \n",
      " 20  is_host_login                1048576 non-null  int64  \n",
      " 21  is_guest_login               1048576 non-null  int64  \n",
      " 22  count                        1048576 non-null  int64  \n",
      " 23  srv_count                    1048576 non-null  int64  \n",
      " 24  serror_rate                  1048576 non-null  float64\n",
      " 25  srv_serror_rate              1048576 non-null  float64\n",
      " 26  rerror_rate                  1048576 non-null  float64\n",
      " 27  srv_rerror_rate              1048576 non-null  float64\n",
      " 28  same_srv_rate                1048576 non-null  float64\n",
      " 29  diff_srv_rate                1048576 non-null  float64\n",
      " 30  srv_diff_host_rate           1048576 non-null  float64\n",
      " 31  dst_host_count               1048576 non-null  int64  \n",
      " 32  dst_host_srv_count           1048576 non-null  int64  \n",
      " 33  dst_host_same_srv_rate       1048576 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       1048576 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  1048576 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  1048576 non-null  float64\n",
      " 37  dst_host_serror_rate         1048576 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     1048576 non-null  float64\n",
      " 39  dst_host_rerror_rate         1048576 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     1048576 non-null  float64\n",
      " 41  result                       1048576 non-null  object \n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 336.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration                       False\n",
      "protocol_type                  False\n",
      "service                        False\n",
      "flag                           False\n",
      "src_bytes                      False\n",
      "dst_bytes                      False\n",
      "land                           False\n",
      "wrong_fragment                 False\n",
      "urgent                         False\n",
      "hot                            False\n",
      "num_failed_logins              False\n",
      "logged_in                      False\n",
      "num_compromised                False\n",
      "root_shell                     False\n",
      "su_attempted                   False\n",
      "num_root                       False\n",
      "num_file_creations             False\n",
      "num_shells                     False\n",
      "num_access_files               False\n",
      "num_outbound_cmds              False\n",
      "is_host_login                  False\n",
      "is_guest_login                 False\n",
      "count                          False\n",
      "srv_count                      False\n",
      "serror_rate                    False\n",
      "srv_serror_rate                False\n",
      "rerror_rate                    False\n",
      "srv_rerror_rate                False\n",
      "same_srv_rate                  False\n",
      "diff_srv_rate                  False\n",
      "srv_diff_host_rate             False\n",
      "dst_host_count                 False\n",
      "dst_host_srv_count             False\n",
      "dst_host_same_srv_rate         False\n",
      "dst_host_diff_srv_rate         False\n",
      "dst_host_same_src_port_rate    False\n",
      "dst_host_srv_diff_host_rate    False\n",
      "dst_host_serror_rate           False\n",
      "dst_host_srv_serror_rate       False\n",
      "dst_host_rerror_rate           False\n",
      "dst_host_srv_rerror_rate       False\n",
      "result                         False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#check missing values\n",
    "train.columns[train.isnull().any()]\n",
    "#print(len(train))\n",
    "print(train.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration                       0.0\n",
      "protocol_type                  0.0\n",
      "service                        0.0\n",
      "flag                           0.0\n",
      "src_bytes                      0.0\n",
      "dst_bytes                      0.0\n",
      "land                           0.0\n",
      "wrong_fragment                 0.0\n",
      "urgent                         0.0\n",
      "hot                            0.0\n",
      "num_failed_logins              0.0\n",
      "logged_in                      0.0\n",
      "num_compromised                0.0\n",
      "root_shell                     0.0\n",
      "su_attempted                   0.0\n",
      "num_root                       0.0\n",
      "num_file_creations             0.0\n",
      "num_shells                     0.0\n",
      "num_access_files               0.0\n",
      "num_outbound_cmds              0.0\n",
      "is_host_login                  0.0\n",
      "is_guest_login                 0.0\n",
      "count                          0.0\n",
      "srv_count                      0.0\n",
      "serror_rate                    0.0\n",
      "srv_serror_rate                0.0\n",
      "rerror_rate                    0.0\n",
      "srv_rerror_rate                0.0\n",
      "same_srv_rate                  0.0\n",
      "diff_srv_rate                  0.0\n",
      "srv_diff_host_rate             0.0\n",
      "dst_host_count                 0.0\n",
      "dst_host_srv_count             0.0\n",
      "dst_host_same_srv_rate         0.0\n",
      "dst_host_diff_srv_rate         0.0\n",
      "dst_host_same_src_port_rate    0.0\n",
      "dst_host_srv_diff_host_rate    0.0\n",
      "dst_host_serror_rate           0.0\n",
      "dst_host_srv_serror_rate       0.0\n",
      "dst_host_rerror_rate           0.0\n",
      "dst_host_srv_rerror_rate       0.0\n",
      "result                         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#missing value counts in each of these columns\n",
    "miss = train.isnull().sum()/len(train)\n",
    "if(miss.sum()==0.0):\n",
    "    print(miss)\n",
    "#print(train.isnull().sum())\n",
    "else:\n",
    "    miss = miss[miss > 0]\n",
    "    miss.sort_values(inplace=True)\n",
    "    miss\n",
    "    print('missing values are'.format(miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no missing values\n",
      "duration         0.0\n",
      "protocol_type    0.0\n",
      "service          0.0\n",
      "flag             0.0\n",
      "src_bytes        0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#visualising missing values\n",
    "#df = pd.DataFrame()\n",
    "#df.to_frame()\n",
    "#miss = pd.DataFrame()\n",
    "#miss.drop_duplicates()\n",
    "if(miss.sum()==0.0):\n",
    "    print(\"There is no missing values\")\n",
    "    print(miss.head())\n",
    "else:    \n",
    "    miss.to_frame()\n",
    "    miss.columns = ['count']\n",
    "    miss.index.names = ['Name']\n",
    "    miss['Name'] = miss.index\n",
    "\n",
    "#plot the missing value count\n",
    "#if(miss.columns!=0):\n",
    "    sns.set(style=\"whitegrid\", color_codes=True)\n",
    "    sns.barplot(x = 'Name', y = ['count'], data=miss)\n",
    "#sns.boxplot, 'species', 'value', x='species', y='value')\n",
    "    plt.xticks(rotation = 90)\n",
    "    sns.plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_shells</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <th>is_host_login</th>\n",
       "      <th>is_guest_login</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1048576.0</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "      <td>1.048576e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.234529e+00</td>\n",
       "      <td>1.640730e+03</td>\n",
       "      <td>2.355018e+03</td>\n",
       "      <td>1.621246e-05</td>\n",
       "      <td>6.036758e-04</td>\n",
       "      <td>1.907349e-05</td>\n",
       "      <td>3.145885e-02</td>\n",
       "      <td>1.173019e-04</td>\n",
       "      <td>5.073900e-01</td>\n",
       "      <td>1.439762e-02</td>\n",
       "      <td>2.384186e-04</td>\n",
       "      <td>8.296967e-05</td>\n",
       "      <td>2.419853e-02</td>\n",
       "      <td>2.906799e-03</td>\n",
       "      <td>1.611710e-04</td>\n",
       "      <td>2.755165e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>2.112389e-03</td>\n",
       "      <td>1.546366e+02</td>\n",
       "      <td>1.203271e+02</td>\n",
       "      <td>1.975607e-01</td>\n",
       "      <td>1.977609e-01</td>\n",
       "      <td>2.475420e-02</td>\n",
       "      <td>2.496099e-02</td>\n",
       "      <td>8.094793e-01</td>\n",
       "      <td>2.117072e-02</td>\n",
       "      <td>8.426697e-02</td>\n",
       "      <td>1.839691e+02</td>\n",
       "      <td>1.864760e+02</td>\n",
       "      <td>7.602534e-01</td>\n",
       "      <td>2.824197e-02</td>\n",
       "      <td>2.744349e-01</td>\n",
       "      <td>1.760540e-02</td>\n",
       "      <td>1.975058e-01</td>\n",
       "      <td>1.972018e-01</td>\n",
       "      <td>2.517304e-02</td>\n",
       "      <td>2.455191e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.285165e+02</td>\n",
       "      <td>6.781544e+05</td>\n",
       "      <td>3.174638e+04</td>\n",
       "      <td>4.026440e-03</td>\n",
       "      <td>4.159995e-02</td>\n",
       "      <td>7.042070e-03</td>\n",
       "      <td>7.063307e-01</td>\n",
       "      <td>1.370621e-02</td>\n",
       "      <td>4.999456e-01</td>\n",
       "      <td>2.439982e+00</td>\n",
       "      <td>1.543898e-02</td>\n",
       "      <td>1.215783e-02</td>\n",
       "      <td>2.738431e+00</td>\n",
       "      <td>1.917875e-01</td>\n",
       "      <td>1.299133e-02</td>\n",
       "      <td>5.706872e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.765625e-04</td>\n",
       "      <td>4.591218e-02</td>\n",
       "      <td>2.033122e+02</td>\n",
       "      <td>2.057385e+02</td>\n",
       "      <td>3.972186e-01</td>\n",
       "      <td>3.974836e-01</td>\n",
       "      <td>1.535523e-01</td>\n",
       "      <td>1.535197e-01</td>\n",
       "      <td>3.767900e-01</td>\n",
       "      <td>9.170193e-02</td>\n",
       "      <td>2.235659e-01</td>\n",
       "      <td>9.889551e+01</td>\n",
       "      <td>1.041205e+02</td>\n",
       "      <td>3.981472e-01</td>\n",
       "      <td>9.997035e-02</td>\n",
       "      <td>4.219412e-01</td>\n",
       "      <td>5.819577e-02</td>\n",
       "      <td>3.969704e-01</td>\n",
       "      <td>3.974174e-01</td>\n",
       "      <td>1.509611e-01</td>\n",
       "      <td>1.512144e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.100000e+01</td>\n",
       "      <td>7.500000e+01</td>\n",
       "      <td>5.600000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.480000e+02</td>\n",
       "      <td>1.210000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.032000e+03</td>\n",
       "      <td>1.398000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.610000e+02</td>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>5.200000e-01</td>\n",
       "      <td>2.000000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.832900e+04</td>\n",
       "      <td>6.933756e+08</td>\n",
       "      <td>1.173059e+07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.840000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.750000e+02</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.110000e+02</td>\n",
       "      <td>5.110000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes          land  wrong_fragment  \\\n",
       "count  1.048576e+06  1.048576e+06  1.048576e+06  1.048576e+06    1.048576e+06   \n",
       "mean   4.234529e+00  1.640730e+03  2.355018e+03  1.621246e-05    6.036758e-04   \n",
       "std    2.285165e+02  6.781544e+05  3.174638e+04  4.026440e-03    4.159995e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00    0.000000e+00   \n",
       "25%    0.000000e+00  4.300000e+01  0.000000e+00  0.000000e+00    0.000000e+00   \n",
       "50%    0.000000e+00  2.480000e+02  1.210000e+02  0.000000e+00    0.000000e+00   \n",
       "75%    0.000000e+00  1.032000e+03  1.398000e+03  0.000000e+00    0.000000e+00   \n",
       "max    5.832900e+04  6.933756e+08  1.173059e+07  1.000000e+00    3.000000e+00   \n",
       "\n",
       "             urgent           hot  num_failed_logins     logged_in  \\\n",
       "count  1.048576e+06  1.048576e+06       1.048576e+06  1.048576e+06   \n",
       "mean   1.907349e-05  3.145885e-02       1.173019e-04  5.073900e-01   \n",
       "std    7.042070e-03  7.063307e-01       1.370621e-02  4.999456e-01   \n",
       "min    0.000000e+00  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00       0.000000e+00  1.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00       0.000000e+00  1.000000e+00   \n",
       "max    5.000000e+00  7.700000e+01       5.000000e+00  1.000000e+00   \n",
       "\n",
       "       num_compromised    root_shell  su_attempted      num_root  \\\n",
       "count     1.048576e+06  1.048576e+06  1.048576e+06  1.048576e+06   \n",
       "mean      1.439762e-02  2.384186e-04  8.296967e-05  2.419853e-02   \n",
       "std       2.439982e+00  1.543898e-02  1.215783e-02  2.738431e+00   \n",
       "min       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max       8.840000e+02  1.000000e+00  2.000000e+00  9.750000e+02   \n",
       "\n",
       "       num_file_creations    num_shells  num_access_files  num_outbound_cmds  \\\n",
       "count        1.048576e+06  1.048576e+06      1.048576e+06          1048576.0   \n",
       "mean         2.906799e-03  1.611710e-04      2.755165e-03                0.0   \n",
       "std          1.917875e-01  1.299133e-02      5.706872e-02                0.0   \n",
       "min          0.000000e+00  0.000000e+00      0.000000e+00                0.0   \n",
       "25%          0.000000e+00  0.000000e+00      0.000000e+00                0.0   \n",
       "50%          0.000000e+00  0.000000e+00      0.000000e+00                0.0   \n",
       "75%          0.000000e+00  0.000000e+00      0.000000e+00                0.0   \n",
       "max          4.000000e+01  2.000000e+00      9.000000e+00                0.0   \n",
       "\n",
       "       is_host_login  is_guest_login         count     srv_count  \\\n",
       "count   1.048576e+06    1.048576e+06  1.048576e+06  1.048576e+06   \n",
       "mean    9.536743e-07    2.112389e-03  1.546366e+02  1.203271e+02   \n",
       "std     9.765625e-04    4.591218e-02  2.033122e+02  2.057385e+02   \n",
       "min     0.000000e+00    0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%     0.000000e+00    0.000000e+00  4.000000e+00  4.000000e+00   \n",
       "50%     0.000000e+00    0.000000e+00  1.800000e+01  1.200000e+01   \n",
       "75%     0.000000e+00    0.000000e+00  2.610000e+02  3.700000e+01   \n",
       "max     1.000000e+00    1.000000e+00  5.110000e+02  5.110000e+02   \n",
       "\n",
       "        serror_rate  srv_serror_rate   rerror_rate  srv_rerror_rate  \\\n",
       "count  1.048576e+06     1.048576e+06  1.048576e+06     1.048576e+06   \n",
       "mean   1.975607e-01     1.977609e-01  2.475420e-02     2.496099e-02   \n",
       "std    3.972186e-01     3.974836e-01  1.535523e-01     1.535197e-01   \n",
       "min    0.000000e+00     0.000000e+00  0.000000e+00     0.000000e+00   \n",
       "25%    0.000000e+00     0.000000e+00  0.000000e+00     0.000000e+00   \n",
       "50%    0.000000e+00     0.000000e+00  0.000000e+00     0.000000e+00   \n",
       "75%    0.000000e+00     0.000000e+00  0.000000e+00     0.000000e+00   \n",
       "max    1.000000e+00     1.000000e+00  1.000000e+00     1.000000e+00   \n",
       "\n",
       "       same_srv_rate  diff_srv_rate  srv_diff_host_rate  dst_host_count  \\\n",
       "count   1.048576e+06   1.048576e+06        1.048576e+06    1.048576e+06   \n",
       "mean    8.094793e-01   2.117072e-02        8.426697e-02    1.839691e+02   \n",
       "std     3.767900e-01   9.170193e-02        2.235659e-01    9.889551e+01   \n",
       "min     0.000000e+00   0.000000e+00        0.000000e+00    0.000000e+00   \n",
       "25%     1.000000e+00   0.000000e+00        0.000000e+00    8.100000e+01   \n",
       "50%     1.000000e+00   0.000000e+00        0.000000e+00    2.550000e+02   \n",
       "75%     1.000000e+00   0.000000e+00        0.000000e+00    2.550000e+02   \n",
       "max     1.000000e+00   1.000000e+00        1.000000e+00    2.550000e+02   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count        1.048576e+06            1.048576e+06            1.048576e+06   \n",
       "mean         1.864760e+02            7.602534e-01            2.824197e-02   \n",
       "std          1.041205e+02            3.981472e-01            9.997035e-02   \n",
       "min          0.000000e+00            0.000000e+00            0.000000e+00   \n",
       "25%          7.500000e+01            5.600000e-01            0.000000e+00   \n",
       "50%          2.550000e+02            1.000000e+00            0.000000e+00   \n",
       "75%          2.550000e+02            1.000000e+00            4.000000e-02   \n",
       "max          2.550000e+02            1.000000e+00            1.000000e+00   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                 1.048576e+06                 1.048576e+06   \n",
       "mean                  2.744349e-01                 1.760540e-02   \n",
       "std                   4.219412e-01                 5.819577e-02   \n",
       "min                   0.000000e+00                 0.000000e+00   \n",
       "25%                   0.000000e+00                 0.000000e+00   \n",
       "50%                   1.000000e-02                 0.000000e+00   \n",
       "75%                   5.200000e-01                 2.000000e-02   \n",
       "max                   1.000000e+00                 1.000000e+00   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count          1.048576e+06              1.048576e+06          1.048576e+06   \n",
       "mean           1.975058e-01              1.972018e-01          2.517304e-02   \n",
       "std            3.969704e-01              3.974174e-01          1.509611e-01   \n",
       "min            0.000000e+00              0.000000e+00          0.000000e+00   \n",
       "25%            0.000000e+00              0.000000e+00          0.000000e+00   \n",
       "50%            0.000000e+00              0.000000e+00          0.000000e+00   \n",
       "75%            0.000000e+00              0.000000e+00          0.000000e+00   \n",
       "max            1.000000e+00              1.000000e+00          1.000000e+00   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count              1.048576e+06  \n",
       "mean               2.455191e-02  \n",
       "std                1.512144e-01  \n",
       "min                0.000000e+00  \n",
       "25%                0.000000e+00  \n",
       "50%                0.000000e+00  \n",
       "75%                0.000000e+00  \n",
       "max                1.000000e+00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics\n",
    "train.describe()\n",
    "#If there is any redundant column, remove it from both train & test datasets\n",
    "#Since there is no zeros for all statistical values,it doesn't contain redundant column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will be extracting all the features as a \"priori\" for preprocessing\n",
    "features = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "            \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\"num_access_files\",\n",
    "            \"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\n",
    "            \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\n",
    "            \"dst_host_count\",\"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "            \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\n",
    "            \"dst_host_srv_rerror_rate\"]\n",
    "target = \"result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048576, 42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = train.loc[:,features]\n",
    "y1 = train.loc[:,target]\n",
    "train.shape\n",
    "#test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['back.' 'buffer_overflow.' 'ftp_write.' 'guess_passwd.' 'imap.'\n",
      " 'ipsweep.' 'land.' 'loadmodule.' 'multihop.' 'neptune.' 'nmap.' 'normal.'\n",
      " 'perl.' 'phf.' 'pod.' 'portsweep.' 'satan.' 'smurf.' 'teardrop.'\n",
      " 'warezmaster.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "normal.             595798\n",
       "smurf.              227524\n",
       "neptune.            204815\n",
       "ipsweep.              7579\n",
       "satan.                5393\n",
       "portsweep.            2782\n",
       "nmap.                 2316\n",
       "back.                 2002\n",
       "teardrop.              199\n",
       "guess_passwd.           53\n",
       "pod.                    40\n",
       "warezmaster.            20\n",
       "land.                   17\n",
       "imap.                   12\n",
       "ftp_write.               8\n",
       "multihop.                6\n",
       "buffer_overflow.         5\n",
       "phf.                     3\n",
       "loadmodule.              2\n",
       "perl.                    2\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.unique(y1)\n",
    "print(classes)\n",
    "# Attack Class Distribution\n",
    "train['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_shells</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <th>is_host_login</th>\n",
       "      <th>is_guest_login</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>215</td>\n",
       "      <td>45076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>162</td>\n",
       "      <td>4528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>236</td>\n",
       "      <td>1228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>233</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        215      45076     0   \n",
       "1         0           tcp    http   SF        162       4528     0   \n",
       "2         0           tcp    http   SF        236       1228     0   \n",
       "3         0           tcp    http   SF        233       2032     0   \n",
       "4         0           tcp    http   SF        239        486     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  num_failed_logins  logged_in  num_compromised  \\\n",
       "0               0       0    0                  0          1                0   \n",
       "1               0       0    0                  0          1                0   \n",
       "2               0       0    0                  0          1                0   \n",
       "3               0       0    0                  0          1                0   \n",
       "4               0       0    0                  0          1                0   \n",
       "\n",
       "   root_shell  su_attempted  num_root  num_file_creations  num_shells  \\\n",
       "0           0             0         0                   0           0   \n",
       "1           0             0         0                   0           0   \n",
       "2           0             0         0                   0           0   \n",
       "3           0             0         0                   0           0   \n",
       "4           0             0         0                   0           0   \n",
       "\n",
       "   num_access_files  num_outbound_cmds  is_host_login  is_guest_login  count  \\\n",
       "0                 0                  0              0               0      1   \n",
       "1                 0                  0              0               0      2   \n",
       "2                 0                  0              0               0      1   \n",
       "3                 0                  0              0               0      2   \n",
       "4                 0                  0              0               0      3   \n",
       "\n",
       "   srv_count  serror_rate  srv_serror_rate  rerror_rate  srv_rerror_rate  \\\n",
       "0          1          0.0              0.0          0.0              0.0   \n",
       "1          2          0.0              0.0          0.0              0.0   \n",
       "2          1          0.0              0.0          0.0              0.0   \n",
       "3          2          0.0              0.0          0.0              0.0   \n",
       "4          3          0.0              0.0          0.0              0.0   \n",
       "\n",
       "   same_srv_rate  diff_srv_rate  srv_diff_host_rate  dst_host_count  \\\n",
       "0            1.0            0.0                 0.0               0   \n",
       "1            1.0            0.0                 0.0               1   \n",
       "2            1.0            0.0                 0.0               2   \n",
       "3            1.0            0.0                 0.0               3   \n",
       "4            1.0            0.0                 0.0               4   \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                   0                     0.0                     0.0   \n",
       "1                   1                     1.0                     0.0   \n",
       "2                   2                     1.0                     0.0   \n",
       "3                   3                     1.0                     0.0   \n",
       "4                   4                     1.0                     0.0   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.00                          0.0   \n",
       "1                         1.00                          0.0   \n",
       "2                         0.50                          0.0   \n",
       "3                         0.33                          0.0   \n",
       "4                         0.25                          0.0   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                   0.0   \n",
       "1                   0.0                       0.0                   0.0   \n",
       "2                   0.0                       0.0                   0.0   \n",
       "3                   0.0                       0.0                   0.0   \n",
       "4                   0.0                       0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  result  \n",
       "0                       0.0  normal  \n",
       "1                       0.0  normal  \n",
       "2                       0.0  normal  \n",
       "3                       0.0  normal  \n",
       "4                       0.0  normal  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing all classes of attack with 1 and normal result with 0 in our icmp_df\n",
    "for i in range(len(classes)):\n",
    "    if classes[i] == \"normal.\":\n",
    "        train = train.replace(classes[i], 0)\n",
    "  #      data[\"Team\"]= data[\"Team\"].str.replace(\"boston\", \"New Boston\", case = False) \n",
    "    else:\n",
    "        train = train.replace(classes[i], 1)\n",
    "\n",
    "#train\n",
    "\n",
    "train[\"result\"] = train[\"result\"].replace(0, \"normal\")\n",
    "train[\"result\"] = train[\"result\"].replace(1, \"abnormal\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal      595798\n",
       "abnormal    452778\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attack Class Distribution\n",
    "#print('0-normal \\t 1-abnorml')\n",
    "train['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 for normal data and 1 for abnormalities\n",
    "train.result=train.result.apply(lambda x: 0 if x == 'normal' else 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#randomly sample 500 data point for training\n",
    "train=train[train.result==0].sample(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Helper function for scaling continous values\n",
    "def minmax_scale_values(train, col_name):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler = scaler.fit(train[col_name].values.reshape(-1, 1))\n",
    "    train_values_standardized = scaler.transform(train[col_name].values.reshape(-1, 1))\n",
    "    train[col_name] = train_values_standardized\n",
    "    #test_values_standardized = scaler.transform(test[col_name].values.reshape(-1, 1))\n",
    "    #test[col_name] = test_values_standardized\n",
    "    \n",
    "    \n",
    "#Helper function for one hot encoding\n",
    "def encode_text(train, name):\n",
    "    training_set_dummies = pd.get_dummies(train[name])\n",
    "    #testing_set_dummies = pd.get_dummies(test[name])\n",
    "    for x in training_set_dummies.columns:\n",
    "        dummy_name = \"{}_{}\".format(name, x)\n",
    "        train[dummy_name] = training_set_dummies[x]\n",
    "        #if x in testing_set_dummies.columns :\n",
    "        #    test[dummy_name]=testing_set_dummies[x]\n",
    "        #else :\n",
    "        #    test[dummy_name]=np.zeros(len(test))\n",
    "    train.drop(name, axis=1, inplace=True)\n",
    "    #test.drop(name, axis=1, inplace=True)\n",
    "             \n",
    "sympolic_columns=[\"protocol_type\",\"service\",\"flag\"]\n",
    "label_column=\"Class\"\n",
    "for column in train.columns :\n",
    "    if column in sympolic_columns:\n",
    "        encode_text(train,column)\n",
    "    elif not column == label_column:\n",
    "        minmax_scale_values(train, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly sample 500 data point for training\n",
    "train=train[train.result==0].sample(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_shells</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <th>is_host_login</th>\n",
       "      <th>is_guest_login</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>result</th>\n",
       "      <th>protocol_type_icmp</th>\n",
       "      <th>protocol_type_tcp</th>\n",
       "      <th>protocol_type_udp</th>\n",
       "      <th>service_IRC</th>\n",
       "      <th>service_X11</th>\n",
       "      <th>service_Z39_50</th>\n",
       "      <th>service_aol</th>\n",
       "      <th>service_auth</th>\n",
       "      <th>service_bgp</th>\n",
       "      <th>service_courier</th>\n",
       "      <th>service_csnet_ns</th>\n",
       "      <th>service_ctf</th>\n",
       "      <th>service_daytime</th>\n",
       "      <th>service_discard</th>\n",
       "      <th>service_domain</th>\n",
       "      <th>service_domain_u</th>\n",
       "      <th>service_echo</th>\n",
       "      <th>service_eco_i</th>\n",
       "      <th>service_ecr_i</th>\n",
       "      <th>service_efs</th>\n",
       "      <th>service_exec</th>\n",
       "      <th>service_finger</th>\n",
       "      <th>service_ftp</th>\n",
       "      <th>service_ftp_data</th>\n",
       "      <th>service_gopher</th>\n",
       "      <th>service_harvest</th>\n",
       "      <th>service_hostnames</th>\n",
       "      <th>service_http</th>\n",
       "      <th>service_http_2784</th>\n",
       "      <th>service_http_443</th>\n",
       "      <th>service_imap4</th>\n",
       "      <th>service_iso_tsap</th>\n",
       "      <th>service_klogin</th>\n",
       "      <th>service_kshell</th>\n",
       "      <th>service_ldap</th>\n",
       "      <th>service_link</th>\n",
       "      <th>service_login</th>\n",
       "      <th>service_mtp</th>\n",
       "      <th>service_name</th>\n",
       "      <th>service_netbios_dgm</th>\n",
       "      <th>service_netbios_ns</th>\n",
       "      <th>service_netbios_ssn</th>\n",
       "      <th>service_netstat</th>\n",
       "      <th>service_nnsp</th>\n",
       "      <th>service_nntp</th>\n",
       "      <th>service_ntp_u</th>\n",
       "      <th>service_other</th>\n",
       "      <th>service_pm_dump</th>\n",
       "      <th>service_pop_2</th>\n",
       "      <th>service_pop_3</th>\n",
       "      <th>service_printer</th>\n",
       "      <th>service_private</th>\n",
       "      <th>service_remote_job</th>\n",
       "      <th>service_rje</th>\n",
       "      <th>service_shell</th>\n",
       "      <th>service_smtp</th>\n",
       "      <th>service_sql_net</th>\n",
       "      <th>service_ssh</th>\n",
       "      <th>service_sunrpc</th>\n",
       "      <th>service_supdup</th>\n",
       "      <th>service_systat</th>\n",
       "      <th>service_telnet</th>\n",
       "      <th>service_time</th>\n",
       "      <th>service_urh_i</th>\n",
       "      <th>service_urp_i</th>\n",
       "      <th>service_uucp</th>\n",
       "      <th>service_uucp_path</th>\n",
       "      <th>service_vmnet</th>\n",
       "      <th>service_whois</th>\n",
       "      <th>flag_OTH</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249263</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.836304e-07</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020523</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.124748e-07</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252421</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.610418e-07</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031311</td>\n",
       "      <td>0.031311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828405</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.658370e-07</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031311</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.023793e-07</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         duration     src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "249263        0.0  3.836304e-07   0.000287   0.0             0.0     0.0  0.0   \n",
       "1020523       0.0  4.124748e-07   0.000139   0.0             0.0     0.0  0.0   \n",
       "252421        0.0  2.610418e-07   0.000341   0.0             0.0     0.0  0.0   \n",
       "828405        0.0  4.658370e-07   0.000037   0.0             0.0     0.0  0.0   \n",
       "824142        0.0  4.023793e-07   0.000968   0.0             0.0     0.0  0.0   \n",
       "\n",
       "         num_failed_logins  logged_in  num_compromised  root_shell  \\\n",
       "249263                 0.0        1.0              0.0         0.0   \n",
       "1020523                0.0        1.0              0.0         0.0   \n",
       "252421                 0.0        1.0              0.0         0.0   \n",
       "828405                 0.0        1.0              0.0         0.0   \n",
       "824142                 0.0        1.0              0.0         0.0   \n",
       "\n",
       "         su_attempted  num_root  num_file_creations  num_shells  \\\n",
       "249263            0.0       0.0                 0.0         0.0   \n",
       "1020523           0.0       0.0                 0.0         0.0   \n",
       "252421            0.0       0.0                 0.0         0.0   \n",
       "828405            0.0       0.0                 0.0         0.0   \n",
       "824142            0.0       0.0                 0.0         0.0   \n",
       "\n",
       "         num_access_files  num_outbound_cmds  is_host_login  is_guest_login  \\\n",
       "249263                0.0                0.0            0.0             0.0   \n",
       "1020523               0.0                0.0            0.0             0.0   \n",
       "252421                0.0                0.0            0.0             0.0   \n",
       "828405                0.0                0.0            0.0             0.0   \n",
       "824142                0.0                0.0            0.0             0.0   \n",
       "\n",
       "            count  srv_count  serror_rate  srv_serror_rate  rerror_rate  \\\n",
       "249263   0.003914   0.003914          0.0              0.0          0.0   \n",
       "1020523  0.005871   0.005871          0.0              0.0          0.0   \n",
       "252421   0.031311   0.031311          0.0              0.0          0.0   \n",
       "828405   0.031311   0.041096          0.0              0.0          0.0   \n",
       "824142   0.021526   0.021526          0.0              0.0          0.0   \n",
       "\n",
       "         srv_rerror_rate  same_srv_rate  diff_srv_rate  srv_diff_host_rate  \\\n",
       "249263               0.0            1.0            0.0                 0.0   \n",
       "1020523              0.0            1.0            0.0                 0.0   \n",
       "252421               0.0            1.0            0.0                 0.0   \n",
       "828405               0.0            1.0            0.0                 0.1   \n",
       "824142               0.0            1.0            0.0                 0.0   \n",
       "\n",
       "         dst_host_count  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
       "249263         0.909804            1.000000                     1.0   \n",
       "1020523        0.105882            0.894118                     1.0   \n",
       "252421         0.062745            1.000000                     1.0   \n",
       "828405         0.368627            1.000000                     1.0   \n",
       "824142         1.000000            1.000000                     1.0   \n",
       "\n",
       "         dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "249263                      0.0                         0.00   \n",
       "1020523                     0.0                         0.04   \n",
       "252421                      0.0                         0.06   \n",
       "828405                      0.0                         0.01   \n",
       "824142                      0.0                         0.00   \n",
       "\n",
       "         dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "249263                          0.01                   0.0   \n",
       "1020523                         0.03                   0.0   \n",
       "252421                          0.03                   0.0   \n",
       "828405                          0.02                   0.0   \n",
       "824142                          0.00                   0.0   \n",
       "\n",
       "         dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "249263                        0.0                   0.0   \n",
       "1020523                       0.0                   0.0   \n",
       "252421                        0.0                   0.0   \n",
       "828405                        0.0                   0.0   \n",
       "824142                        0.0                   0.0   \n",
       "\n",
       "         dst_host_srv_rerror_rate  result  protocol_type_icmp  \\\n",
       "249263                        0.0     0.0                   0   \n",
       "1020523                       0.0     0.0                   0   \n",
       "252421                        0.0     0.0                   0   \n",
       "828405                        0.0     0.0                   0   \n",
       "824142                        0.0     0.0                   0   \n",
       "\n",
       "         protocol_type_tcp  protocol_type_udp  service_IRC  service_X11  \\\n",
       "249263                   1                  0            0            0   \n",
       "1020523                  1                  0            0            0   \n",
       "252421                   1                  0            0            0   \n",
       "828405                   1                  0            0            0   \n",
       "824142                   1                  0            0            0   \n",
       "\n",
       "         service_Z39_50  service_aol  service_auth  service_bgp  \\\n",
       "249263                0            0             0            0   \n",
       "1020523               0            0             0            0   \n",
       "252421                0            0             0            0   \n",
       "828405                0            0             0            0   \n",
       "824142                0            0             0            0   \n",
       "\n",
       "         service_courier  service_csnet_ns  service_ctf  service_daytime  \\\n",
       "249263                 0                 0            0                0   \n",
       "1020523                0                 0            0                0   \n",
       "252421                 0                 0            0                0   \n",
       "828405                 0                 0            0                0   \n",
       "824142                 0                 0            0                0   \n",
       "\n",
       "         service_discard  service_domain  service_domain_u  service_echo  \\\n",
       "249263                 0               0                 0             0   \n",
       "1020523                0               0                 0             0   \n",
       "252421                 0               0                 0             0   \n",
       "828405                 0               0                 0             0   \n",
       "824142                 0               0                 0             0   \n",
       "\n",
       "         service_eco_i  service_ecr_i  service_efs  service_exec  \\\n",
       "249263               0              0            0             0   \n",
       "1020523              0              0            0             0   \n",
       "252421               0              0            0             0   \n",
       "828405               0              0            0             0   \n",
       "824142               0              0            0             0   \n",
       "\n",
       "         service_finger  service_ftp  service_ftp_data  service_gopher  \\\n",
       "249263                0            0                 0               0   \n",
       "1020523               0            0                 0               0   \n",
       "252421                0            0                 0               0   \n",
       "828405                0            0                 0               0   \n",
       "824142                0            0                 0               0   \n",
       "\n",
       "         service_harvest  service_hostnames  service_http  service_http_2784  \\\n",
       "249263                 0                  0             1                  0   \n",
       "1020523                0                  0             1                  0   \n",
       "252421                 0                  0             1                  0   \n",
       "828405                 0                  0             1                  0   \n",
       "824142                 0                  0             1                  0   \n",
       "\n",
       "         service_http_443  service_imap4  service_iso_tsap  service_klogin  \\\n",
       "249263                  0              0                 0               0   \n",
       "1020523                 0              0                 0               0   \n",
       "252421                  0              0                 0               0   \n",
       "828405                  0              0                 0               0   \n",
       "824142                  0              0                 0               0   \n",
       "\n",
       "         service_kshell  service_ldap  service_link  service_login  \\\n",
       "249263                0             0             0              0   \n",
       "1020523               0             0             0              0   \n",
       "252421                0             0             0              0   \n",
       "828405                0             0             0              0   \n",
       "824142                0             0             0              0   \n",
       "\n",
       "         service_mtp  service_name  service_netbios_dgm  service_netbios_ns  \\\n",
       "249263             0             0                    0                   0   \n",
       "1020523            0             0                    0                   0   \n",
       "252421             0             0                    0                   0   \n",
       "828405             0             0                    0                   0   \n",
       "824142             0             0                    0                   0   \n",
       "\n",
       "         service_netbios_ssn  service_netstat  service_nnsp  service_nntp  \\\n",
       "249263                     0                0             0             0   \n",
       "1020523                    0                0             0             0   \n",
       "252421                     0                0             0             0   \n",
       "828405                     0                0             0             0   \n",
       "824142                     0                0             0             0   \n",
       "\n",
       "         service_ntp_u  service_other  service_pm_dump  service_pop_2  \\\n",
       "249263               0              0                0              0   \n",
       "1020523              0              0                0              0   \n",
       "252421               0              0                0              0   \n",
       "828405               0              0                0              0   \n",
       "824142               0              0                0              0   \n",
       "\n",
       "         service_pop_3  service_printer  service_private  service_remote_job  \\\n",
       "249263               0                0                0                   0   \n",
       "1020523              0                0                0                   0   \n",
       "252421               0                0                0                   0   \n",
       "828405               0                0                0                   0   \n",
       "824142               0                0                0                   0   \n",
       "\n",
       "         service_rje  service_shell  service_smtp  service_sql_net  \\\n",
       "249263             0              0             0                0   \n",
       "1020523            0              0             0                0   \n",
       "252421             0              0             0                0   \n",
       "828405             0              0             0                0   \n",
       "824142             0              0             0                0   \n",
       "\n",
       "         service_ssh  service_sunrpc  service_supdup  service_systat  \\\n",
       "249263             0               0               0               0   \n",
       "1020523            0               0               0               0   \n",
       "252421             0               0               0               0   \n",
       "828405             0               0               0               0   \n",
       "824142             0               0               0               0   \n",
       "\n",
       "         service_telnet  service_time  service_urh_i  service_urp_i  \\\n",
       "249263                0             0              0              0   \n",
       "1020523               0             0              0              0   \n",
       "252421                0             0              0              0   \n",
       "828405                0             0              0              0   \n",
       "824142                0             0              0              0   \n",
       "\n",
       "         service_uucp  service_uucp_path  service_vmnet  service_whois  \\\n",
       "249263              0                  0              0              0   \n",
       "1020523             0                  0              0              0   \n",
       "252421              0                  0              0              0   \n",
       "828405              0                  0              0              0   \n",
       "824142              0                  0              0              0   \n",
       "\n",
       "         flag_OTH  flag_REJ  flag_RSTO  flag_RSTOS0  flag_RSTR  flag_S0  \\\n",
       "249263          0         0          0            0          0        0   \n",
       "1020523         0         0          0            0          0        0   \n",
       "252421          0         0          0            0          0        0   \n",
       "828405          0         0          0            0          0        0   \n",
       "824142          0         0          0            0          0        0   \n",
       "\n",
       "         flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  \n",
       "249263         0        0        0        1        0  \n",
       "1020523        0        0        0        1        0  \n",
       "252421         0        0        0        1        0  \n",
       "828405         0        0        0        1        0  \n",
       "824142         0        0        0        1        0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 119)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly sample 500 data point for training\n",
    "df_train=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the item sampled from our dataset\n",
    "index_list=df_train.index\n",
    "train=train.drop(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the label columns\n",
    "df_label=df_train.result\n",
    "df_train=df_train.drop('result',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label\n",
    "df_label.to_csv('normallabel1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 118)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.values.reshape((df_train.shape[0], 1, df_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 1, 118)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed\n",
    "from keras import optimizers\n",
    "from keras.utils import plot_model\n",
    "timesteps =  df_train.shape[1] # equal to the lookback\n",
    "n_features =  df_train.shape[2] # 59\n",
    "\n",
    "epochs = 15\n",
    "batch = 64\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=dict()\n",
    "history['gen']=[]\n",
    "history['dis']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras import callbacks\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error\n",
    "                             ,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Bidirectional, LSTM, Reshape, RepeatVector, TimeDistributed\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#https://www.kaggle.com/function9/bidirectional-lstm-gan-music-generation\n",
    "#https://www.kaggle.com/abhisheksinha28/bidirectional-lstm/data\n",
    "#https://www.kaggle.com/sekfook97/gan-for-anomaly-detection\n",
    "# importing libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Bidirectional, LSTM, Reshape, RepeatVector, TimeDistributed\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 1\n",
    "        self.img_cols = df_train.shape[2]\n",
    "        self.img_shape = (self.img_rows, self.img_cols)\n",
    "        self.latent_dim = df_train.shape[2]\n",
    "        r=df_train.shape[1]\n",
    "\n",
    "        optimizer = Adam(0.0001, 0.4)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates song\n",
    "        z = Input(shape=(1,df_train.shape[2]))\n",
    "    \n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        r=df_train.shape[2]\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(1, df_train.shape[2])))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Bidirectional(LSTM(128)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #specifying output to have 40 timesteps\n",
    "        model.add(RepeatVector(r))\n",
    "        #specifying 1 feature as the output\n",
    "        \n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.3))   \n",
    "        model.add(TimeDistributed(Dense(128)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(TimeDistributed(Dense(128)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(1,df_train.shape[2]))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "        #return Model(img)\n",
    "    \n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(64, use_bias=False, input_shape=(df_train.shape[2], 1)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Convolution1D(32, 3, strides=11, padding='same', use_bias=False))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Convolution1D(1, 3, strides=11, padding='same', use_bias=False))\n",
    "        model.add(Flatten())        \n",
    "        model.add(RepeatVector(1))        \n",
    "        model.add(TimeDistributed(Dense(32, activation = 'relu')))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(TimeDistributed(Dense(1, activation = 'relu')))\n",
    "        #model.add(TimeDistributed(Dense(1)))\n",
    "        #model.add(Dense(1, activation='tanh'))\n",
    "        #model.add(Dense(1))\n",
    "        #model.add(Activation('sigmoid'))\n",
    "        model.summary()\n",
    "        #model.add(layers.BatchNormalization())\n",
    "        #model.add(sigmoid())\n",
    "       \n",
    "        img = Input(shape=(df_train.shape[2],1))\n",
    "        validity = model(img)\n",
    "        print(\"exit\")\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs=15, batch_size=64, save_interval=50):\n",
    "        print(\"enter\")  \n",
    "        # Load the dataset\n",
    "        X_train = df_train\n",
    "       \n",
    "        # Rescale 0 to 1\n",
    "      #  X_train = X_train / 128\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size,1,1))\n",
    "        fake = np.zeros((batch_size,1,1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half of songs\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            imgs = np.array(imgs)\n",
    "            imgs = imgs.reshape(len(imgs),df_train.shape[2],1)\n",
    "\n",
    "            # Sample noise and generate a batch of new songs\n",
    "            noise = np.random.normal(0, 1, (batch_size,1,df_train.shape[2]))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            X_train = df_train\n",
    "            valid = np.ones((batch_size,1,1))\n",
    "            fake = np.zeros((batch_size,1,1))\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake songs as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "            history['gen'].append(g_loss)\n",
    "            \n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            history['dis'].append(d_loss) \n",
    "            #return (g_loss,d_loss)\n",
    "            # If at save interval => save model\n",
    "#            if epoch % save_interval == 0:\n",
    " #               self.generator.save(\"LSTM_generator.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 118, 64)           64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 118, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 11, 32)            6144      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 11, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 1)              96        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 1, 1)              0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 1, 32)             64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 1, 1)              33        \n",
      "=================================================================\n",
      "Total params: 6,401\n",
      "Trainable params: 6,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "exit\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 1, 256)            252928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1, 256)            394240    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 118, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 118, 256)          394240    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 118, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 118, 256)          394240    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 118, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 118, 256)          394240    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 118, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 118, 256)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 118, 128)          32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 118, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 118, 128)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 118, 128)          16512     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 118, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 118, 128)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 118, 1)            129       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 118, 1)            0         \n",
      "=================================================================\n",
      "Total params: 2,273,665\n",
      "Trainable params: 2,273,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "enter\n",
      "0 [D loss: 6.744835, acc.: 50.00%] [G loss: 8.137768]\n",
      "1 [D loss: 3.982466, acc.: 50.00%] [G loss: 7.496657]\n",
      "2 [D loss: 3.702078, acc.: 50.00%] [G loss: 7.414885]\n",
      "3 [D loss: 3.897696, acc.: 50.00%] [G loss: 7.295455]\n",
      "4 [D loss: 4.088574, acc.: 50.00%] [G loss: 7.396400]\n",
      "5 [D loss: 3.679049, acc.: 50.00%] [G loss: 7.374653]\n",
      "6 [D loss: 3.678604, acc.: 50.00%] [G loss: 7.315410]\n",
      "7 [D loss: 3.652072, acc.: 50.00%] [G loss: 7.407744]\n",
      "8 [D loss: 3.643586, acc.: 50.00%] [G loss: 7.016322]\n",
      "9 [D loss: 3.760129, acc.: 50.00%] [G loss: 6.829396]\n",
      "10 [D loss: 3.567531, acc.: 50.00%] [G loss: 6.458469]\n",
      "11 [D loss: 3.230690, acc.: 50.00%] [G loss: 6.379508]\n",
      "12 [D loss: 3.205031, acc.: 50.00%] [G loss: 6.206233]\n",
      "13 [D loss: 3.120349, acc.: 50.00%] [G loss: 6.089005]\n",
      "14 [D loss: 2.994584, acc.: 50.00%] [G loss: 6.070077]\n",
      "15 [D loss: 3.478645, acc.: 50.00%] [G loss: 6.036399]\n",
      "16 [D loss: 3.049219, acc.: 50.00%] [G loss: 5.976896]\n",
      "17 [D loss: 3.058537, acc.: 50.00%] [G loss: 5.941031]\n",
      "18 [D loss: 3.038319, acc.: 50.00%] [G loss: 5.885365]\n",
      "19 [D loss: 3.008163, acc.: 50.00%] [G loss: 5.930743]\n",
      "20 [D loss: 2.952804, acc.: 50.00%] [G loss: 5.784027]\n",
      "21 [D loss: 2.908221, acc.: 50.00%] [G loss: 6.090162]\n",
      "22 [D loss: 2.966483, acc.: 50.00%] [G loss: 5.850270]\n",
      "23 [D loss: 2.930843, acc.: 50.00%] [G loss: 5.767426]\n",
      "24 [D loss: 2.869521, acc.: 50.00%] [G loss: 5.910733]\n",
      "25 [D loss: 2.809056, acc.: 50.00%] [G loss: 5.730273]\n",
      "26 [D loss: 2.828091, acc.: 50.00%] [G loss: 5.568852]\n",
      "27 [D loss: 3.098603, acc.: 50.00%] [G loss: 5.700068]\n",
      "28 [D loss: 2.857777, acc.: 50.00%] [G loss: 5.445211]\n",
      "29 [D loss: 2.815658, acc.: 50.00%] [G loss: 5.328537]\n",
      "30 [D loss: 2.785572, acc.: 50.00%] [G loss: 5.550446]\n",
      "31 [D loss: 2.774253, acc.: 50.00%] [G loss: 5.475381]\n",
      "32 [D loss: 2.700862, acc.: 50.00%] [G loss: 5.700597]\n",
      "33 [D loss: 2.814880, acc.: 50.00%] [G loss: 5.396754]\n",
      "34 [D loss: 2.756141, acc.: 50.00%] [G loss: 5.318340]\n",
      "35 [D loss: 2.623176, acc.: 50.00%] [G loss: 5.565037]\n",
      "36 [D loss: 2.737600, acc.: 50.00%] [G loss: 5.372457]\n",
      "37 [D loss: 2.677675, acc.: 50.00%] [G loss: 5.411534]\n",
      "38 [D loss: 2.727827, acc.: 50.00%] [G loss: 5.442692]\n",
      "39 [D loss: 2.916857, acc.: 50.00%] [G loss: 5.242631]\n",
      "40 [D loss: 2.742373, acc.: 50.00%] [G loss: 5.375630]\n",
      "41 [D loss: 2.946366, acc.: 50.00%] [G loss: 5.214198]\n",
      "42 [D loss: 2.651471, acc.: 50.00%] [G loss: 5.298641]\n",
      "43 [D loss: 2.566558, acc.: 50.00%] [G loss: 5.212512]\n",
      "44 [D loss: 2.835543, acc.: 50.00%] [G loss: 5.395360]\n",
      "45 [D loss: 2.763542, acc.: 50.00%] [G loss: 5.399169]\n",
      "46 [D loss: 2.766171, acc.: 50.00%] [G loss: 5.150743]\n",
      "47 [D loss: 3.169034, acc.: 50.00%] [G loss: 5.337317]\n",
      "48 [D loss: 2.673690, acc.: 50.00%] [G loss: 5.327592]\n",
      "49 [D loss: 2.677596, acc.: 50.00%] [G loss: 5.428093]\n",
      "50 [D loss: 2.603315, acc.: 50.00%] [G loss: 5.370872]\n",
      "51 [D loss: 2.589876, acc.: 50.00%] [G loss: 5.128155]\n",
      "52 [D loss: 2.661805, acc.: 50.00%] [G loss: 5.111030]\n",
      "53 [D loss: 2.609899, acc.: 50.00%] [G loss: 5.204659]\n",
      "54 [D loss: 2.750652, acc.: 50.00%] [G loss: 5.021421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 [D loss: 2.609211, acc.: 50.00%] [G loss: 5.248819]\n",
      "56 [D loss: 2.566744, acc.: 50.00%] [G loss: 5.289219]\n",
      "57 [D loss: 2.810822, acc.: 50.00%] [G loss: 5.232489]\n",
      "58 [D loss: 2.755234, acc.: 50.00%] [G loss: 5.329055]\n",
      "59 [D loss: 2.544341, acc.: 50.00%] [G loss: 5.273108]\n",
      "60 [D loss: 2.625695, acc.: 50.00%] [G loss: 5.350693]\n",
      "61 [D loss: 2.684996, acc.: 50.00%] [G loss: 5.049783]\n",
      "62 [D loss: 2.646278, acc.: 50.00%] [G loss: 5.071521]\n",
      "63 [D loss: 2.693872, acc.: 50.00%] [G loss: 5.034038]\n",
      "64 [D loss: 2.605116, acc.: 50.00%] [G loss: 5.153324]\n",
      "65 [D loss: 2.601581, acc.: 50.00%] [G loss: 5.095273]\n",
      "66 [D loss: 2.577624, acc.: 50.00%] [G loss: 5.036422]\n",
      "67 [D loss: 2.485956, acc.: 50.00%] [G loss: 4.975259]\n",
      "68 [D loss: 2.796237, acc.: 50.00%] [G loss: 5.228862]\n",
      "69 [D loss: 2.482751, acc.: 50.00%] [G loss: 5.098921]\n",
      "70 [D loss: 2.670796, acc.: 50.00%] [G loss: 4.946475]\n",
      "71 [D loss: 2.571917, acc.: 50.00%] [G loss: 5.147181]\n",
      "72 [D loss: 2.568499, acc.: 50.00%] [G loss: 5.309989]\n",
      "73 [D loss: 2.635960, acc.: 50.00%] [G loss: 5.000605]\n",
      "74 [D loss: 2.549210, acc.: 50.00%] [G loss: 5.138436]\n",
      "75 [D loss: 2.761004, acc.: 50.00%] [G loss: 5.186621]\n",
      "76 [D loss: 2.501447, acc.: 50.00%] [G loss: 5.092011]\n",
      "77 [D loss: 2.430282, acc.: 50.00%] [G loss: 5.075497]\n",
      "78 [D loss: 2.567864, acc.: 50.00%] [G loss: 4.854530]\n",
      "79 [D loss: 2.551751, acc.: 50.00%] [G loss: 5.044651]\n",
      "80 [D loss: 2.468667, acc.: 50.00%] [G loss: 4.913797]\n",
      "81 [D loss: 2.721398, acc.: 50.00%] [G loss: 5.134596]\n",
      "82 [D loss: 2.646229, acc.: 50.00%] [G loss: 4.921234]\n",
      "83 [D loss: 2.838496, acc.: 50.00%] [G loss: 5.008107]\n",
      "84 [D loss: 2.527773, acc.: 50.00%] [G loss: 5.218323]\n",
      "85 [D loss: 2.455847, acc.: 50.00%] [G loss: 5.144578]\n",
      "86 [D loss: 2.559225, acc.: 50.00%] [G loss: 4.964553]\n",
      "87 [D loss: 2.833040, acc.: 50.00%] [G loss: 4.813849]\n",
      "88 [D loss: 2.435374, acc.: 50.00%] [G loss: 5.258334]\n",
      "89 [D loss: 2.422015, acc.: 50.00%] [G loss: 4.891134]\n",
      "90 [D loss: 2.411009, acc.: 50.00%] [G loss: 5.083665]\n",
      "91 [D loss: 2.530263, acc.: 50.00%] [G loss: 4.769042]\n",
      "92 [D loss: 2.464643, acc.: 50.00%] [G loss: 5.188584]\n",
      "93 [D loss: 3.105389, acc.: 50.00%] [G loss: 4.915761]\n",
      "94 [D loss: 2.430297, acc.: 50.00%] [G loss: 4.697775]\n",
      "95 [D loss: 2.446641, acc.: 50.00%] [G loss: 4.742818]\n",
      "96 [D loss: 2.447478, acc.: 50.00%] [G loss: 4.893235]\n",
      "97 [D loss: 2.486614, acc.: 50.00%] [G loss: 4.774081]\n",
      "98 [D loss: 2.716174, acc.: 50.00%] [G loss: 4.883039]\n",
      "99 [D loss: 2.484349, acc.: 50.00%] [G loss: 4.729310]\n",
      "100 [D loss: 2.461887, acc.: 50.00%] [G loss: 4.722224]\n",
      "101 [D loss: 2.354414, acc.: 50.00%] [G loss: 4.749712]\n",
      "102 [D loss: 2.757231, acc.: 50.00%] [G loss: 4.788583]\n",
      "103 [D loss: 2.492881, acc.: 50.00%] [G loss: 4.778920]\n",
      "104 [D loss: 2.492778, acc.: 50.00%] [G loss: 4.868498]\n",
      "105 [D loss: 2.362440, acc.: 50.00%] [G loss: 4.817249]\n",
      "106 [D loss: 2.464670, acc.: 50.00%] [G loss: 4.818262]\n",
      "107 [D loss: 2.478236, acc.: 50.00%] [G loss: 4.922510]\n",
      "108 [D loss: 2.392318, acc.: 50.00%] [G loss: 5.016665]\n",
      "109 [D loss: 2.506687, acc.: 50.00%] [G loss: 4.675413]\n",
      "110 [D loss: 2.299776, acc.: 50.00%] [G loss: 5.079584]\n",
      "111 [D loss: 2.456570, acc.: 50.00%] [G loss: 4.818921]\n",
      "112 [D loss: 2.632756, acc.: 50.00%] [G loss: 5.122975]\n",
      "113 [D loss: 2.360739, acc.: 50.00%] [G loss: 4.775754]\n",
      "114 [D loss: 2.409241, acc.: 50.00%] [G loss: 4.844679]\n",
      "115 [D loss: 2.405024, acc.: 50.00%] [G loss: 4.818463]\n",
      "116 [D loss: 2.412160, acc.: 50.00%] [G loss: 5.024061]\n",
      "117 [D loss: 2.420500, acc.: 50.00%] [G loss: 5.152789]\n",
      "118 [D loss: 2.322204, acc.: 50.00%] [G loss: 4.539617]\n",
      "119 [D loss: 2.536810, acc.: 50.00%] [G loss: 4.755293]\n",
      "120 [D loss: 2.353440, acc.: 50.00%] [G loss: 4.741733]\n",
      "121 [D loss: 2.507527, acc.: 50.00%] [G loss: 4.621857]\n",
      "122 [D loss: 2.387498, acc.: 50.00%] [G loss: 5.301553]\n",
      "123 [D loss: 2.511164, acc.: 50.00%] [G loss: 4.567740]\n",
      "124 [D loss: 2.371608, acc.: 50.00%] [G loss: 4.626646]\n",
      "125 [D loss: 2.314167, acc.: 50.00%] [G loss: 4.554777]\n",
      "126 [D loss: 2.365891, acc.: 50.00%] [G loss: 4.782052]\n",
      "127 [D loss: 2.311314, acc.: 50.00%] [G loss: 5.020403]\n",
      "128 [D loss: 2.360741, acc.: 50.00%] [G loss: 4.764005]\n",
      "129 [D loss: 2.330683, acc.: 50.00%] [G loss: 4.746687]\n",
      "130 [D loss: 2.443922, acc.: 50.00%] [G loss: 4.818829]\n",
      "131 [D loss: 2.271794, acc.: 50.00%] [G loss: 4.571804]\n",
      "132 [D loss: 2.451835, acc.: 50.00%] [G loss: 4.849823]\n",
      "133 [D loss: 2.350822, acc.: 50.00%] [G loss: 4.623195]\n",
      "134 [D loss: 2.324963, acc.: 50.00%] [G loss: 4.780715]\n",
      "135 [D loss: 2.195987, acc.: 50.00%] [G loss: 4.662212]\n",
      "136 [D loss: 2.442187, acc.: 50.00%] [G loss: 4.616874]\n",
      "137 [D loss: 2.435344, acc.: 50.00%] [G loss: 4.592385]\n",
      "138 [D loss: 2.433690, acc.: 50.00%] [G loss: 4.573783]\n",
      "139 [D loss: 2.441888, acc.: 50.00%] [G loss: 4.937672]\n",
      "140 [D loss: 2.316930, acc.: 50.00%] [G loss: 4.499116]\n",
      "141 [D loss: 2.318501, acc.: 50.00%] [G loss: 4.917836]\n",
      "142 [D loss: 2.404371, acc.: 50.00%] [G loss: 4.437764]\n",
      "143 [D loss: 2.347390, acc.: 50.00%] [G loss: 4.454367]\n",
      "144 [D loss: 2.448026, acc.: 50.00%] [G loss: 4.657436]\n",
      "145 [D loss: 2.270029, acc.: 50.00%] [G loss: 4.771883]\n",
      "146 [D loss: 2.595987, acc.: 50.00%] [G loss: 4.690389]\n",
      "147 [D loss: 2.363399, acc.: 50.00%] [G loss: 4.591144]\n",
      "148 [D loss: 2.414517, acc.: 50.00%] [G loss: 4.658295]\n",
      "149 [D loss: 2.320347, acc.: 50.00%] [G loss: 4.749931]\n",
      "150 [D loss: 2.205640, acc.: 50.00%] [G loss: 4.763169]\n",
      "151 [D loss: 2.335703, acc.: 50.00%] [G loss: 4.649383]\n",
      "152 [D loss: 2.204183, acc.: 50.00%] [G loss: 4.560463]\n",
      "153 [D loss: 2.180433, acc.: 50.00%] [G loss: 4.505006]\n",
      "154 [D loss: 2.328311, acc.: 50.00%] [G loss: 4.664436]\n",
      "155 [D loss: 2.481273, acc.: 50.00%] [G loss: 4.702142]\n",
      "156 [D loss: 2.322001, acc.: 50.00%] [G loss: 4.550065]\n",
      "157 [D loss: 2.730339, acc.: 50.00%] [G loss: 4.523325]\n",
      "158 [D loss: 2.349879, acc.: 50.00%] [G loss: 4.457349]\n",
      "159 [D loss: 2.219653, acc.: 50.00%] [G loss: 4.405241]\n",
      "160 [D loss: 2.196404, acc.: 50.00%] [G loss: 4.591375]\n",
      "161 [D loss: 2.269802, acc.: 50.00%] [G loss: 4.595616]\n",
      "162 [D loss: 2.364349, acc.: 50.00%] [G loss: 4.646544]\n",
      "163 [D loss: 2.217909, acc.: 50.00%] [G loss: 4.872023]\n",
      "164 [D loss: 2.253864, acc.: 50.00%] [G loss: 4.554764]\n",
      "165 [D loss: 2.317435, acc.: 50.00%] [G loss: 4.400601]\n",
      "166 [D loss: 2.162820, acc.: 50.00%] [G loss: 4.662498]\n",
      "167 [D loss: 2.214277, acc.: 50.00%] [G loss: 4.845059]\n",
      "168 [D loss: 2.584279, acc.: 50.00%] [G loss: 4.784272]\n",
      "169 [D loss: 2.349376, acc.: 50.00%] [G loss: 4.479274]\n",
      "170 [D loss: 2.588685, acc.: 50.00%] [G loss: 4.429905]\n",
      "171 [D loss: 2.198290, acc.: 50.00%] [G loss: 4.527866]\n",
      "172 [D loss: 2.433059, acc.: 50.00%] [G loss: 4.464812]\n",
      "173 [D loss: 2.176021, acc.: 50.00%] [G loss: 4.376356]\n",
      "174 [D loss: 2.335504, acc.: 50.00%] [G loss: 4.550492]\n",
      "175 [D loss: 2.667070, acc.: 50.00%] [G loss: 4.623823]\n",
      "176 [D loss: 2.362410, acc.: 50.00%] [G loss: 4.468553]\n",
      "177 [D loss: 2.194182, acc.: 50.00%] [G loss: 4.674854]\n",
      "178 [D loss: 2.286399, acc.: 50.00%] [G loss: 4.428539]\n",
      "179 [D loss: 2.214626, acc.: 50.00%] [G loss: 4.661259]\n",
      "180 [D loss: 2.269354, acc.: 50.00%] [G loss: 4.456056]\n",
      "181 [D loss: 2.417144, acc.: 50.00%] [G loss: 4.499893]\n",
      "182 [D loss: 2.342527, acc.: 50.00%] [G loss: 4.609541]\n",
      "183 [D loss: 2.279116, acc.: 50.00%] [G loss: 4.517747]\n",
      "184 [D loss: 2.070082, acc.: 50.00%] [G loss: 4.747146]\n",
      "185 [D loss: 2.286806, acc.: 50.00%] [G loss: 4.689143]\n",
      "186 [D loss: 2.177949, acc.: 50.00%] [G loss: 4.553983]\n",
      "187 [D loss: 2.266359, acc.: 50.00%] [G loss: 4.509859]\n",
      "188 [D loss: 2.248014, acc.: 50.00%] [G loss: 4.343003]\n",
      "189 [D loss: 2.210602, acc.: 50.00%] [G loss: 4.305812]\n",
      "190 [D loss: 2.426487, acc.: 50.00%] [G loss: 4.502638]\n",
      "191 [D loss: 2.113869, acc.: 50.00%] [G loss: 4.560224]\n",
      "192 [D loss: 2.132060, acc.: 50.00%] [G loss: 4.377696]\n",
      "193 [D loss: 2.211379, acc.: 50.00%] [G loss: 4.587031]\n",
      "194 [D loss: 2.215240, acc.: 50.00%] [G loss: 4.348013]\n",
      "195 [D loss: 2.331655, acc.: 50.00%] [G loss: 4.287735]\n",
      "196 [D loss: 2.252259, acc.: 50.00%] [G loss: 4.645237]\n",
      "197 [D loss: 2.228720, acc.: 50.00%] [G loss: 4.457819]\n",
      "198 [D loss: 2.242742, acc.: 50.00%] [G loss: 4.591924]\n",
      "199 [D loss: 2.190300, acc.: 50.00%] [G loss: 4.440503]\n",
      "200 [D loss: 2.182445, acc.: 50.00%] [G loss: 4.324713]\n",
      "201 [D loss: 2.252971, acc.: 50.00%] [G loss: 4.420029]\n",
      "202 [D loss: 2.168939, acc.: 50.00%] [G loss: 4.366232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 [D loss: 2.224088, acc.: 50.00%] [G loss: 4.607258]\n",
      "204 [D loss: 2.168237, acc.: 50.00%] [G loss: 4.361618]\n",
      "205 [D loss: 2.217012, acc.: 50.00%] [G loss: 4.799350]\n",
      "206 [D loss: 2.117780, acc.: 50.00%] [G loss: 4.564491]\n",
      "207 [D loss: 2.192044, acc.: 50.00%] [G loss: 4.519375]\n",
      "208 [D loss: 2.306774, acc.: 50.00%] [G loss: 4.340791]\n",
      "209 [D loss: 2.089471, acc.: 50.00%] [G loss: 4.497039]\n",
      "210 [D loss: 2.205668, acc.: 50.00%] [G loss: 3.967773]\n",
      "211 [D loss: 2.229559, acc.: 50.00%] [G loss: 4.217346]\n",
      "212 [D loss: 2.249429, acc.: 50.00%] [G loss: 4.378353]\n",
      "213 [D loss: 2.504699, acc.: 50.00%] [G loss: 4.269631]\n",
      "214 [D loss: 2.266297, acc.: 50.00%] [G loss: 4.556995]\n",
      "215 [D loss: 2.670550, acc.: 50.00%] [G loss: 4.172278]\n",
      "216 [D loss: 2.080776, acc.: 50.00%] [G loss: 4.524429]\n",
      "217 [D loss: 2.183587, acc.: 50.00%] [G loss: 4.383140]\n",
      "218 [D loss: 2.179384, acc.: 50.00%] [G loss: 4.388720]\n",
      "219 [D loss: 2.377287, acc.: 50.00%] [G loss: 4.169604]\n",
      "220 [D loss: 2.105414, acc.: 50.00%] [G loss: 4.024415]\n",
      "221 [D loss: 2.276301, acc.: 50.00%] [G loss: 4.357454]\n",
      "222 [D loss: 2.166117, acc.: 50.00%] [G loss: 4.279033]\n",
      "223 [D loss: 2.239589, acc.: 50.00%] [G loss: 4.753808]\n",
      "224 [D loss: 2.085416, acc.: 50.00%] [G loss: 4.274354]\n",
      "225 [D loss: 2.250810, acc.: 50.00%] [G loss: 4.579730]\n",
      "226 [D loss: 2.229047, acc.: 50.00%] [G loss: 4.197351]\n",
      "227 [D loss: 2.126366, acc.: 50.00%] [G loss: 4.252988]\n",
      "228 [D loss: 2.100581, acc.: 50.00%] [G loss: 4.328821]\n",
      "229 [D loss: 2.121792, acc.: 50.00%] [G loss: 4.634012]\n",
      "230 [D loss: 2.314057, acc.: 50.00%] [G loss: 4.667985]\n",
      "231 [D loss: 2.418186, acc.: 50.00%] [G loss: 4.041862]\n",
      "232 [D loss: 2.169530, acc.: 50.00%] [G loss: 4.324398]\n",
      "233 [D loss: 2.080969, acc.: 50.00%] [G loss: 4.211266]\n",
      "234 [D loss: 2.227542, acc.: 50.00%] [G loss: 4.621092]\n",
      "235 [D loss: 2.466863, acc.: 50.00%] [G loss: 4.170551]\n",
      "236 [D loss: 2.214214, acc.: 50.00%] [G loss: 4.219420]\n",
      "237 [D loss: 2.068963, acc.: 50.00%] [G loss: 3.931754]\n",
      "238 [D loss: 2.135340, acc.: 50.00%] [G loss: 4.133521]\n",
      "239 [D loss: 2.176931, acc.: 50.00%] [G loss: 4.317718]\n",
      "240 [D loss: 2.126011, acc.: 50.00%] [G loss: 4.091499]\n",
      "241 [D loss: 2.186837, acc.: 50.00%] [G loss: 4.032573]\n",
      "242 [D loss: 2.103651, acc.: 50.00%] [G loss: 4.387768]\n",
      "243 [D loss: 2.139140, acc.: 50.00%] [G loss: 4.326947]\n",
      "244 [D loss: 2.107507, acc.: 50.00%] [G loss: 4.354814]\n",
      "245 [D loss: 2.128321, acc.: 50.00%] [G loss: 3.961715]\n",
      "246 [D loss: 2.194134, acc.: 50.00%] [G loss: 4.104717]\n",
      "247 [D loss: 2.094295, acc.: 50.00%] [G loss: 4.268181]\n",
      "248 [D loss: 2.074581, acc.: 50.00%] [G loss: 4.262301]\n",
      "249 [D loss: 2.242805, acc.: 50.00%] [G loss: 4.424863]\n",
      "250 [D loss: 2.161153, acc.: 50.00%] [G loss: 4.461792]\n",
      "251 [D loss: 2.117105, acc.: 50.00%] [G loss: 4.169099]\n",
      "252 [D loss: 2.111134, acc.: 50.00%] [G loss: 4.171134]\n",
      "253 [D loss: 2.230946, acc.: 50.00%] [G loss: 4.060962]\n",
      "254 [D loss: 2.129327, acc.: 50.00%] [G loss: 4.148874]\n",
      "255 [D loss: 2.397810, acc.: 50.00%] [G loss: 4.238663]\n",
      "256 [D loss: 2.147950, acc.: 50.00%] [G loss: 4.506866]\n",
      "257 [D loss: 2.287264, acc.: 50.00%] [G loss: 4.174551]\n",
      "258 [D loss: 2.130784, acc.: 50.00%] [G loss: 4.308642]\n",
      "259 [D loss: 2.431660, acc.: 50.00%] [G loss: 4.209653]\n",
      "260 [D loss: 2.123183, acc.: 50.00%] [G loss: 4.456614]\n",
      "261 [D loss: 2.115175, acc.: 50.00%] [G loss: 4.090570]\n",
      "262 [D loss: 2.096193, acc.: 50.00%] [G loss: 4.137548]\n",
      "263 [D loss: 2.018355, acc.: 50.00%] [G loss: 4.282138]\n",
      "264 [D loss: 2.128399, acc.: 50.00%] [G loss: 4.193833]\n",
      "265 [D loss: 2.081936, acc.: 50.00%] [G loss: 4.301471]\n",
      "266 [D loss: 2.040116, acc.: 50.00%] [G loss: 4.187954]\n",
      "267 [D loss: 2.005788, acc.: 50.00%] [G loss: 4.149207]\n",
      "268 [D loss: 2.197681, acc.: 50.00%] [G loss: 3.993598]\n",
      "269 [D loss: 2.400137, acc.: 50.00%] [G loss: 4.347087]\n",
      "270 [D loss: 2.158896, acc.: 50.00%] [G loss: 4.031774]\n",
      "271 [D loss: 2.150026, acc.: 50.00%] [G loss: 4.230948]\n",
      "272 [D loss: 2.057672, acc.: 50.00%] [G loss: 3.927753]\n",
      "273 [D loss: 2.194350, acc.: 50.00%] [G loss: 4.500353]\n",
      "274 [D loss: 2.084647, acc.: 50.00%] [G loss: 4.026042]\n",
      "275 [D loss: 2.030706, acc.: 50.00%] [G loss: 4.123790]\n",
      "276 [D loss: 2.196623, acc.: 50.00%] [G loss: 4.571313]\n",
      "277 [D loss: 2.059971, acc.: 50.00%] [G loss: 3.953824]\n",
      "278 [D loss: 2.142093, acc.: 50.00%] [G loss: 4.304877]\n",
      "279 [D loss: 2.195837, acc.: 50.00%] [G loss: 3.948770]\n",
      "280 [D loss: 2.102482, acc.: 50.00%] [G loss: 3.993279]\n",
      "281 [D loss: 2.065171, acc.: 50.00%] [G loss: 4.264045]\n",
      "282 [D loss: 2.160025, acc.: 50.00%] [G loss: 4.181955]\n",
      "283 [D loss: 2.113662, acc.: 50.00%] [G loss: 3.871123]\n",
      "284 [D loss: 2.127604, acc.: 50.00%] [G loss: 4.178505]\n",
      "285 [D loss: 2.130835, acc.: 50.00%] [G loss: 3.882583]\n",
      "286 [D loss: 1.976274, acc.: 50.00%] [G loss: 3.967492]\n",
      "287 [D loss: 2.218404, acc.: 50.00%] [G loss: 4.177302]\n",
      "288 [D loss: 2.081892, acc.: 50.00%] [G loss: 4.122867]\n",
      "289 [D loss: 2.363418, acc.: 50.00%] [G loss: 4.271883]\n",
      "290 [D loss: 2.170312, acc.: 50.00%] [G loss: 4.151709]\n",
      "291 [D loss: 2.087609, acc.: 50.00%] [G loss: 4.282710]\n",
      "292 [D loss: 2.143624, acc.: 50.00%] [G loss: 3.957478]\n",
      "293 [D loss: 1.916160, acc.: 50.00%] [G loss: 4.132987]\n",
      "294 [D loss: 2.048599, acc.: 50.00%] [G loss: 3.918795]\n",
      "295 [D loss: 2.002652, acc.: 50.00%] [G loss: 4.197259]\n",
      "296 [D loss: 2.014563, acc.: 50.00%] [G loss: 4.100302]\n",
      "297 [D loss: 2.058904, acc.: 50.00%] [G loss: 4.208486]\n",
      "298 [D loss: 2.065719, acc.: 50.00%] [G loss: 3.823810]\n",
      "299 [D loss: 2.033664, acc.: 50.00%] [G loss: 4.084441]\n",
      "300 [D loss: 2.142217, acc.: 50.00%] [G loss: 3.986339]\n",
      "301 [D loss: 2.032259, acc.: 50.00%] [G loss: 4.060511]\n",
      "302 [D loss: 2.138425, acc.: 50.00%] [G loss: 3.975972]\n",
      "303 [D loss: 2.114586, acc.: 50.00%] [G loss: 3.907340]\n",
      "304 [D loss: 2.114717, acc.: 50.00%] [G loss: 4.010756]\n",
      "305 [D loss: 2.120424, acc.: 50.00%] [G loss: 4.332347]\n",
      "306 [D loss: 1.965117, acc.: 50.00%] [G loss: 4.171221]\n",
      "307 [D loss: 2.000912, acc.: 50.00%] [G loss: 4.060341]\n",
      "308 [D loss: 2.010278, acc.: 50.00%] [G loss: 4.161515]\n",
      "309 [D loss: 1.981424, acc.: 50.00%] [G loss: 4.043724]\n",
      "310 [D loss: 2.244809, acc.: 50.00%] [G loss: 4.010403]\n",
      "311 [D loss: 2.129551, acc.: 50.00%] [G loss: 4.185195]\n",
      "312 [D loss: 2.081718, acc.: 50.00%] [G loss: 4.013481]\n",
      "313 [D loss: 1.991811, acc.: 50.00%] [G loss: 3.911950]\n",
      "314 [D loss: 2.074952, acc.: 50.00%] [G loss: 4.257035]\n",
      "315 [D loss: 1.996704, acc.: 50.00%] [G loss: 3.952067]\n",
      "316 [D loss: 2.020193, acc.: 50.00%] [G loss: 4.432275]\n",
      "317 [D loss: 2.081497, acc.: 50.00%] [G loss: 4.040889]\n",
      "318 [D loss: 2.100956, acc.: 50.00%] [G loss: 3.814974]\n",
      "319 [D loss: 1.968669, acc.: 50.00%] [G loss: 3.928671]\n",
      "320 [D loss: 2.099870, acc.: 50.00%] [G loss: 4.065764]\n",
      "321 [D loss: 1.993401, acc.: 50.00%] [G loss: 4.440276]\n",
      "322 [D loss: 1.974434, acc.: 50.00%] [G loss: 4.260069]\n",
      "323 [D loss: 2.007549, acc.: 50.00%] [G loss: 4.204199]\n",
      "324 [D loss: 1.974790, acc.: 50.00%] [G loss: 4.174595]\n",
      "325 [D loss: 1.955999, acc.: 50.00%] [G loss: 3.861257]\n",
      "326 [D loss: 1.956365, acc.: 50.00%] [G loss: 4.086805]\n",
      "327 [D loss: 1.872887, acc.: 50.00%] [G loss: 4.220890]\n",
      "328 [D loss: 2.124785, acc.: 50.00%] [G loss: 4.043652]\n",
      "329 [D loss: 2.130285, acc.: 50.00%] [G loss: 3.819621]\n",
      "330 [D loss: 1.996210, acc.: 50.00%] [G loss: 3.846078]\n",
      "331 [D loss: 2.099469, acc.: 50.00%] [G loss: 3.972523]\n",
      "332 [D loss: 1.995602, acc.: 50.00%] [G loss: 4.554649]\n",
      "333 [D loss: 1.970084, acc.: 50.00%] [G loss: 3.926262]\n",
      "334 [D loss: 2.087199, acc.: 50.00%] [G loss: 3.840470]\n",
      "335 [D loss: 2.045691, acc.: 50.00%] [G loss: 3.890110]\n",
      "336 [D loss: 1.962055, acc.: 50.00%] [G loss: 4.033603]\n",
      "337 [D loss: 1.911926, acc.: 50.00%] [G loss: 3.887061]\n",
      "338 [D loss: 1.957803, acc.: 50.00%] [G loss: 4.180678]\n",
      "339 [D loss: 2.162067, acc.: 50.00%] [G loss: 3.735830]\n",
      "340 [D loss: 2.009355, acc.: 50.00%] [G loss: 3.751957]\n",
      "341 [D loss: 2.042215, acc.: 50.00%] [G loss: 4.371043]\n",
      "342 [D loss: 1.899433, acc.: 50.00%] [G loss: 4.445338]\n",
      "343 [D loss: 1.931058, acc.: 50.00%] [G loss: 5.462070]\n",
      "344 [D loss: 2.028862, acc.: 50.00%] [G loss: 3.839122]\n",
      "345 [D loss: 1.937600, acc.: 50.00%] [G loss: 3.742512]\n",
      "346 [D loss: 1.975159, acc.: 50.00%] [G loss: 4.010490]\n",
      "347 [D loss: 2.002910, acc.: 50.00%] [G loss: 4.270196]\n",
      "348 [D loss: 2.046212, acc.: 50.00%] [G loss: 4.967799]\n",
      "349 [D loss: 2.051737, acc.: 50.00%] [G loss: 4.834207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 [D loss: 1.975693, acc.: 50.00%] [G loss: 3.544735]\n",
      "351 [D loss: 2.097819, acc.: 50.00%] [G loss: 4.453612]\n",
      "352 [D loss: 2.033425, acc.: 50.00%] [G loss: 5.408351]\n",
      "353 [D loss: 1.942045, acc.: 50.00%] [G loss: 4.412152]\n",
      "354 [D loss: 2.037465, acc.: 50.00%] [G loss: 4.242028]\n",
      "355 [D loss: 2.108137, acc.: 50.00%] [G loss: 4.172122]\n",
      "356 [D loss: 2.039157, acc.: 50.00%] [G loss: 6.067513]\n",
      "357 [D loss: 2.099367, acc.: 50.00%] [G loss: 4.566717]\n",
      "358 [D loss: 2.112082, acc.: 50.00%] [G loss: 4.616860]\n",
      "359 [D loss: 2.045919, acc.: 50.00%] [G loss: 6.674985]\n",
      "360 [D loss: 2.030205, acc.: 50.00%] [G loss: 5.531664]\n",
      "361 [D loss: 2.065898, acc.: 50.00%] [G loss: 4.621988]\n",
      "362 [D loss: 1.988032, acc.: 50.00%] [G loss: 5.262702]\n",
      "363 [D loss: 2.102780, acc.: 50.00%] [G loss: 5.206141]\n",
      "364 [D loss: 2.041986, acc.: 50.00%] [G loss: 5.588595]\n",
      "365 [D loss: 2.034698, acc.: 50.00%] [G loss: 4.754388]\n",
      "366 [D loss: 1.899840, acc.: 50.00%] [G loss: 5.571139]\n",
      "367 [D loss: 2.428107, acc.: 50.00%] [G loss: 4.909564]\n",
      "368 [D loss: 2.078734, acc.: 50.00%] [G loss: 6.959718]\n",
      "369 [D loss: 2.109535, acc.: 50.00%] [G loss: 5.543003]\n",
      "370 [D loss: 2.053397, acc.: 50.00%] [G loss: 4.476064]\n",
      "371 [D loss: 1.994191, acc.: 50.00%] [G loss: 4.987245]\n",
      "372 [D loss: 2.072901, acc.: 50.00%] [G loss: 5.661969]\n",
      "373 [D loss: 1.867303, acc.: 50.00%] [G loss: 5.402616]\n",
      "374 [D loss: 2.099118, acc.: 50.00%] [G loss: 8.964358]\n",
      "375 [D loss: 1.842492, acc.: 50.00%] [G loss: 5.825040]\n",
      "376 [D loss: 1.978637, acc.: 50.00%] [G loss: 7.017646]\n",
      "377 [D loss: 2.022016, acc.: 50.00%] [G loss: 6.191581]\n",
      "378 [D loss: 2.191600, acc.: 50.00%] [G loss: 4.590257]\n",
      "379 [D loss: 2.024610, acc.: 50.00%] [G loss: 5.217567]\n",
      "380 [D loss: 1.994116, acc.: 50.00%] [G loss: 7.101745]\n",
      "381 [D loss: 1.992832, acc.: 50.00%] [G loss: 6.825475]\n",
      "382 [D loss: 2.058999, acc.: 50.00%] [G loss: 5.707139]\n",
      "383 [D loss: 1.949739, acc.: 50.00%] [G loss: 7.674789]\n",
      "384 [D loss: 1.882075, acc.: 50.00%] [G loss: 4.402331]\n",
      "385 [D loss: 1.883870, acc.: 50.00%] [G loss: 7.277921]\n",
      "386 [D loss: 2.083578, acc.: 50.00%] [G loss: 6.794060]\n",
      "387 [D loss: 2.006786, acc.: 50.00%] [G loss: 5.843114]\n",
      "388 [D loss: 1.894545, acc.: 50.00%] [G loss: 7.371695]\n",
      "389 [D loss: 2.023480, acc.: 50.00%] [G loss: 6.258145]\n",
      "390 [D loss: 1.881704, acc.: 50.00%] [G loss: 3.975117]\n",
      "391 [D loss: 1.892870, acc.: 50.00%] [G loss: 3.894865]\n",
      "392 [D loss: 1.917845, acc.: 50.00%] [G loss: 3.971399]\n",
      "393 [D loss: 1.990872, acc.: 50.00%] [G loss: 4.072858]\n",
      "394 [D loss: 1.804862, acc.: 50.00%] [G loss: 3.883776]\n",
      "395 [D loss: 1.931248, acc.: 50.00%] [G loss: 3.838563]\n",
      "396 [D loss: 1.875132, acc.: 50.00%] [G loss: 4.086764]\n",
      "397 [D loss: 1.866929, acc.: 50.00%] [G loss: 4.005730]\n",
      "398 [D loss: 1.968316, acc.: 50.00%] [G loss: 3.750881]\n",
      "399 [D loss: 2.035576, acc.: 50.00%] [G loss: 4.063610]\n",
      "400 [D loss: 1.855943, acc.: 50.00%] [G loss: 4.046990]\n",
      "401 [D loss: 1.841628, acc.: 50.00%] [G loss: 3.706792]\n",
      "402 [D loss: 1.989684, acc.: 50.00%] [G loss: 3.911997]\n",
      "403 [D loss: 1.956658, acc.: 50.00%] [G loss: 3.559053]\n",
      "404 [D loss: 1.940129, acc.: 50.00%] [G loss: 3.887693]\n",
      "405 [D loss: 1.905401, acc.: 50.00%] [G loss: 3.746869]\n",
      "406 [D loss: 2.030612, acc.: 50.00%] [G loss: 4.196861]\n",
      "407 [D loss: 1.876710, acc.: 50.00%] [G loss: 3.722203]\n",
      "408 [D loss: 2.034638, acc.: 50.00%] [G loss: 3.987688]\n",
      "409 [D loss: 2.000971, acc.: 50.00%] [G loss: 3.885750]\n",
      "410 [D loss: 1.937939, acc.: 50.00%] [G loss: 3.904142]\n",
      "411 [D loss: 2.097730, acc.: 50.00%] [G loss: 3.854596]\n",
      "412 [D loss: 1.909483, acc.: 50.00%] [G loss: 3.822925]\n",
      "413 [D loss: 2.016840, acc.: 50.00%] [G loss: 3.675745]\n",
      "414 [D loss: 1.934463, acc.: 50.00%] [G loss: 4.146085]\n",
      "415 [D loss: 1.913315, acc.: 50.00%] [G loss: 3.679107]\n",
      "416 [D loss: 1.845546, acc.: 50.00%] [G loss: 3.591991]\n",
      "417 [D loss: 1.925925, acc.: 50.00%] [G loss: 3.790496]\n",
      "418 [D loss: 1.885975, acc.: 50.00%] [G loss: 3.814178]\n",
      "419 [D loss: 2.042080, acc.: 50.00%] [G loss: 3.614555]\n",
      "420 [D loss: 2.146143, acc.: 50.00%] [G loss: 4.130875]\n",
      "421 [D loss: 2.018821, acc.: 50.00%] [G loss: 3.812630]\n",
      "422 [D loss: 1.924361, acc.: 50.00%] [G loss: 3.620364]\n",
      "423 [D loss: 1.870344, acc.: 50.00%] [G loss: 3.841170]\n",
      "424 [D loss: 1.848803, acc.: 50.00%] [G loss: 3.902174]\n",
      "425 [D loss: 1.988171, acc.: 50.00%] [G loss: 3.876854]\n",
      "426 [D loss: 1.957081, acc.: 50.00%] [G loss: 3.859076]\n",
      "427 [D loss: 1.937740, acc.: 50.00%] [G loss: 3.501336]\n",
      "428 [D loss: 2.156334, acc.: 50.00%] [G loss: 4.141875]\n",
      "429 [D loss: 2.037964, acc.: 50.00%] [G loss: 3.757933]\n",
      "430 [D loss: 1.807694, acc.: 50.00%] [G loss: 3.797897]\n",
      "431 [D loss: 1.960080, acc.: 50.00%] [G loss: 3.843098]\n",
      "432 [D loss: 1.907840, acc.: 50.00%] [G loss: 4.235404]\n",
      "433 [D loss: 2.208958, acc.: 50.00%] [G loss: 3.744243]\n",
      "434 [D loss: 2.099272, acc.: 50.00%] [G loss: 3.614358]\n",
      "435 [D loss: 2.066800, acc.: 50.00%] [G loss: 3.672324]\n",
      "436 [D loss: 1.871816, acc.: 50.00%] [G loss: 4.024531]\n",
      "437 [D loss: 1.872945, acc.: 50.00%] [G loss: 3.649675]\n",
      "438 [D loss: 1.967175, acc.: 50.00%] [G loss: 3.822869]\n",
      "439 [D loss: 2.083390, acc.: 50.00%] [G loss: 3.868222]\n",
      "440 [D loss: 1.891836, acc.: 50.00%] [G loss: 3.942245]\n",
      "441 [D loss: 2.085302, acc.: 50.00%] [G loss: 3.658400]\n",
      "442 [D loss: 1.991024, acc.: 50.00%] [G loss: 3.857128]\n",
      "443 [D loss: 1.926048, acc.: 50.00%] [G loss: 3.958011]\n",
      "444 [D loss: 1.880605, acc.: 50.00%] [G loss: 3.808433]\n",
      "445 [D loss: 1.795729, acc.: 50.00%] [G loss: 3.876402]\n",
      "446 [D loss: 1.925242, acc.: 50.00%] [G loss: 3.877232]\n",
      "447 [D loss: 1.843595, acc.: 50.00%] [G loss: 3.814435]\n",
      "448 [D loss: 1.788862, acc.: 50.00%] [G loss: 3.570624]\n",
      "449 [D loss: 2.030065, acc.: 50.00%] [G loss: 3.795330]\n",
      "450 [D loss: 1.948317, acc.: 50.00%] [G loss: 3.906390]\n",
      "451 [D loss: 1.750211, acc.: 50.00%] [G loss: 3.754056]\n",
      "452 [D loss: 1.883933, acc.: 50.00%] [G loss: 4.146970]\n",
      "453 [D loss: 1.833440, acc.: 50.00%] [G loss: 3.784881]\n",
      "454 [D loss: 1.829588, acc.: 50.00%] [G loss: 3.956525]\n",
      "455 [D loss: 2.240377, acc.: 50.00%] [G loss: 4.105848]\n",
      "456 [D loss: 2.025681, acc.: 50.00%] [G loss: 3.764413]\n",
      "457 [D loss: 2.212023, acc.: 50.00%] [G loss: 3.667657]\n",
      "458 [D loss: 1.863640, acc.: 50.00%] [G loss: 3.835986]\n",
      "459 [D loss: 1.841853, acc.: 50.00%] [G loss: 3.772683]\n",
      "460 [D loss: 1.871081, acc.: 50.00%] [G loss: 3.692025]\n",
      "461 [D loss: 1.892357, acc.: 50.00%] [G loss: 3.737892]\n",
      "462 [D loss: 1.733091, acc.: 50.00%] [G loss: 3.848969]\n",
      "463 [D loss: 1.738130, acc.: 50.00%] [G loss: 3.854690]\n",
      "464 [D loss: 1.906053, acc.: 50.00%] [G loss: 3.550753]\n",
      "465 [D loss: 1.754562, acc.: 50.00%] [G loss: 3.835484]\n",
      "466 [D loss: 1.812960, acc.: 50.00%] [G loss: 3.981269]\n",
      "467 [D loss: 1.868668, acc.: 50.00%] [G loss: 3.837031]\n",
      "468 [D loss: 1.776413, acc.: 50.00%] [G loss: 4.058299]\n",
      "469 [D loss: 1.816421, acc.: 50.00%] [G loss: 3.860931]\n",
      "470 [D loss: 1.784895, acc.: 50.00%] [G loss: 3.769032]\n",
      "471 [D loss: 1.978480, acc.: 50.00%] [G loss: 3.732316]\n",
      "472 [D loss: 1.881676, acc.: 50.00%] [G loss: 3.705889]\n",
      "473 [D loss: 2.049775, acc.: 50.00%] [G loss: 3.472764]\n",
      "474 [D loss: 1.943557, acc.: 50.00%] [G loss: 3.540756]\n",
      "475 [D loss: 1.843652, acc.: 50.00%] [G loss: 3.766415]\n",
      "476 [D loss: 1.793070, acc.: 50.00%] [G loss: 3.627401]\n",
      "477 [D loss: 1.916526, acc.: 50.00%] [G loss: 3.702771]\n",
      "478 [D loss: 1.709979, acc.: 50.00%] [G loss: 3.746766]\n",
      "479 [D loss: 1.900120, acc.: 50.00%] [G loss: 3.602195]\n",
      "480 [D loss: 1.850406, acc.: 50.00%] [G loss: 3.922422]\n",
      "481 [D loss: 1.793989, acc.: 50.00%] [G loss: 4.016267]\n",
      "482 [D loss: 1.921987, acc.: 50.00%] [G loss: 3.810661]\n",
      "483 [D loss: 1.793945, acc.: 50.00%] [G loss: 3.420903]\n",
      "484 [D loss: 1.858214, acc.: 50.00%] [G loss: 3.654732]\n",
      "485 [D loss: 1.768367, acc.: 50.00%] [G loss: 3.512917]\n",
      "486 [D loss: 1.942413, acc.: 50.00%] [G loss: 3.564252]\n",
      "487 [D loss: 1.708268, acc.: 50.00%] [G loss: 3.738879]\n",
      "488 [D loss: 1.946110, acc.: 50.00%] [G loss: 4.072768]\n",
      "489 [D loss: 1.778633, acc.: 50.00%] [G loss: 3.542798]\n",
      "490 [D loss: 1.811537, acc.: 50.00%] [G loss: 4.133236]\n",
      "491 [D loss: 1.855874, acc.: 50.00%] [G loss: 3.798193]\n",
      "492 [D loss: 1.769495, acc.: 50.00%] [G loss: 3.547396]\n",
      "493 [D loss: 1.878056, acc.: 50.00%] [G loss: 3.480811]\n",
      "494 [D loss: 1.747779, acc.: 50.00%] [G loss: 3.551236]\n",
      "495 [D loss: 1.839002, acc.: 50.00%] [G loss: 3.448756]\n",
      "496 [D loss: 1.733802, acc.: 50.00%] [G loss: 3.511801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497 [D loss: 1.837900, acc.: 50.00%] [G loss: 3.637539]\n",
      "498 [D loss: 1.807957, acc.: 50.00%] [G loss: 4.098428]\n",
      "499 [D loss: 1.875423, acc.: 50.00%] [G loss: 3.388411]\n",
      "500 [D loss: 1.726936, acc.: 50.00%] [G loss: 3.395895]\n",
      "501 [D loss: 1.805671, acc.: 50.00%] [G loss: 3.341092]\n",
      "502 [D loss: 1.793589, acc.: 50.00%] [G loss: 3.512008]\n",
      "503 [D loss: 1.973079, acc.: 50.00%] [G loss: 3.407712]\n",
      "504 [D loss: 1.920208, acc.: 50.00%] [G loss: 4.725177]\n",
      "505 [D loss: 1.819950, acc.: 50.00%] [G loss: 4.180139]\n",
      "506 [D loss: 1.777473, acc.: 50.00%] [G loss: 4.089249]\n",
      "507 [D loss: 1.861947, acc.: 50.00%] [G loss: 5.293902]\n",
      "508 [D loss: 1.673612, acc.: 50.00%] [G loss: 4.370320]\n",
      "509 [D loss: 1.739988, acc.: 50.00%] [G loss: 3.495116]\n",
      "510 [D loss: 1.678564, acc.: 50.00%] [G loss: 3.679549]\n",
      "511 [D loss: 1.919547, acc.: 50.00%] [G loss: 3.731314]\n",
      "512 [D loss: 2.257788, acc.: 50.00%] [G loss: 3.738641]\n",
      "513 [D loss: 1.920295, acc.: 50.00%] [G loss: 4.451474]\n",
      "514 [D loss: 1.871513, acc.: 50.00%] [G loss: 3.797526]\n",
      "515 [D loss: 1.911460, acc.: 50.00%] [G loss: 4.156717]\n",
      "516 [D loss: 1.727945, acc.: 50.00%] [G loss: 3.572316]\n",
      "517 [D loss: 1.821644, acc.: 50.00%] [G loss: 3.454704]\n",
      "518 [D loss: 1.730867, acc.: 50.00%] [G loss: 3.758852]\n",
      "519 [D loss: 1.765124, acc.: 50.00%] [G loss: 3.551450]\n",
      "520 [D loss: 1.685212, acc.: 50.00%] [G loss: 3.470259]\n",
      "521 [D loss: 1.914763, acc.: 50.00%] [G loss: 3.836584]\n",
      "522 [D loss: 1.970206, acc.: 50.00%] [G loss: 3.763972]\n",
      "523 [D loss: 1.830856, acc.: 50.00%] [G loss: 3.772138]\n",
      "524 [D loss: 1.735175, acc.: 50.00%] [G loss: 3.605167]\n",
      "525 [D loss: 1.821682, acc.: 50.00%] [G loss: 3.379909]\n",
      "526 [D loss: 2.051126, acc.: 50.00%] [G loss: 3.439677]\n",
      "527 [D loss: 1.889145, acc.: 50.00%] [G loss: 4.261497]\n",
      "528 [D loss: 1.882363, acc.: 50.00%] [G loss: 3.492947]\n",
      "529 [D loss: 1.750975, acc.: 50.00%] [G loss: 3.509087]\n",
      "530 [D loss: 1.641822, acc.: 50.00%] [G loss: 4.374295]\n",
      "531 [D loss: 1.837037, acc.: 50.00%] [G loss: 4.089477]\n",
      "532 [D loss: 1.795001, acc.: 50.00%] [G loss: 3.712850]\n",
      "533 [D loss: 1.697072, acc.: 50.00%] [G loss: 3.885100]\n",
      "534 [D loss: 1.932079, acc.: 50.00%] [G loss: 3.943411]\n",
      "535 [D loss: 1.773957, acc.: 50.00%] [G loss: 3.163029]\n",
      "536 [D loss: 1.796278, acc.: 50.00%] [G loss: 3.536615]\n",
      "537 [D loss: 1.883795, acc.: 50.00%] [G loss: 3.758321]\n",
      "538 [D loss: 1.820005, acc.: 50.00%] [G loss: 3.299222]\n",
      "539 [D loss: 1.915631, acc.: 50.00%] [G loss: 3.474226]\n",
      "540 [D loss: 1.836757, acc.: 50.00%] [G loss: 4.200282]\n",
      "541 [D loss: 1.825631, acc.: 50.00%] [G loss: 3.587969]\n",
      "542 [D loss: 1.752628, acc.: 50.00%] [G loss: 3.438850]\n",
      "543 [D loss: 1.761836, acc.: 50.00%] [G loss: 3.542677]\n",
      "544 [D loss: 1.847594, acc.: 50.00%] [G loss: 4.520246]\n",
      "545 [D loss: 1.919331, acc.: 50.00%] [G loss: 3.593501]\n",
      "546 [D loss: 1.840440, acc.: 50.00%] [G loss: 4.007989]\n",
      "547 [D loss: 1.823774, acc.: 50.00%] [G loss: 3.561817]\n",
      "548 [D loss: 2.016352, acc.: 50.00%] [G loss: 3.623566]\n",
      "549 [D loss: 1.756754, acc.: 50.00%] [G loss: 3.546448]\n",
      "550 [D loss: 1.822304, acc.: 50.00%] [G loss: 3.931203]\n",
      "551 [D loss: 1.960419, acc.: 50.00%] [G loss: 5.193258]\n",
      "552 [D loss: 1.773116, acc.: 50.00%] [G loss: 4.644508]\n",
      "553 [D loss: 1.752269, acc.: 50.00%] [G loss: 3.354564]\n",
      "554 [D loss: 1.801728, acc.: 50.00%] [G loss: 3.562021]\n",
      "555 [D loss: 1.654580, acc.: 50.00%] [G loss: 3.412678]\n",
      "556 [D loss: 1.752580, acc.: 50.00%] [G loss: 3.928886]\n",
      "557 [D loss: 1.695970, acc.: 50.00%] [G loss: 3.874587]\n",
      "558 [D loss: 1.791519, acc.: 50.00%] [G loss: 3.697902]\n",
      "559 [D loss: 1.805380, acc.: 50.00%] [G loss: 7.741803]\n",
      "560 [D loss: 2.049107, acc.: 50.00%] [G loss: 5.290996]\n",
      "561 [D loss: 1.728578, acc.: 50.00%] [G loss: 5.003557]\n",
      "562 [D loss: 1.677129, acc.: 50.00%] [G loss: 5.005826]\n",
      "563 [D loss: 1.792672, acc.: 50.00%] [G loss: 5.945036]\n",
      "564 [D loss: 1.822248, acc.: 50.00%] [G loss: 6.705532]\n",
      "565 [D loss: 1.849843, acc.: 50.00%] [G loss: 5.033998]\n",
      "566 [D loss: 1.852253, acc.: 50.00%] [G loss: 4.522826]\n",
      "567 [D loss: 1.764132, acc.: 50.00%] [G loss: 6.498149]\n",
      "568 [D loss: 1.792309, acc.: 50.00%] [G loss: 7.915367]\n",
      "569 [D loss: 1.841325, acc.: 50.00%] [G loss: 7.211418]\n",
      "570 [D loss: 1.723088, acc.: 50.00%] [G loss: 4.905402]\n",
      "571 [D loss: 1.803905, acc.: 50.00%] [G loss: 5.659644]\n",
      "572 [D loss: 1.774990, acc.: 50.00%] [G loss: 5.691195]\n",
      "573 [D loss: 1.743684, acc.: 50.00%] [G loss: 5.365075]\n",
      "574 [D loss: 1.820359, acc.: 50.00%] [G loss: 5.443499]\n",
      "575 [D loss: 1.800334, acc.: 50.00%] [G loss: 6.198778]\n",
      "576 [D loss: 1.885906, acc.: 50.00%] [G loss: 6.122854]\n",
      "577 [D loss: 1.767117, acc.: 50.00%] [G loss: 5.604209]\n",
      "578 [D loss: 1.877984, acc.: 50.00%] [G loss: 6.180871]\n",
      "579 [D loss: 1.667753, acc.: 50.00%] [G loss: 7.036870]\n",
      "580 [D loss: 1.707693, acc.: 50.00%] [G loss: 8.030416]\n",
      "581 [D loss: 1.877770, acc.: 50.00%] [G loss: 6.502720]\n",
      "582 [D loss: 1.827480, acc.: 50.00%] [G loss: 5.456300]\n",
      "583 [D loss: 1.727301, acc.: 50.00%] [G loss: 6.988667]\n",
      "584 [D loss: 1.933354, acc.: 50.00%] [G loss: 6.429325]\n",
      "585 [D loss: 1.819768, acc.: 50.00%] [G loss: 5.970114]\n",
      "586 [D loss: 1.909974, acc.: 50.00%] [G loss: 7.024008]\n",
      "587 [D loss: 1.882428, acc.: 50.00%] [G loss: 5.421666]\n",
      "588 [D loss: 1.857775, acc.: 50.00%] [G loss: 3.468554]\n",
      "589 [D loss: 1.750470, acc.: 50.00%] [G loss: 4.150764]\n",
      "590 [D loss: 1.820349, acc.: 50.00%] [G loss: 3.531470]\n",
      "591 [D loss: 1.698958, acc.: 50.00%] [G loss: 3.621679]\n",
      "592 [D loss: 1.817805, acc.: 50.00%] [G loss: 4.314734]\n",
      "593 [D loss: 1.736799, acc.: 50.00%] [G loss: 3.511616]\n",
      "594 [D loss: 1.626667, acc.: 50.00%] [G loss: 3.743734]\n",
      "595 [D loss: 1.850824, acc.: 50.00%] [G loss: 3.707909]\n",
      "596 [D loss: 1.671769, acc.: 50.00%] [G loss: 3.389530]\n",
      "597 [D loss: 1.597962, acc.: 50.00%] [G loss: 3.950469]\n",
      "598 [D loss: 1.879792, acc.: 50.00%] [G loss: 3.503434]\n",
      "599 [D loss: 1.617359, acc.: 50.00%] [G loss: 3.506404]\n",
      "600 [D loss: 1.697053, acc.: 50.00%] [G loss: 3.709431]\n",
      "601 [D loss: 1.703662, acc.: 50.00%] [G loss: 3.434553]\n",
      "602 [D loss: 1.581219, acc.: 50.00%] [G loss: 3.083093]\n",
      "603 [D loss: 1.895547, acc.: 50.00%] [G loss: 3.270520]\n",
      "604 [D loss: 1.769613, acc.: 50.00%] [G loss: 3.217551]\n",
      "605 [D loss: 1.743715, acc.: 50.00%] [G loss: 3.551396]\n",
      "606 [D loss: 1.798854, acc.: 50.00%] [G loss: 3.490550]\n",
      "607 [D loss: 1.696971, acc.: 50.00%] [G loss: 3.504686]\n",
      "608 [D loss: 1.586566, acc.: 50.00%] [G loss: 3.328408]\n",
      "609 [D loss: 1.632509, acc.: 50.00%] [G loss: 3.695982]\n",
      "610 [D loss: 1.941437, acc.: 50.00%] [G loss: 3.596706]\n",
      "611 [D loss: 1.753300, acc.: 50.00%] [G loss: 3.370045]\n",
      "612 [D loss: 1.714479, acc.: 50.00%] [G loss: 3.496811]\n",
      "613 [D loss: 2.157294, acc.: 50.00%] [G loss: 3.476552]\n",
      "614 [D loss: 1.736992, acc.: 50.00%] [G loss: 3.239158]\n",
      "615 [D loss: 1.898654, acc.: 50.00%] [G loss: 3.467979]\n",
      "616 [D loss: 1.721433, acc.: 50.00%] [G loss: 3.403563]\n",
      "617 [D loss: 1.764772, acc.: 50.00%] [G loss: 3.517091]\n",
      "618 [D loss: 1.734624, acc.: 50.00%] [G loss: 3.850636]\n",
      "619 [D loss: 1.747314, acc.: 50.00%] [G loss: 3.355560]\n",
      "620 [D loss: 1.711884, acc.: 50.00%] [G loss: 3.524507]\n",
      "621 [D loss: 1.673381, acc.: 50.00%] [G loss: 3.339490]\n",
      "622 [D loss: 1.792659, acc.: 50.00%] [G loss: 3.359772]\n",
      "623 [D loss: 1.718200, acc.: 50.00%] [G loss: 3.508671]\n",
      "624 [D loss: 1.854907, acc.: 50.00%] [G loss: 3.566472]\n",
      "625 [D loss: 1.726297, acc.: 50.00%] [G loss: 3.386348]\n",
      "626 [D loss: 1.769973, acc.: 50.00%] [G loss: 3.552017]\n",
      "627 [D loss: 1.807468, acc.: 50.00%] [G loss: 3.363543]\n",
      "628 [D loss: 1.810838, acc.: 50.00%] [G loss: 3.323380]\n",
      "629 [D loss: 1.577938, acc.: 50.00%] [G loss: 3.302680]\n",
      "630 [D loss: 1.686675, acc.: 50.00%] [G loss: 3.360980]\n",
      "631 [D loss: 1.747517, acc.: 50.00%] [G loss: 4.076512]\n",
      "632 [D loss: 1.679410, acc.: 50.00%] [G loss: 3.311925]\n",
      "633 [D loss: 1.662873, acc.: 50.00%] [G loss: 3.593470]\n",
      "634 [D loss: 1.927066, acc.: 50.00%] [G loss: 3.531226]\n",
      "635 [D loss: 1.744529, acc.: 50.00%] [G loss: 3.550982]\n",
      "636 [D loss: 1.745551, acc.: 50.00%] [G loss: 3.571847]\n",
      "637 [D loss: 1.775841, acc.: 50.00%] [G loss: 3.384759]\n",
      "638 [D loss: 1.791837, acc.: 50.00%] [G loss: 3.661082]\n",
      "639 [D loss: 1.746762, acc.: 50.00%] [G loss: 3.280017]\n",
      "640 [D loss: 1.706249, acc.: 50.00%] [G loss: 3.515881]\n",
      "641 [D loss: 1.790891, acc.: 50.00%] [G loss: 3.739172]\n",
      "642 [D loss: 1.584933, acc.: 50.00%] [G loss: 3.407691]\n",
      "643 [D loss: 1.842460, acc.: 50.00%] [G loss: 3.514519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644 [D loss: 1.922311, acc.: 50.00%] [G loss: 3.378475]\n",
      "645 [D loss: 1.741905, acc.: 50.00%] [G loss: 3.397212]\n",
      "646 [D loss: 1.843602, acc.: 50.00%] [G loss: 3.147562]\n",
      "647 [D loss: 1.742466, acc.: 50.00%] [G loss: 3.653245]\n",
      "648 [D loss: 1.661037, acc.: 50.00%] [G loss: 3.207461]\n",
      "649 [D loss: 1.815178, acc.: 50.00%] [G loss: 3.429190]\n",
      "650 [D loss: 1.764333, acc.: 50.00%] [G loss: 3.317325]\n",
      "651 [D loss: 1.750380, acc.: 50.00%] [G loss: 3.535349]\n",
      "652 [D loss: 1.677299, acc.: 50.00%] [G loss: 3.159036]\n",
      "653 [D loss: 1.825857, acc.: 50.00%] [G loss: 3.438137]\n",
      "654 [D loss: 1.688672, acc.: 50.00%] [G loss: 3.521661]\n",
      "655 [D loss: 1.836300, acc.: 50.00%] [G loss: 3.388936]\n",
      "656 [D loss: 1.757153, acc.: 50.00%] [G loss: 3.377601]\n",
      "657 [D loss: 1.622551, acc.: 50.00%] [G loss: 3.223226]\n",
      "658 [D loss: 1.726020, acc.: 50.00%] [G loss: 3.424760]\n",
      "659 [D loss: 1.741217, acc.: 50.00%] [G loss: 3.452536]\n",
      "660 [D loss: 1.819192, acc.: 50.00%] [G loss: 3.740307]\n",
      "661 [D loss: 1.860814, acc.: 50.00%] [G loss: 3.718022]\n",
      "662 [D loss: 1.660258, acc.: 50.00%] [G loss: 3.306088]\n",
      "663 [D loss: 1.625867, acc.: 50.00%] [G loss: 3.417272]\n",
      "664 [D loss: 1.595315, acc.: 50.00%] [G loss: 3.158556]\n",
      "665 [D loss: 1.650913, acc.: 50.00%] [G loss: 3.586524]\n",
      "666 [D loss: 1.716365, acc.: 50.00%] [G loss: 3.403704]\n",
      "667 [D loss: 1.646883, acc.: 50.00%] [G loss: 3.559139]\n",
      "668 [D loss: 1.751625, acc.: 50.00%] [G loss: 3.611999]\n",
      "669 [D loss: 1.711049, acc.: 50.00%] [G loss: 3.461274]\n",
      "670 [D loss: 1.675022, acc.: 50.00%] [G loss: 3.218894]\n",
      "671 [D loss: 1.757135, acc.: 50.00%] [G loss: 3.416413]\n",
      "672 [D loss: 1.742489, acc.: 50.00%] [G loss: 3.268087]\n",
      "673 [D loss: 1.639410, acc.: 50.00%] [G loss: 3.411849]\n",
      "674 [D loss: 1.843751, acc.: 50.00%] [G loss: 3.975585]\n",
      "675 [D loss: 1.643648, acc.: 50.00%] [G loss: 3.211725]\n",
      "676 [D loss: 1.651177, acc.: 50.00%] [G loss: 3.434541]\n",
      "677 [D loss: 1.547602, acc.: 50.00%] [G loss: 3.342227]\n",
      "678 [D loss: 1.844201, acc.: 50.00%] [G loss: 3.244462]\n",
      "679 [D loss: 1.825001, acc.: 50.00%] [G loss: 3.279107]\n",
      "680 [D loss: 1.605971, acc.: 50.00%] [G loss: 3.358747]\n",
      "681 [D loss: 1.662705, acc.: 50.00%] [G loss: 3.335514]\n",
      "682 [D loss: 1.749654, acc.: 50.00%] [G loss: 3.422070]\n",
      "683 [D loss: 1.618032, acc.: 50.00%] [G loss: 3.253427]\n",
      "684 [D loss: 1.808347, acc.: 50.00%] [G loss: 3.498779]\n",
      "685 [D loss: 1.729134, acc.: 50.00%] [G loss: 3.565647]\n",
      "686 [D loss: 1.655640, acc.: 50.00%] [G loss: 3.278603]\n",
      "687 [D loss: 1.764158, acc.: 50.00%] [G loss: 3.320866]\n",
      "688 [D loss: 1.712335, acc.: 50.00%] [G loss: 3.114948]\n",
      "689 [D loss: 1.561021, acc.: 50.00%] [G loss: 3.660470]\n",
      "690 [D loss: 1.848718, acc.: 50.00%] [G loss: 3.498805]\n",
      "691 [D loss: 1.514805, acc.: 50.00%] [G loss: 3.116118]\n",
      "692 [D loss: 1.615077, acc.: 50.00%] [G loss: 3.796762]\n",
      "693 [D loss: 1.593528, acc.: 50.00%] [G loss: 3.523448]\n",
      "694 [D loss: 1.551883, acc.: 50.00%] [G loss: 3.480011]\n",
      "695 [D loss: 1.756088, acc.: 50.00%] [G loss: 3.499566]\n",
      "696 [D loss: 1.799815, acc.: 50.00%] [G loss: 3.454810]\n",
      "697 [D loss: 1.607376, acc.: 50.00%] [G loss: 3.613954]\n",
      "698 [D loss: 1.706321, acc.: 50.00%] [G loss: 3.322453]\n",
      "699 [D loss: 1.736238, acc.: 50.00%] [G loss: 3.250971]\n",
      "700 [D loss: 1.592009, acc.: 50.00%] [G loss: 3.331193]\n",
      "701 [D loss: 1.794201, acc.: 50.00%] [G loss: 3.241341]\n",
      "702 [D loss: 1.618992, acc.: 50.00%] [G loss: 3.128898]\n",
      "703 [D loss: 1.833156, acc.: 50.00%] [G loss: 3.289973]\n",
      "704 [D loss: 1.777537, acc.: 50.00%] [G loss: 3.299612]\n",
      "705 [D loss: 1.499236, acc.: 50.00%] [G loss: 3.610732]\n",
      "706 [D loss: 1.681610, acc.: 50.00%] [G loss: 3.349392]\n",
      "707 [D loss: 1.740693, acc.: 50.00%] [G loss: 3.377620]\n",
      "708 [D loss: 1.775055, acc.: 50.00%] [G loss: 3.055723]\n",
      "709 [D loss: 1.642503, acc.: 50.00%] [G loss: 3.524619]\n",
      "710 [D loss: 1.642830, acc.: 50.00%] [G loss: 3.367603]\n",
      "711 [D loss: 1.551507, acc.: 50.00%] [G loss: 3.271676]\n",
      "712 [D loss: 1.619707, acc.: 50.00%] [G loss: 3.422327]\n",
      "713 [D loss: 1.675387, acc.: 50.00%] [G loss: 3.127034]\n",
      "714 [D loss: 1.738934, acc.: 50.00%] [G loss: 3.475404]\n",
      "715 [D loss: 1.576021, acc.: 50.00%] [G loss: 3.288638]\n",
      "716 [D loss: 1.657735, acc.: 50.00%] [G loss: 3.395686]\n",
      "717 [D loss: 1.664338, acc.: 50.00%] [G loss: 3.391258]\n",
      "718 [D loss: 1.948867, acc.: 50.00%] [G loss: 2.997913]\n",
      "719 [D loss: 1.787961, acc.: 50.00%] [G loss: 3.261451]\n",
      "720 [D loss: 1.692991, acc.: 50.00%] [G loss: 3.164160]\n",
      "721 [D loss: 1.681165, acc.: 50.00%] [G loss: 3.069991]\n",
      "722 [D loss: 1.785067, acc.: 50.00%] [G loss: 3.592583]\n",
      "723 [D loss: 1.786736, acc.: 50.00%] [G loss: 3.493504]\n",
      "724 [D loss: 1.576259, acc.: 50.00%] [G loss: 3.498140]\n",
      "725 [D loss: 1.575783, acc.: 50.00%] [G loss: 3.440674]\n",
      "726 [D loss: 1.618428, acc.: 50.00%] [G loss: 3.338176]\n",
      "727 [D loss: 1.870024, acc.: 50.00%] [G loss: 3.427020]\n",
      "728 [D loss: 1.672649, acc.: 50.00%] [G loss: 3.237443]\n",
      "729 [D loss: 1.756462, acc.: 50.00%] [G loss: 3.320148]\n",
      "730 [D loss: 1.649713, acc.: 50.00%] [G loss: 3.363993]\n",
      "731 [D loss: 1.606930, acc.: 50.00%] [G loss: 3.105774]\n",
      "732 [D loss: 1.605988, acc.: 50.00%] [G loss: 3.308470]\n",
      "733 [D loss: 1.552245, acc.: 50.00%] [G loss: 3.565699]\n",
      "734 [D loss: 1.604462, acc.: 50.00%] [G loss: 3.199215]\n",
      "735 [D loss: 1.691211, acc.: 50.00%] [G loss: 3.534374]\n",
      "736 [D loss: 1.510296, acc.: 50.00%] [G loss: 3.212000]\n",
      "737 [D loss: 1.784826, acc.: 50.00%] [G loss: 3.094915]\n",
      "738 [D loss: 1.734852, acc.: 50.00%] [G loss: 3.243803]\n",
      "739 [D loss: 1.673956, acc.: 50.00%] [G loss: 3.443972]\n",
      "740 [D loss: 1.675923, acc.: 50.00%] [G loss: 3.140043]\n",
      "741 [D loss: 1.584335, acc.: 50.00%] [G loss: 3.648565]\n",
      "742 [D loss: 1.676807, acc.: 50.00%] [G loss: 3.225821]\n",
      "743 [D loss: 1.750042, acc.: 50.00%] [G loss: 3.212344]\n",
      "744 [D loss: 1.869645, acc.: 50.00%] [G loss: 3.351973]\n",
      "745 [D loss: 1.596626, acc.: 50.00%] [G loss: 3.357402]\n",
      "746 [D loss: 1.678656, acc.: 50.00%] [G loss: 3.225795]\n",
      "747 [D loss: 1.659941, acc.: 50.00%] [G loss: 3.116673]\n",
      "748 [D loss: 1.675393, acc.: 50.00%] [G loss: 3.495342]\n",
      "749 [D loss: 1.691882, acc.: 50.00%] [G loss: 3.159393]\n",
      "750 [D loss: 1.718645, acc.: 50.00%] [G loss: 3.661609]\n",
      "751 [D loss: 1.664461, acc.: 50.00%] [G loss: 3.317266]\n",
      "752 [D loss: 1.544491, acc.: 50.00%] [G loss: 3.561275]\n",
      "753 [D loss: 1.690599, acc.: 50.00%] [G loss: 3.349564]\n",
      "754 [D loss: 1.618027, acc.: 50.00%] [G loss: 3.480473]\n",
      "755 [D loss: 1.626141, acc.: 50.00%] [G loss: 3.416145]\n",
      "756 [D loss: 1.556266, acc.: 50.00%] [G loss: 3.641161]\n",
      "757 [D loss: 1.602352, acc.: 50.00%] [G loss: 3.662478]\n",
      "758 [D loss: 1.565742, acc.: 50.00%] [G loss: 3.104377]\n",
      "759 [D loss: 1.580618, acc.: 50.00%] [G loss: 3.117448]\n",
      "760 [D loss: 1.612927, acc.: 50.00%] [G loss: 3.193656]\n",
      "761 [D loss: 1.564995, acc.: 50.00%] [G loss: 3.065677]\n",
      "762 [D loss: 1.707505, acc.: 50.00%] [G loss: 3.269740]\n",
      "763 [D loss: 1.545933, acc.: 50.00%] [G loss: 3.410348]\n",
      "764 [D loss: 1.608982, acc.: 50.00%] [G loss: 3.405693]\n",
      "765 [D loss: 1.645888, acc.: 50.00%] [G loss: 3.553249]\n",
      "766 [D loss: 1.653511, acc.: 50.00%] [G loss: 3.253019]\n",
      "767 [D loss: 1.788457, acc.: 50.00%] [G loss: 3.336159]\n",
      "768 [D loss: 1.466204, acc.: 50.00%] [G loss: 3.292351]\n",
      "769 [D loss: 1.566394, acc.: 50.00%] [G loss: 3.872264]\n",
      "770 [D loss: 1.655201, acc.: 50.00%] [G loss: 3.133327]\n",
      "771 [D loss: 1.707538, acc.: 50.00%] [G loss: 3.183639]\n",
      "772 [D loss: 1.546169, acc.: 50.00%] [G loss: 3.381202]\n",
      "773 [D loss: 1.605733, acc.: 50.00%] [G loss: 3.366122]\n",
      "774 [D loss: 1.677839, acc.: 50.00%] [G loss: 3.402981]\n",
      "775 [D loss: 1.660693, acc.: 50.00%] [G loss: 3.231908]\n",
      "776 [D loss: 1.649422, acc.: 50.00%] [G loss: 3.264876]\n",
      "777 [D loss: 1.639823, acc.: 50.00%] [G loss: 3.051737]\n",
      "778 [D loss: 1.696562, acc.: 50.00%] [G loss: 3.237603]\n",
      "779 [D loss: 1.683753, acc.: 50.00%] [G loss: 3.568535]\n",
      "780 [D loss: 1.621579, acc.: 50.00%] [G loss: 3.175599]\n",
      "781 [D loss: 1.568550, acc.: 50.00%] [G loss: 3.032377]\n",
      "782 [D loss: 1.636545, acc.: 50.00%] [G loss: 3.184147]\n",
      "783 [D loss: 1.583996, acc.: 50.00%] [G loss: 3.140364]\n",
      "784 [D loss: 1.600512, acc.: 50.00%] [G loss: 3.435825]\n",
      "785 [D loss: 1.999450, acc.: 50.00%] [G loss: 3.177021]\n",
      "786 [D loss: 1.622081, acc.: 50.00%] [G loss: 3.211910]\n",
      "787 [D loss: 1.607219, acc.: 50.00%] [G loss: 2.958045]\n",
      "788 [D loss: 1.662733, acc.: 50.00%] [G loss: 2.936817]\n",
      "789 [D loss: 1.625128, acc.: 50.00%] [G loss: 3.139902]\n",
      "790 [D loss: 1.751674, acc.: 50.00%] [G loss: 3.173905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791 [D loss: 1.689819, acc.: 50.00%] [G loss: 3.035753]\n",
      "792 [D loss: 1.606588, acc.: 50.00%] [G loss: 3.164282]\n",
      "793 [D loss: 1.678192, acc.: 50.00%] [G loss: 3.064244]\n",
      "794 [D loss: 1.554057, acc.: 50.00%] [G loss: 3.338873]\n",
      "795 [D loss: 1.606869, acc.: 50.00%] [G loss: 3.330568]\n",
      "796 [D loss: 1.603748, acc.: 50.00%] [G loss: 3.114733]\n",
      "797 [D loss: 1.644455, acc.: 50.00%] [G loss: 3.161070]\n",
      "798 [D loss: 1.815571, acc.: 50.00%] [G loss: 3.118551]\n",
      "799 [D loss: 1.663989, acc.: 50.00%] [G loss: 2.973483]\n",
      "800 [D loss: 1.638378, acc.: 50.00%] [G loss: 3.525602]\n",
      "801 [D loss: 1.555400, acc.: 50.00%] [G loss: 3.292119]\n",
      "802 [D loss: 1.665119, acc.: 50.00%] [G loss: 2.883109]\n",
      "803 [D loss: 1.527235, acc.: 50.00%] [G loss: 3.179940]\n",
      "804 [D loss: 1.638663, acc.: 50.00%] [G loss: 3.214832]\n",
      "805 [D loss: 1.598825, acc.: 50.00%] [G loss: 3.131518]\n",
      "806 [D loss: 1.754489, acc.: 50.00%] [G loss: 3.098774]\n",
      "807 [D loss: 1.674980, acc.: 50.00%] [G loss: 3.170163]\n",
      "808 [D loss: 1.621109, acc.: 50.00%] [G loss: 2.944468]\n",
      "809 [D loss: 1.603861, acc.: 50.00%] [G loss: 3.080955]\n",
      "810 [D loss: 1.936487, acc.: 50.00%] [G loss: 3.017865]\n",
      "811 [D loss: 1.546198, acc.: 50.00%] [G loss: 3.236646]\n",
      "812 [D loss: 1.579353, acc.: 50.00%] [G loss: 3.085418]\n",
      "813 [D loss: 1.561227, acc.: 50.00%] [G loss: 3.158551]\n",
      "814 [D loss: 1.696003, acc.: 50.00%] [G loss: 3.514064]\n",
      "815 [D loss: 1.491004, acc.: 50.00%] [G loss: 2.956197]\n",
      "816 [D loss: 1.538256, acc.: 50.00%] [G loss: 3.757041]\n",
      "817 [D loss: 1.485335, acc.: 50.00%] [G loss: 3.358967]\n",
      "818 [D loss: 1.728765, acc.: 50.00%] [G loss: 2.787815]\n",
      "819 [D loss: 1.536234, acc.: 50.00%] [G loss: 3.310485]\n",
      "820 [D loss: 1.490094, acc.: 50.00%] [G loss: 3.561854]\n",
      "821 [D loss: 1.616057, acc.: 50.00%] [G loss: 3.116265]\n",
      "822 [D loss: 1.708875, acc.: 50.00%] [G loss: 3.131954]\n",
      "823 [D loss: 1.653032, acc.: 50.00%] [G loss: 3.020960]\n",
      "824 [D loss: 1.615533, acc.: 50.00%] [G loss: 3.029034]\n",
      "825 [D loss: 1.685618, acc.: 50.00%] [G loss: 3.329387]\n",
      "826 [D loss: 1.624600, acc.: 50.00%] [G loss: 3.322995]\n",
      "827 [D loss: 1.482583, acc.: 50.00%] [G loss: 3.176591]\n",
      "828 [D loss: 1.791513, acc.: 50.00%] [G loss: 3.323184]\n",
      "829 [D loss: 1.605728, acc.: 50.00%] [G loss: 2.998091]\n",
      "830 [D loss: 1.613683, acc.: 50.00%] [G loss: 2.970587]\n",
      "831 [D loss: 1.807697, acc.: 50.00%] [G loss: 2.971869]\n",
      "832 [D loss: 1.624297, acc.: 50.00%] [G loss: 3.057151]\n",
      "833 [D loss: 1.683821, acc.: 50.00%] [G loss: 3.261941]\n",
      "834 [D loss: 1.607754, acc.: 50.00%] [G loss: 3.122285]\n",
      "835 [D loss: 1.597754, acc.: 50.00%] [G loss: 3.067437]\n",
      "836 [D loss: 1.547140, acc.: 50.00%] [G loss: 2.940226]\n",
      "837 [D loss: 1.683660, acc.: 50.00%] [G loss: 3.138284]\n",
      "838 [D loss: 1.576027, acc.: 50.00%] [G loss: 3.051974]\n",
      "839 [D loss: 1.571083, acc.: 50.00%] [G loss: 3.051405]\n",
      "840 [D loss: 1.556092, acc.: 50.00%] [G loss: 2.776192]\n",
      "841 [D loss: 1.625218, acc.: 50.00%] [G loss: 3.007761]\n",
      "842 [D loss: 1.706707, acc.: 50.00%] [G loss: 3.124563]\n",
      "843 [D loss: 1.587394, acc.: 50.00%] [G loss: 3.836933]\n",
      "844 [D loss: 1.662416, acc.: 50.00%] [G loss: 2.932974]\n",
      "845 [D loss: 1.668130, acc.: 50.00%] [G loss: 2.908917]\n",
      "846 [D loss: 1.642879, acc.: 50.00%] [G loss: 3.030175]\n",
      "847 [D loss: 1.667641, acc.: 50.00%] [G loss: 4.010356]\n",
      "848 [D loss: 1.714663, acc.: 50.00%] [G loss: 3.140152]\n",
      "849 [D loss: 1.530524, acc.: 50.00%] [G loss: 3.819906]\n",
      "850 [D loss: 1.574641, acc.: 50.00%] [G loss: 3.198971]\n",
      "851 [D loss: 1.660278, acc.: 50.00%] [G loss: 3.789744]\n",
      "852 [D loss: 1.806194, acc.: 50.00%] [G loss: 3.070424]\n",
      "853 [D loss: 1.642564, acc.: 50.00%] [G loss: 3.683067]\n",
      "854 [D loss: 1.512880, acc.: 50.00%] [G loss: 3.058567]\n",
      "855 [D loss: 1.498999, acc.: 50.00%] [G loss: 3.254220]\n",
      "856 [D loss: 1.559853, acc.: 50.00%] [G loss: 2.768444]\n",
      "857 [D loss: 1.562111, acc.: 50.00%] [G loss: 3.199603]\n",
      "858 [D loss: 1.683556, acc.: 50.00%] [G loss: 2.821262]\n",
      "859 [D loss: 1.686031, acc.: 50.00%] [G loss: 3.119457]\n",
      "860 [D loss: 1.654993, acc.: 50.00%] [G loss: 4.554053]\n",
      "861 [D loss: 1.687513, acc.: 50.00%] [G loss: 3.175752]\n",
      "862 [D loss: 1.455415, acc.: 50.00%] [G loss: 3.074143]\n",
      "863 [D loss: 1.612914, acc.: 50.00%] [G loss: 2.815497]\n",
      "864 [D loss: 1.681988, acc.: 50.00%] [G loss: 3.455669]\n",
      "865 [D loss: 1.555828, acc.: 50.00%] [G loss: 2.964052]\n",
      "866 [D loss: 1.646112, acc.: 50.00%] [G loss: 3.362575]\n",
      "867 [D loss: 1.637119, acc.: 50.00%] [G loss: 3.677637]\n",
      "868 [D loss: 1.584361, acc.: 50.00%] [G loss: 2.903839]\n",
      "869 [D loss: 1.547208, acc.: 50.00%] [G loss: 2.868742]\n",
      "870 [D loss: 1.586012, acc.: 50.00%] [G loss: 3.042407]\n",
      "871 [D loss: 1.626338, acc.: 50.00%] [G loss: 3.297417]\n",
      "872 [D loss: 1.508256, acc.: 50.00%] [G loss: 3.349762]\n",
      "873 [D loss: 1.507641, acc.: 50.00%] [G loss: 2.917718]\n",
      "874 [D loss: 1.589455, acc.: 50.00%] [G loss: 3.355272]\n",
      "875 [D loss: 1.620688, acc.: 50.00%] [G loss: 3.279170]\n",
      "876 [D loss: 1.625092, acc.: 50.00%] [G loss: 2.863557]\n",
      "877 [D loss: 1.520416, acc.: 50.00%] [G loss: 3.451073]\n",
      "878 [D loss: 1.573627, acc.: 50.00%] [G loss: 2.950847]\n",
      "879 [D loss: 1.595157, acc.: 50.00%] [G loss: 3.052036]\n",
      "880 [D loss: 1.457669, acc.: 50.00%] [G loss: 3.206954]\n",
      "881 [D loss: 1.420310, acc.: 50.00%] [G loss: 3.120369]\n",
      "882 [D loss: 1.773978, acc.: 50.00%] [G loss: 3.038260]\n",
      "883 [D loss: 1.473694, acc.: 50.00%] [G loss: 3.478909]\n",
      "884 [D loss: 1.377327, acc.: 50.00%] [G loss: 3.196473]\n",
      "885 [D loss: 1.699363, acc.: 50.00%] [G loss: 3.310581]\n",
      "886 [D loss: 1.645447, acc.: 50.00%] [G loss: 3.270068]\n",
      "887 [D loss: 1.597326, acc.: 50.00%] [G loss: 3.120742]\n",
      "888 [D loss: 1.489694, acc.: 50.00%] [G loss: 3.618913]\n",
      "889 [D loss: 1.566623, acc.: 50.00%] [G loss: 2.943758]\n",
      "890 [D loss: 1.466953, acc.: 50.00%] [G loss: 3.493838]\n",
      "891 [D loss: 1.614619, acc.: 50.00%] [G loss: 3.168268]\n",
      "892 [D loss: 1.555712, acc.: 50.00%] [G loss: 3.407304]\n",
      "893 [D loss: 1.464551, acc.: 50.00%] [G loss: 2.973469]\n",
      "894 [D loss: 1.622522, acc.: 50.00%] [G loss: 3.219990]\n",
      "895 [D loss: 1.629339, acc.: 50.00%] [G loss: 3.241007]\n",
      "896 [D loss: 1.555198, acc.: 50.00%] [G loss: 3.517865]\n",
      "897 [D loss: 1.564885, acc.: 50.00%] [G loss: 3.005370]\n",
      "898 [D loss: 1.560462, acc.: 50.00%] [G loss: 2.915500]\n",
      "899 [D loss: 1.622501, acc.: 50.00%] [G loss: 3.189136]\n",
      "900 [D loss: 1.480139, acc.: 50.00%] [G loss: 3.251774]\n",
      "901 [D loss: 1.490851, acc.: 50.00%] [G loss: 2.758306]\n",
      "902 [D loss: 1.536632, acc.: 50.00%] [G loss: 3.284002]\n",
      "903 [D loss: 1.445478, acc.: 50.00%] [G loss: 2.989367]\n",
      "904 [D loss: 1.475311, acc.: 50.00%] [G loss: 3.083747]\n",
      "905 [D loss: 1.454205, acc.: 50.00%] [G loss: 3.348904]\n",
      "906 [D loss: 1.701917, acc.: 50.00%] [G loss: 2.745756]\n",
      "907 [D loss: 1.474762, acc.: 50.00%] [G loss: 3.240897]\n",
      "908 [D loss: 1.578294, acc.: 50.00%] [G loss: 3.001725]\n",
      "909 [D loss: 1.361937, acc.: 50.00%] [G loss: 2.828237]\n",
      "910 [D loss: 1.561420, acc.: 50.00%] [G loss: 2.990115]\n",
      "911 [D loss: 1.478395, acc.: 50.00%] [G loss: 2.821504]\n",
      "912 [D loss: 1.489911, acc.: 50.00%] [G loss: 3.292161]\n",
      "913 [D loss: 1.615783, acc.: 50.00%] [G loss: 3.426880]\n",
      "914 [D loss: 1.629272, acc.: 50.00%] [G loss: 2.895288]\n",
      "915 [D loss: 1.551341, acc.: 50.00%] [G loss: 2.834712]\n",
      "916 [D loss: 1.486309, acc.: 50.00%] [G loss: 2.860889]\n",
      "917 [D loss: 1.536338, acc.: 50.00%] [G loss: 3.160210]\n",
      "918 [D loss: 1.620843, acc.: 50.00%] [G loss: 3.109876]\n",
      "919 [D loss: 1.511479, acc.: 50.00%] [G loss: 3.288114]\n",
      "920 [D loss: 1.508664, acc.: 50.00%] [G loss: 3.005651]\n",
      "921 [D loss: 1.500197, acc.: 50.00%] [G loss: 3.091627]\n",
      "922 [D loss: 1.565373, acc.: 50.00%] [G loss: 3.253539]\n",
      "923 [D loss: 1.563678, acc.: 50.00%] [G loss: 3.258438]\n",
      "924 [D loss: 1.617386, acc.: 50.00%] [G loss: 3.530190]\n",
      "925 [D loss: 1.573457, acc.: 50.00%] [G loss: 2.688699]\n",
      "926 [D loss: 1.490555, acc.: 50.00%] [G loss: 2.939496]\n",
      "927 [D loss: 1.452044, acc.: 50.00%] [G loss: 3.274321]\n",
      "928 [D loss: 1.467002, acc.: 50.00%] [G loss: 3.497302]\n",
      "929 [D loss: 1.455756, acc.: 50.00%] [G loss: 2.744773]\n",
      "930 [D loss: 1.611422, acc.: 50.00%] [G loss: 3.001640]\n",
      "931 [D loss: 1.703225, acc.: 50.00%] [G loss: 3.533607]\n",
      "932 [D loss: 1.630103, acc.: 50.00%] [G loss: 3.533757]\n",
      "933 [D loss: 1.532431, acc.: 50.00%] [G loss: 2.974214]\n",
      "934 [D loss: 1.504925, acc.: 50.00%] [G loss: 2.825887]\n",
      "935 [D loss: 1.618494, acc.: 50.00%] [G loss: 3.135936]\n",
      "936 [D loss: 1.559443, acc.: 50.00%] [G loss: 3.087320]\n",
      "937 [D loss: 1.449519, acc.: 50.00%] [G loss: 2.933544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 [D loss: 1.619891, acc.: 50.00%] [G loss: 2.957844]\n",
      "939 [D loss: 1.724196, acc.: 50.00%] [G loss: 3.084551]\n",
      "940 [D loss: 1.705757, acc.: 50.00%] [G loss: 3.106049]\n",
      "941 [D loss: 1.512157, acc.: 50.00%] [G loss: 3.037138]\n",
      "942 [D loss: 1.659788, acc.: 50.00%] [G loss: 2.824077]\n",
      "943 [D loss: 1.535586, acc.: 50.00%] [G loss: 2.918664]\n",
      "944 [D loss: 1.531354, acc.: 50.00%] [G loss: 3.491662]\n",
      "945 [D loss: 1.644020, acc.: 50.00%] [G loss: 3.275450]\n",
      "946 [D loss: 1.735662, acc.: 50.00%] [G loss: 2.724183]\n",
      "947 [D loss: 1.571554, acc.: 50.00%] [G loss: 2.961546]\n",
      "948 [D loss: 1.454587, acc.: 50.00%] [G loss: 2.983495]\n",
      "949 [D loss: 1.441155, acc.: 50.00%] [G loss: 2.783501]\n",
      "950 [D loss: 1.640263, acc.: 50.00%] [G loss: 3.031682]\n",
      "951 [D loss: 1.551210, acc.: 50.00%] [G loss: 3.175784]\n",
      "952 [D loss: 1.487708, acc.: 50.00%] [G loss: 3.000450]\n",
      "953 [D loss: 1.530308, acc.: 50.00%] [G loss: 3.297256]\n",
      "954 [D loss: 1.451642, acc.: 50.00%] [G loss: 3.055366]\n",
      "955 [D loss: 1.565704, acc.: 50.00%] [G loss: 3.423577]\n",
      "956 [D loss: 1.453412, acc.: 50.00%] [G loss: 3.227542]\n",
      "957 [D loss: 1.610211, acc.: 50.00%] [G loss: 2.835820]\n",
      "958 [D loss: 1.583141, acc.: 50.00%] [G loss: 2.825119]\n",
      "959 [D loss: 1.545106, acc.: 50.00%] [G loss: 3.081315]\n",
      "960 [D loss: 1.490674, acc.: 50.00%] [G loss: 2.710934]\n",
      "961 [D loss: 1.529194, acc.: 50.00%] [G loss: 2.761720]\n",
      "962 [D loss: 1.489785, acc.: 50.00%] [G loss: 2.932857]\n",
      "963 [D loss: 1.522004, acc.: 50.00%] [G loss: 3.006991]\n",
      "964 [D loss: 1.407935, acc.: 50.00%] [G loss: 2.933294]\n",
      "965 [D loss: 1.519809, acc.: 50.00%] [G loss: 2.944373]\n",
      "966 [D loss: 1.576045, acc.: 50.00%] [G loss: 3.197225]\n",
      "967 [D loss: 1.534069, acc.: 50.00%] [G loss: 3.454596]\n",
      "968 [D loss: 1.549278, acc.: 50.00%] [G loss: 2.996158]\n",
      "969 [D loss: 1.626163, acc.: 50.00%] [G loss: 3.186615]\n",
      "970 [D loss: 1.605087, acc.: 50.00%] [G loss: 3.226090]\n",
      "971 [D loss: 1.645951, acc.: 50.00%] [G loss: 3.339131]\n",
      "972 [D loss: 1.587563, acc.: 50.00%] [G loss: 2.713449]\n",
      "973 [D loss: 1.578440, acc.: 50.00%] [G loss: 2.886399]\n",
      "974 [D loss: 1.559637, acc.: 50.00%] [G loss: 3.133509]\n",
      "975 [D loss: 1.408581, acc.: 50.00%] [G loss: 3.463957]\n",
      "976 [D loss: 1.507182, acc.: 50.00%] [G loss: 3.050616]\n",
      "977 [D loss: 1.722095, acc.: 50.00%] [G loss: 3.020258]\n",
      "978 [D loss: 1.520942, acc.: 50.00%] [G loss: 3.118543]\n",
      "979 [D loss: 1.514625, acc.: 50.00%] [G loss: 3.295727]\n",
      "980 [D loss: 1.514354, acc.: 50.00%] [G loss: 3.476587]\n",
      "981 [D loss: 1.325754, acc.: 50.00%] [G loss: 3.090273]\n",
      "982 [D loss: 1.543600, acc.: 50.00%] [G loss: 3.402343]\n",
      "983 [D loss: 1.380497, acc.: 50.00%] [G loss: 3.151261]\n",
      "984 [D loss: 1.421719, acc.: 50.00%] [G loss: 3.000857]\n",
      "985 [D loss: 1.663469, acc.: 50.00%] [G loss: 2.805533]\n",
      "986 [D loss: 1.602834, acc.: 50.00%] [G loss: 2.725386]\n",
      "987 [D loss: 1.459830, acc.: 50.00%] [G loss: 2.870372]\n",
      "988 [D loss: 1.659254, acc.: 50.00%] [G loss: 3.096758]\n",
      "989 [D loss: 1.590494, acc.: 50.00%] [G loss: 2.959643]\n",
      "990 [D loss: 1.433594, acc.: 50.00%] [G loss: 2.851885]\n",
      "991 [D loss: 1.474837, acc.: 50.00%] [G loss: 2.900964]\n",
      "992 [D loss: 1.422600, acc.: 50.00%] [G loss: 3.516919]\n",
      "993 [D loss: 1.394493, acc.: 50.00%] [G loss: 3.295116]\n",
      "994 [D loss: 1.514878, acc.: 50.00%] [G loss: 3.072505]\n",
      "995 [D loss: 1.525787, acc.: 50.00%] [G loss: 3.165932]\n",
      "996 [D loss: 1.552431, acc.: 50.00%] [G loss: 2.971045]\n",
      "997 [D loss: 1.445063, acc.: 50.00%] [G loss: 2.977590]\n",
      "998 [D loss: 1.578200, acc.: 50.00%] [G loss: 3.313880]\n",
      "999 [D loss: 1.466483, acc.: 50.00%] [G loss: 3.025506]\n"
     ]
    }
   ],
   "source": [
    "lstmgan = LSTMGAN()\n",
    "lstmgan.train(epochs=1000, batch_size=20, save_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0h 37m 4s\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "\n",
    "diff = (end - start)\n",
    "\n",
    "datetime.timedelta(seconds=10, microseconds=885206)\n",
    "\n",
    "diff_seconds = int(diff.total_seconds())\n",
    "\n",
    "minute_seconds, seconds = divmod(diff_seconds, 60)\n",
    "hours, minutes = divmod(minute_seconds, 60)\n",
    "hms = f\"{hours}h {minutes}m {seconds}s\"\n",
    "\n",
    "'0h 0m 10s'\n",
    "print(hms) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lstmgan.train(epochs=1000, batch_size=20, save_interval=100)\n",
    "\n",
    "FailedPreconditionError:  Error while reading resource variable _AnonymousVar401 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar401/class tensorflow::Var does not exist.\n",
    "\t [[node mul_296/ReadVariableOp (defined at C:\\Users\\Admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_55197]\n",
    "\n",
    "Function call stack:\n",
    "keras_scratch_graph\n",
    "\n",
    "FailedPreconditionError reSOLVED BY\n",
    "\n",
    "#https://github.com/keras-team/keras/issues/13550\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "like this\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[0.000e+00, 3.836e-07, 2.875e-04, ..., 0.000e+00, 1.000e+00,\n",
      "         0.000e+00]],\n",
      "\n",
      "       [[0.000e+00, 4.125e-07, 1.390e-04, ..., 0.000e+00, 1.000e+00,\n",
      "         0.000e+00]],\n",
      "\n",
      "       [[0.000e+00, 2.610e-07, 3.408e-04, ..., 0.000e+00, 1.000e+00,\n",
      "         0.000e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.000e+00, 4.226e-07, 2.216e-03, ..., 0.000e+00, 1.000e+00,\n",
      "         0.000e+00]],\n",
      "\n",
      "       [[0.000e+00, 4.630e-07, 1.138e-04, ..., 0.000e+00, 1.000e+00,\n",
      "         0.000e+00]],\n",
      "\n",
      "       [[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
      "         0.000e+00]]], dtype=float32)]\n",
      "(1, 40000, 1, 118)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "hidden_layers = keras.backend.function(\n",
    "[lstmgan.discriminator.layers[0].input],  # we will feed the function with the input of the first layer  \n",
    "[lstmgan.discriminator.layers[0].output,] # we want to get the output of the first layer\n",
    ")\n",
    "h=hidden_layers([df_train])\n",
    "print(h)\n",
    "print(np.shape(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=np.array(h)  \n",
    "\n",
    "arr_reshaped = np.array(h).reshape(40000, df_train.shape[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 118)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(arr_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('normal1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.000e+00 4.125e-07 1.390e-04 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 5.871e-03 5.871e-03\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "   1.059e-01 8.941e-01 1.000e+00 0.000e+00 4.000e-02 3.000e-02 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "#To check 1st row\n",
    "print(h[:,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_1 = pd.read_csv('normal1.csv')\n",
    "csv_2 = pd.read_csv('normallabel1.csv')\n",
    "\n",
    "result = pd.concat([csv_1, csv_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"lgcnormalresult.csv\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23c4cc86fc8>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['gen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23c4cc4b208>,\n",
       " <matplotlib.lines.Line2D at 0x23c4cc4b388>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD9CAYAAAB3ECbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXzU9YH/8ddMLnITQoBw3x+5BQRUFIq21GM9KPVqXetq1Vat6233111b11qtWtutW++rlqqt1aqodK0CoqjIpcj14RAId0II5D5nfn/MkZnJJDMJCZlJ3s/Hw4dzfGfm8yHwnk8+p8PtdiMiIvHB2dkFEBGR6Cm0RUTiiEJbRCSOKLRFROKIQltEJI4otEVE4khipAuMMVcAtwY8lA0MBAZaaw92VMFERKQpR2vmaRtjkoBlwAvW2icjXJ4CTAP2Aw1tLqGISPeSAOQDK4Ga0CcjtrRD3AUURhHY4Ansj1r5/iIi4nE68HHog1GHtjGmN3AbMDXKl+wHKCmpwOVq26rL3NwMiovL2/TaeNTd6guqc3ehOkfP6XSQk5MO3gwNFXX3iDHm/wGjrbVXRvnZQ4EdUV4rIiLBhgE7Qx9sTffIJcBNrf3U4uLyNre08/IyKSoqa9Nr41F3qy+ozt2F6hw9p9NBbm5G889H8ybGmBxgJPBJq0sgIiLtJtp52iOB/dbauo4sjIiItCyq7hFr7Uo8wS0iIp1IKyJFROKIQltEJI7EZGgfLa/hjseWs6ewe402i4hEEpOhfbishuLSGvYdqujsooiIxJSYDG0/HV8pIhIkJkPb4ejsEoiIxKaYDG0fnRQvIhIsJkPbgaeprcgWEQkWk6Hto4a2iEiwmAztxj5tpbaISKCYDG0ftbRFRILFZGg7HOrTFhEJJzZD23dDqS0iEiQmQ9uX2m6ltohIkJgMba2tEREJLyZD20cDkSIiwWIztB3+/hEREQkQk6Ht6x5Rn7aISLDYDG1fQ1uZLSISJCZD20eZLSISLCZD26GmtohIWLEZ2t7/K7JFRILFZGijhraISFiJ0VxkjJkAPApkAw3Addba1R1VKC2uEREJL2JL2xiTBrwHPGitnQzcC/y5owvmoaa2iEigaFrac4Ht1tp3vfffAnZ0XJHwz/lT94iISLBoQns0cMAY8ywwCTgC3BntB+TmZrS6UA1Ozy8Abjfk5WW2+vXxrLvVF1Tn7kJ1bh/RhHYScA4wx1q7whhzAfCuMWaItbYm0ouLi8txuVrXZC45UuW95aaoqKxVr41neXmZ3aq+oDp3F6pz9JxOR4uN3Whmj+wDNllrVwBYa98EEoDhrS5NtDR7REQkrGhCexEwzBgzFcAYMwvPCGGH9WvrNHYRkfAido9Yaw8YYy4EHjPGpAM1wHestdUdVSgtiBQRCS+qedrW2mXAjA4uSxhKbRGRQDG5ItK/94iIiASJydD2UfeIiEiw2A7tzi6AiEiMicnQ9veOqKktIhIkNkPb+39FtohIsJgMbe09IiISXkyGtn/uiFJbRCRITIa2fxl755ZCRCTmxGRoaxxSRCS82AxtX5+22toiIkFiMrRFRCS82A5tNbRFRILEZGg7NBApIhJWbIa29/8aiBQRCRaToa01kSIi4cVkaOsQBBGR8GIytH0U2iIiwWIytBvPQFBqi4gEis3QRhtGiYiEE5OhjU4bExEJKzZD20sNbRGRYDEZ2o3ztBXbIiKBYjO01T0iIhJWYjQXGWN+A1wEHPY+ZK21l3RYqTQQKSISVlShDZwKXGqt/aQjC+PTuPeIUltEJFDE0DbGpACTgTuNMSOALcAt1tqCji6cMltEJFg0Le3+wGLgP4ENwO3Am8aYKdbaiLGam5vR6kI1NLgAT2bn5WW2+vXxrLvVF1Tn7kJ1bh8RQ9tauwM4x3ffGPMw8F/AUGBHpNcXF5fjcrWuyey73u2GoqKyVr02nuXlZXar+oLq3F2oztFzOh0tNnYjzh4xxkw0xvxryMMOoK7VpYmWZo+IiIQVzZQ/F/B7Y8ww7/0fA+ustXs6rlhemj4iIhIkYmhba9cDPwEWGmM2AfOAyzqyUNpNW0QkvKim/FlrFwALOrgsfv7T2JXaIiJBYnJFpI/maYuIBIvZ0HaA+kdERELEbGjjUGaLiISK2dB24NAufyIiIWI3tDVXW0SkiZgNbdDsERGRUDEd2iIiEixmQ9vh0Mk1IiKhYja0tQGJiEhTMRvanpZ2Z5dCRCS2xG5oo3naIiKhYja0UZ+2iEgTMRvaDvVpi4g0EbOhjfq0RUSaiNnQ9vRpK7VFRALFbmird0REpImYDW1A00dERELEcGg7lNkiIiFiNrQdaMqfiEio2A1tra4REWkiZkMblNkiIqFiNrQdDp1cIyISKurQNsZcaIwp68jChHr3k518tG7f8fxIEZGYFlVoG2NGAQ9zHPdLbXB5WtnPv7v5eH2kiEjMixjaxpg0YAFwa8cXp1F1bT0ACU6tshER8Ymmpf2k9791HVyWIL7u7MSEmO12FxE57hJbetIYcz1Qb619zhgztC0fkJub0ZaX+SUlOsnLyzym94gn3amuPqpz96A6t48WQxu4EkgzxnwBJAOp3tvnWGujGiEsLi7H5Wr7LJAEp4OiouM6/tlp8vIyu01dfVTn7kF1jp7T6WixsdtiaFtrp/tue1va6621J7a6FMdA3SMiIo1iPhETE2O+iCIix02k7hE/a+1O4Ng6qNsgMUGzR0REfGK+GavuERGRRjGfiJXVdazYeLCziyEiEhNiPrSLjlTz5FsbqKqp7+yiiIh0upgPbZ/q2obOLoKISKeL2dC+Yd74oPs1dQptEZGYDe2ppg8/vWKa/75vLxIRke4sZkMbYOak/pxk8gCorlFLW0QkpkMb4OyThwDq0xYRgTgI7ZSkBACq69Q9IiIS86Gd5F3GXl+vo8dERGI+tH0rIrfsPsLnm7TIRkS6t5gPbV9L++Ov9vPEmxs6uTQiIp0r9kNbe4+IiPjFfCImJmqXPxERn5gP7QSnE4dyW0QEiIPQhsZ+bRGR7i4u0lD92iIiHnGRhoEHIbjcmq8tIt1XXIR2YPdIQ4NCW0S6r7gI7f690/236xtcnVgSEZHOFRehPXJAtv92g6vllvaf/7mFTzcc6OgiiYh0irgI7V5ZKf7bDRFa2h+s3sPTCzd2dJFERDpFXIR2TmYP/+16b5/28q/2c/BwZbt9xqtLtvGZWugiEuMSo7nIGHMj8GPADWwHrrHWFnZkwQJlpiX5b1fX1uN2u3n2nU2kpiTyh1tmtctnLFpRAMDJ4/q1y/uJiHSEiC1tY8xU4HbgVGvteGArcG9HFyxQZmpjaP9t6Xb/YKROaBeR7iZiaFtrVwOjrLVHjTE9gAFAcYeXLEB6QGhvKiihqpmjx9yawy0iXVxU3SPW2jpjzIXAM0ANcHe0H5Cbm9HGonnk5WUG3a+tc7F848Gwz9fVu5p9XVs/73jr7M/vDKpz96A6t4+oQhvAWvsG8IYx5hrg/4wxI621ESdNFxeX44owTa85eXmZFBWVAfDozadTUlrD3c99zqsfbPVf43v+k/X7OVpR2+Tx1mrr69pDYH27C9W5e1Cdo+d0Olps7EYMbWPMSKCftfZj70PPAU8AORzHbpL0HkmkpoQv7sHDlTzz9qbjVRQRkU4TzZS/fOAVY0xv7/3vA+uttce1XxvA6XAweVTvJo///aOvj3dRREQ6RTQDkR8B9wFLjTFfAJcCF3Z0wZrzk/kT2+299h6qoKSshpra8AObIiKxJtqByMeBxzu4LG3y6pJtVDYz9W/bnqOkpyaSn5se9vn/emZFRxZNRKTdxcWKyFDnnTrUf3vRigLWf3047HW/WrCanz3tCeZ/rCjgqgcW+7d21fRAEYlHcRna82YN54nbZrd4zaZdJUH3/7Z0OwBbCo5w+2PLKa2sC/u6+gYXT761gYMl7bdEXkSkvcRlaAMkJyXgbObwyKy0JB56ea3/fmCr+tWl2zhcWsN7nxeEfe2C97awYuNBXvyHbXPZNu08zI8f+ZDK6vBfDCIibRW3oQ0wND/8xPXQVvQdj3/i7xaprfNMLfftNRJq2Zf7ANo8txzgzeU7qaltoOBgeZvfQ0QknLgO7Zu+G91MksOlNf7bew9VRPWahg7o875/wWoWLt8R9fUPvbyW/3jy03Yvh4jEr7gO7ay0ZP/ti74xAgg+5eZYuF1u6htcPPjSGrbvO9ou77l1z1H+/lH0ob1pVwkHS6ra5bNFpGuI69AGuPTMUeT17EFutmfP7d7ZPSK8wiPBGb4/3MfldrPvUAWbC47wx0WR+7fXbili5WbPbrW+d/a11XfsL2X18dvJVkS6sKj3HolVc6cNYu60QWza6Zn219DgYqrJY7UtavF1kY4ta3C5/dckJrQc8ACPvv4VANN+ekbQ43X1Lu7946qIrxcRiUbct7R9Rg3qyewT+3P5XMP1F47nidtmk5qSAMC804e1+v1crsZdAxMTnCx4z7Jue3Qr932TWlzeLhYRkfYS9y1tn8QEJz846wT//eSkBB69eRarNhdykunj70se0jeTXQcj77y1p6icB/68BvB0pSxes5fFa/YyLD+L//rBSVGVqb7BRV0bQ7ukrCbyRSLS7XSZlnY4ToeD6WP64gzov544IveY3nPH/lLAE8jhVlW63W42FxzxX9PQ0LZZKK99uL3Z53YdKGPVZvWRi3RHXaalHclvbpjJ5oISZozpy8JPdgIwuG9GVHOpQ/u/P/xiL3/0Lr4ZMSCLfr3S/M/VBhzEUN/gbrGl7XK72VNYzuC+rdso/Z4XVgLwXEj/ueczXazaXMiMsX1xNLP4qKPV1bsoOFjGiAHZnfL5Il1Zl25pB8rJTOGUcf1wOh0M6pPBsPwsfn7lNK48+4SIr922N3jK3x8DVktu31vK8q8aT3H/Yush/21PS7tpaF/1wGKWfbmP9z7fzS+eX8m2PU2nFDYXt7c8+nEzz0B5VR2PvvYVTy3cyGpbhMvl5tP1B45poVBbvPzBVu7702oOHtZWACLtrdu0tAPdc9V0/+1Zk/rT0OAiKz2ZyaPyuP63H/pXTbbFn/+5xX9736EKsjOSw173l8XbGD+sFwDFpdWMJKRVGpDar3ywlUvOGInD4Qg6nSfUQy+vZXeh5zeH8qo6ln6xlwXvbaG6roE5kwcEXVtwsIyBfTKa3QrgWBR4xwzKq+ro2+7vLtK9dZuWdkvmTBnIVNMHp9PB8PysY3qv8qrGJfSLVhTwyF++DHtdVU29vwV8tKKW0pAwdgSk9nsrd1Nb72rSYg6dmeILbB/fYGZZZfB77zxQyi+eX8k73m6i9ub7HtBGiiLtT6Ed4sbvTOCm+RN55MaZ/sf+xbsVbLQLd6Ll6yt/5YOt3BzQ7bFpVwm7i4IDuK7e1SR8Aw8ybsLRGJqhfdu+MP96X2lbi94i3+e5lNoi7U6hHSKtRxInjupNz4wUcjJTALjwtGFcfe4Y7rtmBrlZKcHXpyQyfUyfNn3WF9sOhX38oZfXsutA8LTEr/eVUl4dfNhDbV3LJ+74QjN08WeC0/Nj74j9VTyf5/lA7Vku0v4U2i24/9qTeezWWTidDmZOyCcpMYGHrp/JbZee6L+mf146V587pl0+785HP2L91+EX8Pzu1S95bWnwNMAab0u7pq6B5V/tb/Iatz+0g1PbGbD4J5QtKGHL7iOtLnvY9z8OmV1SVnPMvzEUllRy1QOLm3xRisQihXYLkpMS6JHcdKx23NBe/gU2dXUukhITePL2lg9liMamnYd55K/h+8Chacvc19L++7KvefadkNPo3c33Kbe0/eyvX1rrX1TUVr7ukQZX+6wGdbncrN1aFLblfvezK/jli6s4dLTtG2t9sc3zRbl8fdMvPpFYo9Buo/TUJAB6ebtLkhITOG1ivv/5Pjmpx/wZg/tktPj8b//6Ja8v+5r3Vu5u8lx9Q+PA5atLt3PVA4u56oHFbN93lFXefVki7b/SVr6Wdn29mwaXi/teXMVXzfwGEY0P1uzh0de+YsWmg02eq/B2Gd334uo2v79IPFFot1GfnqncMG9CUNfID84yzJkygPHDevGzf53Kjd+Z4H/OF8Df/9Zorr9wfJP3uz2gy8UnOTmhxTKUlNXwdjMzQOoaXNSE6fMODLete47idrs5XFrNnsLoD2z4xXOf8+5nu5p93tfSrm9wUV5Zx/Z9pTy9cGPU7+9yu1ltC3G53by/ajcfrN4DwMHDzbemW5oKGYnD///jvxhpx/5Snl64QYO2ErVuOU+7vUw1eUH3E5xO/nWu8d+fMjqP/756OkfKahg3rBcut5sEp5O1Wzwt3RMG9/QveR87tBcv/uLbXPGL//O//li+UV9d0vwy+ECrbRGPvbEegPzcxpWddfUukhI9JSivquPhl9dy7qlDmXZCHwoKyykoLOeck4f4rz9cWs3+w5WMHtjTH9olZTVhvzgiWb5uP88v2swVZxleen+r//GqmvoWXnXs3Bz/4Hz0tXUcKa9l/uwR9Mpq39lJ0jVFFdrGmMuBO/BsEV0J3GSt1X6jURiYl8HAPE8rO8E3IOj9X1JiAglOB9840bPwJSezB9dfON4fom1x2TdH8XJA0EVSXdsYqvuLG1cwvrpkG++v3sOQvplccPowCgrLefyN9ew/LXjHxMIjVdz7wkp/N0Wglz/YyssfNJbl0JEqDpfVMHpQzybXut1u7nl+Jd+ePpgj5Z4picVHq4OuKTpSxatLtnHK+H7+P9P2oDauxJOIjTljjAEeAs6y1p4I/BJ4vaML1pWl9/D0h/fpmcoTt8/m+3NH+5876YQ+3PidCUwZncf0sZ71hDfMm0BGahKTR/Xm0jNGBrxPItecN9Z//w+3zOJbJw0K2/3SnLeaOf7sfW+XxK6DZUFTC9/4OPj6p97aEDawQ5VX1XHnE582O8hZV++ioLCcp9/e6N/gK7TPfe3WQyxaUcDdz34e8fNsQQl19a1v5fts3XMkqi6X0spa9hbpLFA5fqJpadcAP7TW+obWVwH9jDHJ1tq2dyR2Y6MH9eT6C8czaWSuf850oCmj85gyOg+3283pE/uTlOgM6oo5Y+pA1m0vZlh+FjmZKYwb1ovqmnpSUzw/zuZ+zT5xZG9yMlNYsnYvGalJlFfVcSikNRtOc4t4/v33H1FW2foT51fbQqaaPvxt6XYOHqniW1MHBoW5L6xb2jNl36EK3lsZ/nDmoiNV/Pqltcyc0I+rzx0b9ppA4Xqy71+whpzMFH5zw8ygx91uNzv2lzEsPxOHw8F/Pr2C8qq6sJt3tUb9cd4fRuJXxJa2tXantfYdAGOMA3gEeEuBfWxOOqEPSYktDzQ6HA5/v3KgxAQnU0bn+Rf/ZKUl0yensT86cOZKgtPBr649mbnTBnHj/An+PUgSQk7jOWVcv2bL0WQ6oVdoYJ85dWCL9fH5w9/Xs2LjQd79bBerNxc2aX1v9W6g1dJ88Rf+sZllXzZO0RvSr3GnxEpvy3/73ujmb4dOJfQNCobb03zFpoP88sVV/qPlArctaAv/9MgucliGy+3m6YUb2+1cVWkq6oFIY0w68AIwCDgr2tfl5h5b32NeXuu2LY137VHfPOCNB89j/dfF9MrqwaC+mUwwnq4WZ5Kna2bUoBxWeafQ/fVX55KU6GTenQuP6XN/cukU/0yPSJ58a0Ozz+0tqgBgZwuLXUK/8HIye/j/7K56YDHgWfHpe8ztduNyB58NesNDiznzpMEke7ur0lKTSUlL4WePL/dfE/rzOFLpqd9L72/l7NNGNHtdJL7rfV1BmVmpnfJ3vcHlpqKqjqz08BubtVZJWTWfbjjApl0l/Ome4Jjobv+WoWPqHO1A5GBgIbAJmGOtjXolQ3FxeZu3Bs3Ly6SoqPusUmvv+vbv6ekmCX3PWy+ZxIj+2f7QLi/1/DjPmDKAgX0yOG1CPglOB29/spMtu4+wYWcJQNhB0tSURP+sjsPF5Tz30zP8oRno3FOG8M6nzU8TDOQbiGyJ70xQn8qq2ib1PFpew959R9i4q4Tf/20d0LgHucvtpuBAGc+/vYELvIOrlZW1vPvRdnbub2yhr92wnw07DzNn8gASE51s3+35syitqGXpysb6FBaWNtnjpbK6jteWfc3Fc0aSktT4JeP7OW/aedg/2Fp0qJyMpODfqlZtLmT04J5kpSVTcLCMvJ6p/i6w9vLKB1t5b+VuHrt1VtiFZK3lGwdocLmCfh6+Ou86UMY7n+7kugvGhe0a7Era+u/Z6XS02NiN+FMyxmQCS4E/WmvvaXUJJOaMH9Z4ek//3un+25cHTFcEOG+mJ8x8IXzSCX3om5PKwZLG7+x7/m0a1bUNlEXoJsjreeyLjVqyu6ic/3n1SyaO7O1/rLbOxY9+82HQdfUNLhITnNQEzJrx7Zb4/uo9zJqUH3T9fX9aTU1dA39ZvI2RA7KD9lavDzrwwuVv/dfUNuByu1m0ooAla/ayZM3eoD7v4qNVrNlSxIdf7PM/ZguOMCxgh8nyqjoee2M9I/pncef3pvCL51cyfngvbr246Xz+Y+Hr5qmsrm+X0PY10Jqbdv74G+spPFLF/CPV9A04PESiF81P6UZgCDDPGDMv4PEzrbVtX+Ymne6+a2aQ3cpfi++4bDJ7D1Xw4Rf7OG1CPr3DhPH82cOpqK7nHysaBwr7RfEPdNzQHH+rvrWqahr4cnsxX0Y4fPnah5Zy8ZyR/N/njWUL3Ltk14HgmSCB88xDD8NwBHS1lFfVk5nmIDHByfW//bBJaB08XElez1R++OAS/2PjvPupA/x1yTbOmuGZ7piVnuz/IjlwuJLDpZ7W+I6QPVb2FJaTkpxwTF+Iid6xjeraBtZsKaKmtoFTxjeOb+zYX8rmghLOnjGkubcIEulMVP9c+M45VKlLiBja1tr7gfuPQ1nkOMvPTY98EXDX9yazY7/n17xeWT3oldWDCcObP2vz3FOGAp6gfmHRZgBGDszmRxeMY0jfTN75dBcfB2xwdfK4vgzMy+DMqQP55Yur2FtUwXXnjwvq9x7RP4vsjBTOnzmUXzy/srVVDfLXJduC7m/a1fhFUV4V/fh64FTI2/7g6Qe/7vxxYVuZa7YU8WrIhl/VIYuFSspquO0Pyzl/5lBOneBp8bvcboq9oV1RXU9tXQMfrdtPemoiT721kQSng6fvnAPAc+9sYsf+Ugb2yeDa88bicDi46oHFXHj6MM73/tb02YYDmME5/kHsxARPF0VlTT3/+/pXAEGhfe8fPcsxog3tSAOqWvh57LQiUiIyg3Mwg3Na/bpZk/pTU9vA6EE9/Ycsg+dw5Y+/2s/EEbkMH9iTKSNyGehd5n/zdyexfkcxM8b2JTnRyd5DFby+7Gvye6dz1Tnhd1OcOaFf0JFvx6K4NHJ/us/7YQZdmxtgDQ1sgO0hLecD3uPZ3lq+0z+DpaqmIWiLgdDunsC57L4vwr2HKshKS2ZYvmcQ7I2PdtAnJ5Xh+Vk8tXAjvbN78OCPTwUaQzvSLJgGl6tJH7TL7cbtXeXrUx9ykHV1bT3XP7KMn14xjdH9GwflQg+8Lq+qY+Hyncyc0K/JmambdpVQdKSKWZP6t1jG7kKhLR3qW9MGNXls7NBeDO2XyUXfGMGJY/ODBmtys3sw27tCdPLoPMYMzWHvoQrmzxruv2bUwGz/tECAq88diwNHUOs9McHRJEBakt4jMapFQoHCne15LB56ea3/9qLPGrtvXlm8LdzlQUJPMfrnquBNxJ56q3Hvl0NHq3njo6+58PTh/tD2DdSCZ6bNgve2BE25rK1zkZoSHNov/sOy7Mt9Qf31oeXwfQn+adEm7r16un96Zeh1N/3PRwB8uuEAv//304Oe8/25tBTa+w5VsG57MWfNGNzsNV1F1x6+lZiU1iORu6+cxoAolqL3SE7kuvPHkZ3RePjEHZdN5lfXntzsawb0Tve3JAHOmh75H7IvvJpz2yWeAcDMtKSI79Ueot2BMcHp4PVl27n2oaWtev+3lntmBu3Y33Qu+7Iv97Fk7V72HqrwPxZugZVvi9/Aee6+FnR5VR13Pv5JQHeJm2fe3ugP8foGN0crapuEd4unMbXggT+v4a9LtrX59T6+7YQ37Tzc5AjAWKHQlriTmOCkX680br5oIj/9/hQAzGDPfiYXzRnBvT+cQc+AkL84YOl/4K6M6T0SGTXQc6BypCXr44b14sqzT+DuH0zj51dO44wpwQclZ2ckk+UN9HNPCe7//eZJ0S06aosGl5u3P4luKmWo5rYUCFy05PPqkm28ErCPzMfrGq9ZtKIAl8uzW2TgQOSho9UUHfHMNHK54JP1jV1YJWU13PLox/zkdx+xfkfTweNdB8rYtKuEhQHbLLS0LYFv2qmviynU5l0lzU49Plpew/a9RymvquOaB5eyaMUuHnrlCx75yxfNfh7A68u288NfL2nxmo6g7hGJWxNHNE7vO3V8P6aPCV5levW5Y/jSe3DE5FG96d87nZkT8pkxti+HS6tJTUnk4Vca/2Hef+3J/MdTnwEEzTdP7+H5Z+L79Tw3uwf1Df1YvGav/7XllXU8+ONTKSypxAzO8c9Jv/+6k3G53Ly/qvlFR/NnD6essi7svug/umAcT7zZ/EKkjhCu9b3cG7gHDlfyb+eM4bl3G1fJ/m3pdhZ9touK6vqglakAr3zg6doJPd/0D3/3DHrW1DUEHX5dU9fA7/+2LuxRfC+9v5UPv9hHakoiN180kVEDGzce802R//lzn/PMXXOCTmvavKuEB19ey7xZwznPe95roPsXrKHwSBU/u2Iq0LhDZuhB2aF8X5Zut5uqmgZSUxKazNXvCGppS5fgWfIfvEpy5oR8rp/n2dP8J/MnMn+2ZwVjYoKTPjlpZKYl+7tOLpozgr690rhh3nhuuXhS0Ps88KNTmnyebxuA3tk9GDkwm+vOH0dOZop/wDYxwUF6j0T65qSRn5ve4jmi554ylO9+w1O2K84Knis/PGDudixYt724yawXaDyMIvTINt/Ml9Ys92/u7FTfvPaqmnruX7AmZKvexrD07afj67Yp8S7W2neoApfL3WTv8kLvbwOhZXcD+4srCHW0ojZoH/vio8w4cOoAAAvzSURBVNXc+LtlXP3rJU0WfXUEtbSlWztlfL+gKW5TTWO4jhmSQ32Dy78rY6AhfTOZP3s4p0/sH3YJ+P/cdHpQa2/UwJ58vqmw2XIkJjj9A3ov/sMCnhWogfPgf/nDGSQkOEhLSeTff/9x0OtbuyVvoO99cxTrthezfkd0gRM6ZbKz3PDbZWSlJZGRlhzUN/7up7v4fNNBqmsbGNE/y//zdbvd/OyZFZRX1jLthD6MG9Yr6MtkwXtbmnzGz55ewX3XzKC0ohYzOAe3280tjwb/2fu+mMAzo2jM0F6hb9OuFNoizbjjssnNPudwOPzz0cMJXW4+Z/IAFn6ys1WDW5NH9w66H7h69eI5Ixk/rBd3P/c52enJfOukQUwe1Zs7H//Uf03oCs7m5GT24Eh5rfd2StiNsiaOyGWdd+HS2q3hW8LfOLE/SwNWeR4PpZV1lIZsXOYbIAXPtErfIPZqW+Qf4F36xb6oy/rAn9dQVlnH47fNZmuYTcwCg9/38121uZAze3bMik91j4gcB06ng9/ccCo3XzSJGeP6ceaUgcydNijsF8O3TvJMk/TNf77mvLF8M2QHxbNmDGZgnwxuvXgSP73cMxibnd44+PrMXXP8g6w+V587JuyukUP7ZTJ2qKdb59aQrqHJo3pz3fnjwvYFhxoxwPN5GalJPH7bbP+uj76FPADXnt90q9wU77F6F80ZEfR4TmYKGanHPlvHNwDZ1jNRfbtZbtl9JOzB24Hnn9bUuXjlg6089sZ6nl/YMWMRammLHCcJTicTR+Ry5slDW9xI6LJvjuKyb47y3z9lXL9mt84dH7AyNSnRSUpSAmfNGIzT4eD804axyLuVwEVzRjBzQj7vrdzN7sJy5k4bxJHyGq49bxxOp4OLzxjJ+TOHktYjiVmT8v0zSH4yfyLQOJCYm5XCiAHZTbp6LjxtGKeO70efnFRGDsjG4XBwzslDKCmr4fK5o7n1fz0rRsOtpO2d3YO9RRUkOBzMnz2c1z78mlPG9ePyuaO55/mVYfvDe2f3iGoveGi+j7y1fhsQ2HOnDfIPHAfOtimvqvU/3lGHYyi0RbqQx2+b7b+dkpTA5FG9KThY5l+Gnp2RzO5CT3dN4IZNToeDNG/f/ZVnj2HZl/uDBk8z05J55s45OByerqEfXQCfrj/A029vZPqYPpzv3SkxcEZHTmaK/3Dr394ymzUb9pPeI4ln75rD1QFT5bLTk9lbVEFNvYvzTh0a1O10yyWT2Lm/rMlK019dezJ/Wbytxa2AxwzJCdqioDWG5WeFnUUDnimd/ZvZAsLXzQRtb9lHotAW6cJ8LWWfa88bx5fbDkXcYe9/b55FSnJwV4rTGTydzTcLI5oNq0YO7El2iqcbxOFw+A+1HtI3k/NnDmPjzhLGD2s6gNc3J42+OWlkpSfjcrv5jXeKZmKCk4u+MYKTx/UlvUcS/887VTNQc3uEp6Uk8i+nDqV/73R+96qn9Txv1nD+vuxrAJ664xv8c9XuZkN72gl9OBym3/94UWiLdCMZqUnMnJAf8bq0HpGjYcbYvpRW1EZ9YlGgO783Jeh+pOPaxgzx9LlfesZIVtkiAJKTEhjRPztoJ0aAK88+gZ0Hyrjw9GHMnzWcO59oHJw9a/rgoMVWY4fmsHFnCZNH9mb5V/upq/ds3Ru6mdp3Zg3ndW+oZ6UnR3V+6KUhWx23F4W2iLRJYoKTs0+Obve/9jJ3+mDmhmxLkJKUELTP+6xJ/ZnlG09Ngwd/fApL1u5l0WcFTb6Mbr90Mm63G4fDEbQ1wokje3PX9yYzpF+mf5/x1baIXQfLyEhNIi3MYRR3fW8yv37Js0/Kw9efihnRu0MOcdHsERGJe/df51kAFe5kn97ZqTi8i2/CLVj0rWJ0OhxBc+vN4JyggyFuvWQSP/3+FBITnIwYkM2tl0zixIBDN8zgHC775ijOPWVIs4drtwe1tEWkS7jnqunNThGcfWJ/Vm0ubPEA60gy05LJTGvsJx8/LNe/SvOyMz2zfXzTNTuSWtoi0iUM6pMRNCc8UF7PVB740Snt3gKefaJnP5rQhVAdSS1tEZE2Gj8sN+IgantTS1tEJI4otEVE4ohCW0Qkjii0RUTiiEJbRCSORDV7xBjjAF4AvrLWPtyhJRIRkWZFbGkbY8YAHwDf7fjiiIhIS6Jpad8APAMUdHBZREQkgoihba29EcAYM7fjiyMiIi3p8BWRubkZx/T6vLzMdipJfOhu9QXVubtQndtHh4d2cXG5/4y21srLy+yQrQ1jVXerL6jO3YXqHD2n09FiY1dT/kRE4ohCW0QkjkTdPWKtvbIDyyEiIlFQS1tEJI4otEVE4ohCW0Qkjii0RUTiiEJbRCSOKLRFROKIQltEJI4otEVE4ohCW0QkjnT4hlFtVbdlOfv+8Ql1dfWdXZTjZl9SYreqL6jO3UV3rHPZSXMhf2q7v69a2iIicSRmW9pJo2eSN/OsbrWdo7av7B5U5+4hMy+T6g6os1raIiJxRKEtIhJHFNoiInFEoS0iEkcU2iIicUShLSISRxTaIiJxpCPnaSeA5zj4Y3Gsr4833a2+oDp3F6pzq1+TEO55h9vtPoYiteg04KOOenMRkS7udODj0Ac7MrRTgGnAfqChoz5ERKSLSQDygZVATeiTHRnaIiLSzjQQKSISRxTaIiJxRKEtIhJHFNoiInFEoS0iEkcU2iIicUShLSISR2LyuDFjzLnA/XgW6KwDrrbWlnZuqY6dMeZy4A7ADVQCNwFrgd8AZ+H5eTxsrX3Ce/0o4FmgN1AOXGGt3dwJRT9mxpgLgT9ZazONMQl04TobYyYAjwLZeBaWXQd8Qdeu8zzgHsAFHAauAXbSxepsjHEALwBfWWsfbuvfZWPMVcDtQBLwPnCTtbYumjLEXEvbGJMHPA/Mt9Ya4Gvggc4t1bEzxhjgIeAsa+2JwC+B1/H8gx4NjMezgvRmY8x078v+DDxhrR0L/Bz4m/cvTVzx/uV9GPCVvcvW2RiTBrwHPGitnQzci6dOXbnOqcAC4Dvev9sLgd/TxepsjBkDfAB8N+DhVtfRGDMezxfcbMAAPYFboi1HzIU2MBdYaa3d6r3/OPD9WP+BRqEG+KG1dr/3/iqgH3AR8Ly1tt5aWwK8AlxujBkAnOC9j7V2EZABTD7uJT8G3hBbANwa8PA8um6d5wLbrbXveu+/BVxM165zAp4v5Gzv/Qygmq5X5xuAZ4BXAx5rSx0vAN6y1hZZa13Ak8Dl0RYiFkN7ELA74P4eIAvI7JzitA9r7U5r7Tvg/xXrETz/oPNpWt+BeP4c9nl/qKHPxZMnvf+tC3gs3M+4q9R5NHDAGPOsMWYV8E88vzZ32Tpba8uBHwGfGGP2ATcCd9HF6mytvdFa+1LIw22pY3OviUoshrYTT59vqC6x6ZQxJh34KzAS+CFN6+vAU9dwfw6+5+KCMeZ6oN5a+1zIU122znj6KM8BnrLWnoSnb/tdPOMzXbLO3j78u4Gx1tr+wH3Aa3ha4F2yzgHa8ne5uddE/YGxpgDoH3B/AFBira3opPK0G2PMYOATPD+gOdbaIzStb38837wFQH5It5DvuXhxJTDNGPMFnuBK9d7eQ9et8z5gk7V2BYC19k084fU1XbfO3waWW2u3e+//AU8f7y66bp192vLvt7nXRCUWQ/s94GTv4BV4fu16sxPL0y6MMZnAUuB1a+2l1toq71NvAlcZYxKNMT2BS4E3rLV7gG3AJd7XfxvPyPxXx73wbWStnW6tHe8dnDoHqPLe/jtdtM7AImCYMWYqgDFmFp5W1Rt03TqvAWYbY/p6718I7KAL/90O0JY6vgWcb4zp4w31a/H8/YhKzE35s9YWGmP+Dc9IazKwHbiik4vVHm4EhgDzvNOjfL4NjAC+BJKBJ621H3qfuwx42hjzn3gGdi4K6SOLV4/TRetsrT3gnd74mLcrrAb4DvAZXbfOi40xDwFLjTG1eKb8XQBYumidA7Tl7/I6Y8x/A4vxdKetAH4d7QdqP20RkTgSi90jIiLSDIW2iEgcUWiLiMQRhbaISBxRaIuIxBGFtohIHFFoi4jEEYW2iEgc+f9sXiPD+6QPBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['dis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-eda2b5cc1a42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "import itertools\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(train_x,train_y,train_size=0.70, random_state=2)\n",
    "\n",
    "train_x.shape\n",
    "\n",
    "# create the RFE model and select 10 attributes\n",
    "rfe = RFE(rfc, n_features_to_select=41)\n",
    "rfe = rfe.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "ac = accuracy_score(Y_test,rfe.predict(X_test))\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(Y_test,rfe.predict(X_test))\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
