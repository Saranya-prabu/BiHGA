{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]\n"
     ]
    }
   ],
   "source": [
    "def createList(r1, r2):\n",
    "  \n",
    "    # Testing if range r1 and r2 \n",
    "    # are equal\n",
    "    if (r1 == 118):\n",
    "        return \"Label\"\n",
    "  \n",
    "    else:\n",
    "  \n",
    "        # Create empty list\n",
    "        res = []\n",
    "  \n",
    "        # loop to append successors to \n",
    "        # list until r2 is reached.\n",
    "        while(r1 < r2+1 ):\n",
    "              \n",
    "            res.append(r1)\n",
    "            r1 += 1\n",
    "        return res\n",
    "      \n",
    "# Driver Code\n",
    "r1, r2 = 1, 118\n",
    "print(createList(r1, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_1 = pd.read_csv(r'C:\\Users\\admin\\ablation study - Copy\\with attention and without dimensionality reduction\\lgcabnormalresult.csv', header=None, names=createList(1, 118))\n",
    "\n",
    "csv_1.to_csv(\"lgcabnormalresult.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             1    2    3    4    5    6    7    8    9     10   ...    109  \\\n",
       "0      1.000000  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0  10.0  ...  109.0   \n",
       "1      0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "2      0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "3      0.000001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "4      0.000001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...   \n",
       "39996  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "39997  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "39998  0.000001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "39999  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "40000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "\n",
       "         110    111    112    113    114    115    116    117    118  \n",
       "0      110.0  111.0  112.0  113.0  114.0  115.0  116.0  117.0  118.0  \n",
       "1        0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "2        0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "3        0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0  \n",
       "4        0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "39996    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "39997    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "39998    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0  \n",
       "39999    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "40000    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "\n",
       "[40001 rows x 118 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_1.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lgcabnormalresult.csv\",sep=\",\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      float64\n",
      "2      float64\n",
      "3      float64\n",
      "4      float64\n",
      "5      float64\n",
      "        ...   \n",
      "114    float64\n",
      "115    float64\n",
      "116    float64\n",
      "117    float64\n",
      "118    float64\n",
      "Length: 118, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               1    2    3    4    5    6    7    8    9    10  ...    109  \\\n",
       "0      1.000000  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0  10.0  ...  109.0   \n",
       "1      0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "2      0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "3      0.000001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "4      0.000001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...   \n",
       "39996  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "39997  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "39998  0.000001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "39999  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "40000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0   \n",
       "\n",
       "         110    111    112    113    114    115    116    117    118  \n",
       "0      110.0  111.0  112.0  113.0  114.0  115.0  116.0  117.0  118.0  \n",
       "1        0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "2        0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "3        0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0  \n",
       "4        0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "39996    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "39997    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "39998    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    1.0  \n",
       "39999    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "40000    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "\n",
       "[40001 rows x 118 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = mydataframe.drop(['acol','bcol'], axis=1).values \n",
    "#y = mydataframe['targetvalue'].values\n",
    "df_label=df['118'].values\n",
    "X=df.drop(['118'], axis=1).values \n",
    "y=df['118'].values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y.to_csv('normallabel1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000 Training sequences (28000, 117)\n",
      "12001 Validation sequences (12001, 117)\n",
      "28000 Training sequences (28000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(X,y,train_size=0.70, random_state=2)\n",
    "print(len(x_train), \"Training sequences\",x_train.shape)\n",
    "print(len(x_val), \"Validation sequences\",x_val.shape)\n",
    "print(len(y_train), \"Training sequences\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#https://stackoverflow.com/questions/53867351/how-to-visualize-attention-weights#:~:text=On%20loading%20saved%20model%20you,attention%20layer%20output%20on%20predict.&text=Now%20you%20can%20get%20the,and%20also%20the%20attention%20vector.&text=To%20summarize%20you%20need%20to,rgb%20or%20hex%20and%20visualise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation,RepeatVector,Permute \n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "maxlen=117\n",
    "vocab_size = x_train.shape[0]\n",
    "visible = layers.Input(shape=(maxlen,))\n",
    "\n",
    "embed=Embedding(vocab_size,117)(visible)\n",
    "\n",
    "activations= keras.layers.GRU(117, return_sequences=True)(embed)\n",
    "\n",
    "attention = TimeDistributed(Dense(1, activation='tanh'))(activations) \n",
    "attention = Flatten()(attention)\n",
    "attention = Activation('softmax', name='attention_vec')(attention)\n",
    "#attention = RepeatVector(1)(attention)\n",
    "#attention = Permute([2, 1])(attention) \n",
    "\n",
    "#sent_representation = keras.layers.multiply([activations, attention])\n",
    "#sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",
    "predictions=Dense(1, activation='sigmoid')(attention)\n",
    "\n",
    "model = keras.Model(inputs=visible, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 117)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 117, 117)          3276000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 117, 117)          82836     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 117, 1)            118       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 117)               0         \n",
      "_________________________________________________________________\n",
      "attention_vec (Activation)   (None, 117)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 118       \n",
      "=================================================================\n",
      "Total params: 3,359,072\n",
      "Trainable params: 3,359,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 12001 samples\n",
      "Epoch 1/5\n",
      "28000/28000 [==============================] - 116s 4ms/sample - loss: 0.6715 - accuracy: 1.0000 - val_loss: 0.6528 - val_accuracy: 0.9999\n",
      "Epoch 2/5\n",
      "28000/28000 [==============================] - 102s 4ms/sample - loss: 0.6396 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "28000/28000 [==============================] - 100s 4ms/sample - loss: 0.6123 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "28000/28000 [==============================] - 105s 4ms/sample - loss: 0.5858 - accuracy: 1.0000 - val_loss: 0.5703 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "28000/28000 [==============================] - 101s 4ms/sample - loss: 0.5633 - accuracy: 1.0000 - val_loss: 0.5558 - val_accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, batch_size=1024, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0h 8m 55s\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "\n",
    "diff = (end - start)\n",
    "\n",
    "datetime.timedelta(seconds=10, microseconds=885206)\n",
    "\n",
    "diff_seconds = int(diff.total_seconds())\n",
    "\n",
    "minute_seconds, seconds = divmod(diff_seconds, 60)\n",
    "hours, minutes = divmod(minute_seconds, 60)\n",
    "hms = f\"{hours}h {minutes}m {seconds}s\"\n",
    "\n",
    "'0h 0m 10s'\n",
    "print(hms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=model.input,\n",
    "              outputs=[model.output, model.get_layer('attention_vec').output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.get_layer('attention_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[0.00211791, 0.00161591, 0.00145112, ..., 0.00980348, 0.0098013 ,\n",
      "        0.00980391],\n",
      "       [0.00211791, 0.00161591, 0.00145112, ..., 0.00980348, 0.0098013 ,\n",
      "        0.00980391],\n",
      "       [0.00211221, 0.00161156, 0.00144721, ..., 0.00977711, 0.00977708,\n",
      "        0.00977708],\n",
      "       ...,\n",
      "       [0.00211791, 0.00161591, 0.00145112, ..., 0.00980348, 0.0098013 ,\n",
      "        0.00980391],\n",
      "       [0.00211791, 0.00161591, 0.00145112, ..., 0.00980348, 0.0098013 ,\n",
      "        0.00980391],\n",
      "       [0.00211221, 0.00161156, 0.00144721, ..., 0.00977711, 0.00977708,\n",
      "        0.00977708]], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K\n",
    "outputs = []\n",
    "keras_function = K.function([model.input], [layer.output])\n",
    "outputs.append(keras_function([x_train, 0]))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.        , 0.        , 0.        , ..., 0.08554822, 0.23254418,\n",
      "        0.6321206 ],\n",
      "       [0.00760901, 0.00760901, 0.00760901, ..., 0.00760901, 0.00760901,\n",
      "        0.00760901],\n",
      "       [0.00758161, 0.00758161, 0.00758161, ..., 0.00758161, 0.00758161,\n",
      "        0.00758161],\n",
      "       ...,\n",
      "       [0.00745372, 0.00745371, 0.00745371, ..., 0.00745371, 0.02026127,\n",
      "        0.00745371],\n",
      "       [0.00761792, 0.00761792, 0.00761792, ..., 0.00761792, 0.00761792,\n",
      "        0.00761792],\n",
      "       [0.00760203, 0.00760203, 0.00760203, ..., 0.00760203, 0.00760203,\n",
      "        0.00760203]], dtype=float32)]\n",
      "(1, 40001, 117)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "hidden_layers = keras.backend.function(\n",
    "[layer.input],  # we will feed the function with the input of the first layer  \n",
    "[layer.output,] # we want to get the output of the first layer\n",
    ")\n",
    "h=hidden_layers([X])\n",
    "print(h)\n",
    "print(np.shape(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.concatenate(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('abnormalattentionvector.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_1 = pd.read_csv('abnormalattentionvector.csv')\n",
    "csv_2 = pd.read_csv('abnormallabel1.csv')\n",
    "\n",
    "result = pd.concat([csv_1, csv_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"attenetionabnormalresult.csv\", index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
